id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/3290:140,security,hash,hashes,140,"Hi @oshadura As it is, I think we should squash the PR. The first two commits should be just one, since one adds the files (which makes the hashes and filenames broken), then the other one fixes it. Please merge the commits so that there is not intermediate broken state.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3290:11,deployability,build,build,11,@phsft-bot build just on windows10/default.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3290
https://github.com/root-project/root/pull/3291:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3291:42,deployability,Contain,Contains,42,"For the record, a very similar idiom (`if(Contains())` followed by `DistFromOutside()`) appears at TGeoNavigator.cxx:888, in `FindNextBoundary()`. It should probably be addressed as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3294:39,reliability,pra,pragma,39,"Hi @bellenot ,. As far as I know, same pragma supported with clang compiler. In your changes you should disable just windows compiler",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3294
https://github.com/root-project/root/pull/3294:46,usability,support,supported,46,"Hi @bellenot ,. As far as I know, same pragma supported with clang compiler. In your changes you should disable just windows compiler",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3294
https://github.com/root-project/root/pull/3294:43,reliability,pra,pragma,43,"> Hi @bellenot ,. > As far as I know, same pragma supported with clang compiler. > In your changes you should disable just windows compiler. OK, will change them",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3294
https://github.com/root-project/root/pull/3294:50,usability,support,supported,50,"> Hi @bellenot ,. > As far as I know, same pragma supported with clang compiler. > In your changes you should disable just windows compiler. OK, will change them",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3294
https://github.com/root-project/root/pull/3298:11,deployability,build,build,11,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3298:30,performance,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3298:30,usability,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3298:11,deployability,build,build,11,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON -DCTEST_TEST_EXCLUDE_NONE=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3298:30,performance,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON -DCTEST_TEST_EXCLUDE_NONE=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3298:30,usability,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3 with flags -Dpyroot_experimental=ON -DCTEST_TEST_EXCLUDE_NONE=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3299:85,deployability,modul,modules,85,"I cannot tell whether it's better to expose this header to `rootcling` and add it to modules.map, or vice versa... @amadio what's your take? IIUC, before your change, `ROOT/Rconfig.h` wasn't part of the headers passed to `rootcling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:85,modifiability,modul,modules,85,"I cannot tell whether it's better to expose this header to `rootcling` and add it to modules.map, or vice versa... @amadio what's your take? IIUC, before your change, `ROOT/Rconfig.h` wasn't part of the headers passed to `rootcling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:85,safety,modul,modules,85,"I cannot tell whether it's better to expose this header to `rootcling` and add it to modules.map, or vice versa... @amadio what's your take? IIUC, before your change, `ROOT/Rconfig.h` wasn't part of the headers passed to `rootcling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:37,security,expos,expose,37,"I cannot tell whether it's better to expose this header to `rootcling` and add it to modules.map, or vice versa... @amadio what's your take? IIUC, before your change, `ROOT/Rconfig.h` wasn't part of the headers passed to `rootcling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:117,deployability,modul,module,117,"If it wasn't part of the headers, removing it is fine, but you know better than me in case you want to add it to the module map.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:117,modifiability,modul,module,117,"If it wasn't part of the headers, removing it is fine, but you know better than me in case you want to add it to the module map.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:117,safety,modul,module,117,"If it wasn't part of the headers, removing it is fine, but you know better than me in case you want to add it to the module map.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:51,deployability,modul,module,51,Thanks! Yeah this header is already in ROOT_Config module,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:51,modifiability,modul,module,51,Thanks! Yeah this header is already in ROOT_Config module,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:51,safety,modul,module,51,Thanks! Yeah this header is already in ROOT_Config module,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:102,deployability,modul,modules,102,"No it's not, that's why brought it up. We have `RConfig.h` (the backward-compatibility header) in the modules.map, not `ROOT/RConfig.hxx`, the real one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:73,interoperability,compatib,compatibility,73,"No it's not, that's why brought it up. We have `RConfig.h` (the backward-compatibility header) in the modules.map, not `ROOT/RConfig.hxx`, the real one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:102,modifiability,modul,modules,102,"No it's not, that's why brought it up. We have `RConfig.h` (the backward-compatibility header) in the modules.map, not `ROOT/RConfig.hxx`, the real one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:102,safety,modul,modules,102,"No it's not, that's why brought it up. We have `RConfig.h` (the backward-compatibility header) in the modules.map, not `ROOT/RConfig.hxx`, the real one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:40,deployability,modul,module,40,"Hi, added ROOT/RConfig.h to ROOT_Config module and removed the exposure to rootcling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:40,modifiability,modul,module,40,"Hi, added ROOT/RConfig.h to ROOT_Config module and removed the exposure to rootcling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:40,safety,modul,module,40,"Hi, added ROOT/RConfig.h to ROOT_Config module and removed the exposure to rootcling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3299:63,security,expos,exposure,63,"Hi, added ROOT/RConfig.h to ROOT_Config module and removed the exposure to rootcling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3300:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3300
https://github.com/root-project/root/pull/3301:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3301
https://github.com/root-project/root/pull/3303:13,deployability,fail,failing,13,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:98,deployability,build,builds,98,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:78,energy efficiency,current,current,78,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:13,reliability,fail,failing,13,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:21,safety,test,test,21,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:21,testability,test,test,21,Warnings and failing test are not related to my change (they are there in the current incremental builds).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3306:71,energy efficiency,measur,measurement,71,> Set the block size for TBufferMergerFile to 1MB. What's the rational/measurement leading to that choice?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:0,energy efficiency,Reduc,Reduce,0,"Reduce the memory usage by 50% in some usecases, e.g. atlas susy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:11,performance,memor,memory,11,"Reduce the memory usage by 50% in some usecases, e.g. atlas susy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:11,usability,memor,memory,11,"Reduce the memory usage by 50% in some usecases, e.g. atlas susy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:29,availability,cluster,cluster,29,What is the size of the file/cluster in that case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:29,deployability,cluster,cluster,29,What is the size of the file/cluster in that case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:100,interoperability,specif,specific,100,The question I am pondering is whether we need to tweak the default (as done in the PR) or just the specific case (as now allowed by this PR).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3310:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:32,availability,error,errors,32,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:18,deployability,configurat,configuration,18,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:18,integrability,configur,configuration,18,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:67,interoperability,platform,platforms,67,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:18,modifiability,configur,configuration,18,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:32,performance,error,errors,32,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:32,safety,error,errors,32,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:18,security,configur,configuration,18,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:32,usability,error,errors,32,"There are lots of configuration errors on this branch on different platforms, unrelated to this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:70,deployability,patch,patch,70,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:76,deployability,releas,release,76,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:192,energy efficiency,schedul,schedule,192,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:171,interoperability,compatib,compatible,171,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:192,performance,schedul,schedule,192,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:70,safety,patch,patch,70,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:70,security,patch,patch,70,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:139,security,team,team,139,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:37,testability,plan,plans,37,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:124,usability,help,helpful,124,"@agheata @Axel-Naumann Are there any plans on your side to make a new patch release to the v6.12 series? That would be very helpful for my team, but I don't know if it is compatible with your schedule. Also, I am not sure this is the correct place to ask. Should I open a new issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:29,deployability,patch,patch,29,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:35,deployability,releas,release,35,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:233,deployability,patch,patch,233,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:29,safety,patch,patch,29,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:233,safety,patch,patch,233,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:29,security,patch,patch,29,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:233,security,patch,patch,233,We were indeed considering a patch release to v6.12 - also for other reasons than your commit. Could I ask for your use-case / experiment / some motivation? I.e. if this is mission critical for an experiment's DAQ (doubt it for this patch ;-) then we'll hurry up!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:270,deployability,patch,patch,270,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:276,deployability,releas,release,276,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:400,deployability,releas,release,400,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:270,safety,patch,patch,270,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:352,safety,valid,validation,352,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:33,security,team,team,33,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:270,security,patch,patch,270,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:352,security,validat,validation,352,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:8,testability,context,context,8,"For the context, I belong to the team that develops the TRIPOLI-4 Monte-Carlo particle transport code, which uses ROOT as (among other things) a geometry engine. We are not in a terrible hurry (hopefully in a month or two though?), but we would greatly appreciate a new patch release on top of the v6.12 branch. That would largely cut on the amount of validation work that we need to do for our next release. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:33,deployability,patch,patch,33,@Axel-Naumann any news about the patch release to v6.12? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:39,deployability,releas,release,39,@Axel-Naumann any news about the patch release to v6.12? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:33,safety,patch,patch,33,@Axel-Naumann any news about the patch release to v6.12? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:33,security,patch,patch,33,@Axel-Naumann any news about the patch release to v6.12? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3312:20,availability,error,error,20,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:55,deployability,log,log,55,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:26,integrability,messag,message,26,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:26,interoperability,messag,message,26,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:20,performance,error,error,20,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:20,safety,error,error,20,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:55,safety,log,log,55,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:55,security,log,log,55,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:55,testability,log,log,55,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:20,usability,error,error,20,> Could you add the error message we get to the commit log? @Axel-Naumann Done,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3316:158,deployability,fail,fails,158,"> thanks a lot. If this works also on linux and mac, why not removing the ifdef? Well, this is a problem very specific to Windows (gSystem->Unlink(filename); fails when the file is in use) , but if you want I can remove the ifdef...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3316
https://github.com/root-project/root/pull/3316:110,interoperability,specif,specific,110,"> thanks a lot. If this works also on linux and mac, why not removing the ifdef? Well, this is a problem very specific to Windows (gSystem->Unlink(filename); fails when the file is in use) , but if you want I can remove the ifdef...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3316
https://github.com/root-project/root/pull/3316:158,reliability,fail,fails,158,"> thanks a lot. If this works also on linux and mac, why not removing the ifdef? Well, this is a problem very specific to Windows (gSystem->Unlink(filename); fails when the file is in use) , but if you want I can remove the ifdef...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3316
https://github.com/root-project/root/pull/3320:52,interoperability,standard,standard,52,"I heard we cannot use just `<regex>` from the C++11 standard, but I can't remember why. Do you know?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:74,safety,reme,remember,74,"I heard we cannot use just `<regex>` from the C++11 standard, but I can't remember why. Do you know?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:37,reliability,doe,doesn,37,"Nevermind, I remembered... GCC 4.8.5 doesn't have full support for `<regex>` yet (the compiler in CentOS 7). What a bummer. If we could require 4.9 at least, which is still ancient, we'd be able to use it. @Axel-Naumann any thoughts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:13,safety,reme,remembered,13,"Nevermind, I remembered... GCC 4.8.5 doesn't have full support for `<regex>` yet (the compiler in CentOS 7). What a bummer. If we could require 4.9 at least, which is still ancient, we'd be able to use it. @Axel-Naumann any thoughts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:55,usability,support,support,55,"Nevermind, I remembered... GCC 4.8.5 doesn't have full support for `<regex>` yet (the compiler in CentOS 7). What a bummer. If we could require 4.9 at least, which is still ancient, we'd be able to use it. @Axel-Naumann any thoughts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:23,deployability,version,version,23,"Increasing the minimal version even by a tiny bit kills CentOS7 support, which we want to keep.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:23,integrability,version,version,23,"Increasing the minimal version even by a tiny bit kills CentOS7 support, which we want to keep.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:23,modifiability,version,version,23,"Increasing the minimal version even by a tiny bit kills CentOS7 support, which we want to keep.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:15,usability,minim,minimal,15,"Increasing the minimal version even by a tiny bit kills CentOS7 support, which we want to keep.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3320:64,usability,support,support,64,"Increasing the minimal version even by a tiny bit kills CentOS7 support, which we want to keep.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3320
https://github.com/root-project/root/pull/3321:0,usability,Close,Closed,0,Closed in favor of #4027.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3322:11,deployability,build,build,11,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:30,performance,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:30,usability,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:11,deployability,build,build,11,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:30,performance,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:30,usability,perform,performance-,30,"@phsft-bot build just on ROOT-performance-centos7-multicore/default, ROOT-fedora29/python3, mac1014/cxx17 with flags -Dpyroot_experimental=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3323:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3323
https://github.com/root-project/root/pull/3323:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3323
https://github.com/root-project/root/pull/3323:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3323
https://github.com/root-project/root/pull/3324:4,reliability,doe,does,4,How does this lexer/tokenizer compare to TString::Tokenize?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:20,security,token,tokenizer,20,How does this lexer/tokenizer compare to TString::Tokenize?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:50,security,Token,Tokenize,50,How does this lexer/tokenizer compare to TString::Tokenize?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:267,availability,error,errors,267,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:257,modifiability,variab,variable,257,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:111,performance,time,time,111,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:267,performance,error,errors,267,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:325,reliability,doe,does,325,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:19,safety,detect,detection,19,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:267,safety,error,errors,267,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:531,safety,compl,complex,531,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:19,security,detect,detection,19,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:316,security,Token,Tokenize,316,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:370,security,token,tokens,370,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:480,security,Token,Tokenize,480,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:514,security,token,token,514,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:531,security,compl,complex,531,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:183,testability,hook,hook,183,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:334,testability,understand,understand,334,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:267,usability,error,errors,267,"This is great! The detection of names of used branches with regexps has always been a dark corner of RDF. Some time ago @axelnaumann suggested to use cling directly for this purpose, hook into the jitting of the expression itself and react upon ""undeclared variable"" errors, but this seems cleaner. @pcanal TString::Tokenize does not understand c++, here we need to get tokens in the programming language parser sense of the term. I.o.w. the regexp that one would need to pass to Tokenize to properly separate c++ token is way too complex, if it even exists",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:510,availability,reliab,reliable,510,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,deployability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,integrability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,interoperability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,modifiability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,reliability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:510,reliability,reliab,reliable,510,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:16,safety,compl,complement,16,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:16,security,compl,complement,16,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:60,security,token,tokenises,60,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,security,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:91,testability,simpl,simple,91,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:384,testability,integr,integrating,384,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:552,testability,hook,hook,552,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:91,usability,simpl,simple,91,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:287,usability,clear,clear,287,"Hi @pcanal,. to complement the answer of @bluehood"" TString tokenises, we are using here a simple lexer. @bluehood : the suggestion of treating names in strings to jit with a procedure similar to the one adopted for entities in files, ""dynamic scopes"", has not been forgotten. It is not clear to me how to put it in place though. On the other hand, this step goes in the direction of integrating more cling in the handling of ""code strings"". For example, if the strategy explored in this PR demonstrates to be reliable, we could potentially imagine to hook in the lexer used by clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3325:32,availability,failur,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3325:32,deployability,fail,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3325:32,performance,failur,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3325:32,reliability,fail,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3325:27,safety,test,test,27,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3325:27,testability,test,test,27,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3326:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3326:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3326:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3326:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3327:32,availability,failur,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:32,deployability,fail,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:32,performance,failur,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:32,reliability,fail,failures,32,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:27,safety,test,test,27,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:27,testability,test,test,27,"Merging, because dataframe test failures should be unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3329:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3329:6,availability,failur,failures,6,These failures are expected in this (old-ish) branch with distro packages.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3329:6,deployability,fail,failures,6,These failures are expected in this (old-ish) branch with distro packages.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3329:65,modifiability,pac,packages,65,These failures are expected in this (old-ish) branch with distro packages.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3329:6,performance,failur,failures,6,These failures are expected in this (old-ish) branch with distro packages.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3329:6,reliability,fail,failures,6,These failures are expected in this (old-ish) branch with distro packages.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3329
https://github.com/root-project/root/pull/3335:27,safety,review,review,27,Please do not merge before review by @pcanal,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3335:27,testability,review,review,27,Please do not merge before review by @pcanal,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3335:43,integrability,interfac,interface,43,doing the merge resolution through the git interface did not workout well :( ... . @bellenot Can you rebase this branch? Thanks,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3335:43,interoperability,interfac,interface,43,doing the merge resolution through the git interface did not workout well :( ... . @bellenot Can you rebase this branch? Thanks,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3335:43,modifiability,interfac,interface,43,doing the merge resolution through the git interface did not workout well :( ... . @bellenot Can you rebase this branch? Thanks,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3335:32,integrability,sub,submitted,32,@pcanal re-basing messed up. Re-submitted as #3388,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3335
https://github.com/root-project/root/pull/3337:150,availability,failur,failure,150,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:115,deployability,instal,install,115,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:150,deployability,fail,failure,150,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:300,deployability,instal,installed,300,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:150,performance,failur,failure,150,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:150,reliability,fail,failure,150,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:135,safety,avoid,avoid,135,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:145,safety,test,test,145,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:321,safety,test,tests,321,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:145,testability,test,test,145,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:321,testability,test,tests,321,"Hi Oksana, I think it's better to fix all at once in a single commit, and you probably have to tweak the temporary install location to avoid the test failure. Once that's fixed, it should be ok to merge. Please also check that `root -l -e '#include <Math/CladDerivator.h>'` works after ROOT has been installed, since the tests won't catch this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:164,deployability,build,build,164,"@amadio Bertrand helped me to fix Windows side (thanks a lot @bellenot ), tests are finally passing and `root -l -e '#include <Math/CladDerivator.h>` works both in build dir and install dir. I think it is good to go!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:178,deployability,instal,install,178,"@amadio Bertrand helped me to fix Windows side (thanks a lot @bellenot ), tests are finally passing and `root -l -e '#include <Math/CladDerivator.h>` works both in build dir and install dir. I think it is good to go!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:74,safety,test,tests,74,"@amadio Bertrand helped me to fix Windows side (thanks a lot @bellenot ), tests are finally passing and `root -l -e '#include <Math/CladDerivator.h>` works both in build dir and install dir. I think it is good to go!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:74,testability,test,tests,74,"@amadio Bertrand helped me to fix Windows side (thanks a lot @bellenot ), tests are finally passing and `root -l -e '#include <Math/CladDerivator.h>` works both in build dir and install dir. I think it is good to go!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:17,usability,help,helped,17,"@amadio Bertrand helped me to fix Windows side (thanks a lot @bellenot ), tests are finally passing and `root -l -e '#include <Math/CladDerivator.h>` works both in build dir and install dir. I think it is good to go!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:112,safety,review,review,112,"@Axel-Naumann we agreed with @amadio it is good to go. I would like to merge it, do you think I need additional review?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3337:112,testability,review,review,112,"@Axel-Naumann we agreed with @amadio it is good to go. I would like to merge it, do you think I need additional review?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3337
https://github.com/root-project/root/pull/3343:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3343
https://github.com/root-project/root/pull/3343:11,deployability,build,build,11,@phsft-bot build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3343
https://github.com/root-project/root/pull/3343:62,interoperability,conflict,conflicts,62,"Yes let's backport. Yuka, could you have a look at the rebase conflicts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3343
https://github.com/root-project/root/pull/3345:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3345:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3345:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos7-multicore/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3345:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3352:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:253,deployability,build,builds,253,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:368,deployability,upgrad,upgrade,368,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:396,deployability,version,version,396,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:433,deployability,instal,install,433,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:549,deployability,patch,patch,549,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:568,deployability,build,build,568,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:598,deployability,version,version,598,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:615,deployability,instal,installed,615,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:651,deployability,manag,manager,651,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:858,deployability,upgrad,upgrade,858,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:908,deployability,build,build,908,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:651,energy efficiency,manag,manager,651,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:733,energy efficiency,current,currently,733,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:334,integrability,event,event,334,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:396,integrability,version,version,396,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:598,integrability,version,version,598,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:368,modifiability,upgrad,upgrade,368,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:396,modifiability,version,version,396,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:598,modifiability,version,version,598,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:643,modifiability,pac,package,643,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:858,modifiability,upgrad,upgrade,858,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:801,performance,time,time,801,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:549,safety,patch,patch,549,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:651,safety,manag,manager,651,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:925,safety,prevent,prevent,925,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:549,security,patch,patch,549,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:925,security,preven,prevent,925,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3352:348,usability,user,users,348,"Hi Axel,. Thanks for following up with me. I am involved with 2 groups that still rely on v5.34 to run legacy code: the P-27 group at Los Alamos National Laboratory and the DRAGON group at TRIUMF. I have tried to be diligent with making sure that v5.34 builds properly with as many options enabled as possible on MacOS so that in the event our mac users are forced to upgrade to the latest MacOS version, they would still be able to install v5.34 and run the plethora of analysis codes written for v5 that both of these groups still work with. This patch is needed to build v5.34 on MacOS with the version of mysql installed with the homebrew package manager on MacOS Mojave. . It is also worth noting that the DRAGON DAQ machine is currently a mac, and will likely be replaced with a mac, so at some time in the foreseeable future, DRAGON will be forced to upgrade to the latest MacOS, and the inability to build v5.34 will prevent DRAGON from running its DAQ frontend and online analysis program.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3352
https://github.com/root-project/root/pull/3356:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3356
https://github.com/root-project/root/pull/3357:4,availability,failur,failures,4,"The failures are not related to my changes. I will merge and if any problem arises in the nightlies, I will revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3357
https://github.com/root-project/root/pull/3357:4,deployability,fail,failures,4,"The failures are not related to my changes. I will merge and if any problem arises in the nightlies, I will revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3357
https://github.com/root-project/root/pull/3357:4,performance,failur,failures,4,"The failures are not related to my changes. I will merge and if any problem arises in the nightlies, I will revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3357
https://github.com/root-project/root/pull/3357:4,reliability,fail,failures,4,"The failures are not related to my changes. I will merge and if any problem arises in the nightlies, I will revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3357
https://github.com/root-project/root/pull/3361:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3361:223,interoperability,compatib,compatible,223,"For the sake of (git) history, could you split this in two commits, one renaming `ROOT/RConfig.h` to `ROOT/RConfig.hxx` and and everything else (e.g. changing the `#include`s), and the other adding the forwarding, backward compatible `ROOT/RConfig.h`? This will allow `git` to realize that the history of `ROOT/RConfig.hxx` is that of `ROOT/RConfig.h` before the rename.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3361:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3362:76,deployability,patch,patch,76,@bellenot I finish refactoring of eve7 code. Now one can apply your Windows patch - after rebasing it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:19,modifiability,refact,refactoring,19,@bellenot I finish refactoring of eve7 code. Now one can apply your Windows patch - after rebasing it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:19,performance,refactor,refactoring,19,@bellenot I finish refactoring of eve7 code. Now one can apply your Windows patch - after rebasing it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:76,safety,patch,patch,76,@bellenot I finish refactoring of eve7 code. Now one can apply your Windows patch - after rebasing it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:76,security,patch,patch,76,@bellenot I finish refactoring of eve7 code. Now one can apply your Windows patch - after rebasing it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:6,interoperability,conflict,conflicts,6,"I got conflicts, so I close this PR and will open a new one",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3362:22,usability,close,close,22,"I got conflicts, so I close this PR and will open a new one",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3362
https://github.com/root-project/root/pull/3363:166,availability,redund,redundant,166,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3363:166,deployability,redundan,redundant,166,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3363:101,reliability,doe,does,101,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3363:166,reliability,redundan,redundant,166,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3363:166,safety,redund,redundant,166,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3363:152,testability,understand,understand,152,"@dpiparo #3364 , which includes these changes, has been merged, but at least the change in `Histo1D` does not seem to resolve the issue and as far as I understand is redundant, do you agree?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3365:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3365
https://github.com/root-project/root/pull/3365:61,safety,test,test,61,Made sturdier thanks to the suggestion of @pcanal and a unit test for TClassEdit,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3365
https://github.com/root-project/root/pull/3365:56,testability,unit,unit,56,Made sturdier thanks to the suggestion of @pcanal and a unit test for TClassEdit,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3365
https://github.com/root-project/root/pull/3365:61,testability,test,test,61,Made sturdier thanks to the suggestion of @pcanal and a unit test for TClassEdit,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3365
https://github.com/root-project/root/pull/3366:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3366
https://github.com/root-project/root/pull/3371:37,deployability,modul,modules,37,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:100,deployability,build,build,100,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:125,deployability,build,build,125,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:37,modifiability,modul,modules,37,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:192,performance,I/O,I/O,192,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:37,safety,modul,modules,37,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:176,security,expos,exposed,176,"Splitting `G__Core` is disallowed by modules: interdependent PCMs cannot be built, we would have to build only one. But that build would need all headers and `LinkDef.h` files exposed to have I/O annotations - which brings us back to a non-split `G__Core`. New PR without splitting `G__Core` is coming up...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3374:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:0,availability,Failur,Failures,0,Failures are unrelated to the changes proposed in PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:0,deployability,Fail,Failures,0,Failures are unrelated to the changes proposed in PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:0,performance,Failur,Failures,0,Failures are unrelated to the changes proposed in PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:0,reliability,Fail,Failures,0,Failures are unrelated to the changes proposed in PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3375:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3375
https://github.com/root-project/root/pull/3376:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3376
https://github.com/root-project/root/pull/3378:9,availability,error,error,9,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:9,performance,error,error,9,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:53,performance,lock,lock,53,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:9,safety,error,error,9,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:53,security,lock,lock,53,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:9,usability,error,error,9,"FYI, the error on Windows was due to the `.git/index.lock` file being present, and it has just been deleted.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:0,availability,error,error,0,error is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:0,performance,error,error,0,error is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:0,safety,error,error,0,error is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3378:0,usability,error,error,0,error is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3378
https://github.com/root-project/root/pull/3381:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:85,deployability,patch,patch,85,"I have a question, too... Doesn't `CMAKE_PREFIX_PATH` work without the need for this patch? Or setting `PKG_CONFIG_PATH` for that matter...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:26,reliability,Doe,Doesn,26,"I have a question, too... Doesn't `CMAKE_PREFIX_PATH` work without the need for this patch? Or setting `PKG_CONFIG_PATH` for that matter...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:85,safety,patch,patch,85,"I have a question, too... Doesn't `CMAKE_PREFIX_PATH` work without the need for this patch? Or setting `PKG_CONFIG_PATH` for that matter...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:85,security,patch,patch,85,"I have a question, too... Doesn't `CMAKE_PREFIX_PATH` work without the need for this patch? Or setting `PKG_CONFIG_PATH` for that matter...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:43,usability,help,help,43,"I'm not sure how `CMAKE_PREFIX_PATH` would help? The problem was that there were missing includes. If I'm reading [this](https://gitlab.kitware.com/cmake/cmake/merge_requests/1043) correctly, it looks like `LIBXML2_INCLUDE_DIRS` instead of `LIBXML2_INCLUDE_DIR`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:287,deployability,contain,contain,287,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:70,modifiability,variab,variable,70,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:368,modifiability,variab,variable,368,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:401,reliability,doe,does,401,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:714,testability,simpl,simple,714,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:497,usability,prefer,prefer,497,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:630,usability,support,support,630,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:714,usability,simpl,simple,714,"Further detail: Before CMake 3.10, `LIBXML2_INCLUDE_DIR` was the only variable. Then, after that, both are defined. `LIBXML2_INCLUDE_DIR` is just the libxml include directory, and `LIBXML2_INCLUDE_DIRS` is all the includes, including that one, that libxml needs. In some cases, this can contain extra required directories that are not otherwise picked up. If the DIRS variable is not defined, then it does not hurt to have it here, and listing the same directory twice is okay. I could do, if you prefer,. ```cmake. if(DEFINED LIBXML2_INCLUDE_DIRS). include_directories(${LIBXML2_INCLUDE_DIRS}). else(). # Remove when CMake <3.10 support is dropped. include_directories(${LIBXML2_INCLUDE_DIR}). endif(). ```. Less simple",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:52,deployability,patch,patch,52,"If this gets backported to 6.16.02, I'll remove the patch from conda-forge when it releases. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:83,deployability,releas,releases,83,"If this gets backported to 6.16.02, I'll remove the patch from conda-forge when it releases. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:52,safety,patch,patch,52,"If this gets backported to 6.16.02, I'll remove the patch from conda-forge when it releases. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3381:52,security,patch,patch,52,"If this gets backported to 6.16.02, I'll remove the patch from conda-forge when it releases. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3385:135,availability,cluster,cluster,135,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:135,deployability,cluster,cluster,135,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:89,energy efficiency,reduc,reduce,89,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:124,energy efficiency,reduc,reduce,124,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:328,energy efficiency,current,current,328,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:96,performance,memor,memory,96,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:209,performance,perform,performance,209,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:336,performance,bottleneck,bottleneck,336,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:551,performance,memor,memory,551,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:302,safety,reme,remembering,302,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:398,safety,input,input,398,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:437,safety,avoid,avoid,437,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:96,usability,memor,memory,96,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:209,usability,perform,performance,209,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:398,usability,input,input,398,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:526,usability,help,help,526,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:551,usability,memor,memory,551,"> We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage. Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...])",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:27,availability,cluster,cluster,27,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:356,availability,cluster,clusters,356,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:27,deployability,cluster,cluster,27,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:356,deployability,cluster,clusters,356,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:16,energy efficiency,reduc,reduce,16,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:452,energy efficiency,current,current,452,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:889,energy efficiency,profil,profiles,889,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:167,modifiability,reu,reuse,167,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:101,performance,perform,performance,101,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:460,performance,bottleneck,bottleneck,460,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:675,performance,memor,memory,675,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:751,performance,bottleneck,bottleneck,751,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:827,performance,disk,disk,827,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:889,performance,profil,profiles,889,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:910,performance,time,time,910,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:426,safety,reme,remembering,426,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:522,safety,input,input,522,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:561,safety,avoid,avoid,561,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:698,safety,test,test,698,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:698,testability,test,test,698,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1061,testability,context,context,1061,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:101,usability,perform,performance,101,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:522,usability,input,input,522,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:650,usability,help,help,650,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:675,usability,memor,memory,675,"> Wouldn't that reduce the cluster size and hence decrease compression ratio and likely overall read performance of the produced files? According to @Axel-Naumann, we reuse zlib dictionaries, so the whole file is a single stream, which means that this shouldn't be a problem. Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. > We may also want to speed up the merging process (if I am remembering correctly the current bottleneck is likely the uncompression and unstreaming of the input TTree, if we could find a way to avoid having to do that ... maybe 'just' not compressing the TTree in the TMemFile might help [yes at the cost of memory but ...]). This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:911,availability,cluster,clusters,911,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:979,availability,cluster,clusters,979,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1003,availability,cluster,clusters,1003,"test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I j",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1172,availability,cluster,clusters,1172,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:911,deployability,cluster,clusters,911,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:979,deployability,cluster,clusters,979,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1003,deployability,cluster,clusters,1003,"test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I j",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1172,deployability,cluster,clusters,1172,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:198,energy efficiency,profil,profiles,198,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1416,energy efficiency,reduc,reducing,1416,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1861,integrability,buffer,buffer,1861,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:703,modifiability,reu,reuse,703,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:60,performance,bottleneck,bottleneck,60,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:136,performance,disk,disk,136,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:198,performance,profil,profiles,198,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:219,performance,time,time,219,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:478,performance,memor,memory,478,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:524,performance,memor,memory,524,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:685,performance,disk,disk,685,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1321,performance,perform,performance,1321,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1355,performance,latenc,latency,1355,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1429,performance,memor,memory,1429,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1572,performance,time,times,1572,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1826,performance,memor,memory,1826,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:7,safety,test,test,7,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1486,security,loss,loss,1486,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:7,testability,test,test,7,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:370,testability,context,context,370,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1721,testability,context,context,1721,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2054,testability,context,context,2054,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:478,usability,memor,memory,478,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:524,usability,memor,memory,524,"> This test is with uncompressed data already. However, the bottleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1321,usability,perform,performance,1321,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1355,usability,latenc,latency,1355,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1429,usability,memor,memory,1429,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1826,usability,memor,memory,1826,"ttleneck is not the merging process. Merging can go as fast as the output disk can write, which is the fastest we can do. What I see in profiles is a lot of time being spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. I think we should focus on these parts first. Fair enough ; I had misunderstood where the memory mentioned in ""the total amount of used memory is still high since tasks are accumulating large chunks of data into the"" was located (and it is on the 'client/producer' side rather than the 'writer-to-disk' side). > we reuse zlib dictionaries, so the whole file is a single stream. Not that I know off. They are limited to each TBuffer/TBasket. > Nevertheless, this is dealing with data generation, so there are no pre-defined clusters. Yes and the chunking of the generation is determining the clusters size . Smaller clusters size means smaller basket which means smaller compression ratio (usually), smaller baskets also means more baskets which means more meta data (always). Smaller clusters means that the default TTreeCache size when reading the file will be smaler which means higher number of individual reads which means lower performance (especially over high latency links). Of course this is a trade-off; the gain from reducing the memory during the writing may offset the above mentioned loss but this is often challenging since the files are (usually) write once read many times. > spent creating and destroying task arenas for `TTree::Fill()`, as well as a lot of calculations of the pool size for the arenas and lots of context switches. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. Maybe we are creating too many TTree objects and we could re-use some of them or maybe the re-use I just mentioned is somehow not happening in this context?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:231,availability,cluster,clusters,231,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:322,availability,cluster,clusters,322,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:231,deployability,cluster,clusters,231,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:322,deployability,cluster,clusters,322,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:846,deployability,depend,depending,846,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1300,deployability,stack,stack,1300,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1740,energy efficiency,core,core,1740,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:846,integrability,depend,depending,846,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1062,integrability,buffer,buffer,1062,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:846,modifiability,depend,depending,846,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1122,modifiability,reu,reusing,1122,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:709,performance,memor,memory,709,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1027,performance,memor,memory,1027,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1130,performance,memor,memory,1130,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:846,safety,depend,depending,846,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:846,testability,depend,depending,846,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:709,usability,memor,memory,709,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1027,usability,memor,memory,1027,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1130,usability,memor,memory,1130,"> Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each `TBranch` is a single zlib stream when compressed with zlib. > Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the [auto-save option](https://github.com/root-project/root/blob/master/tree/dataframe/inc/ROOT/RSnapshotOptions.hxx#L35) in `RSnapshotOptions`. The problem is that the default is to not auto-save, but save only when calling `Write()`, which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call `Write()` depending on this setting, so in principle there's no need to increase the number of tasks. > This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The `TTree` is reusing memory chunks for the baskets, but the TBB task arenas that are created for each `TTree:Fill()` are not. They are created by a `TBranchIMTHelper` that is [created on the stack](https://github.com/root-project/root/blob/master/tree/tree/src/TTree.cxx#L4406) in `TTree::Fill()`. I had already noticed this before (see 5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57), but now `TBranchIMTHelper` creates a `TTaskGroup` [on the heap](https://github.com/root-project/root/blob/master/tree/tree/src/TBranchIMTHelper.h#L35), which then creates a TBB task arena [on the heap](https://github.com/root-project/root/blob/master/core/imt/src/TTaskGroup.cxx#L67) on every call to `TTree::Fill()`. This is a big problem in my opinion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:58,deployability,build,build,58,I'll merge this manually. This already passed the Jenkins build and I just changed a comment afterwards.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:33,modifiability,reu,reuse,33,"> According to @Axel-Naumann, we reuse zlib dictionaries. Just a precision: we don't, but we *want* to! :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1471,availability,cluster,cluster,1471,"ldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will sta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1805,availability,cluster,clusters,1805,"://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1896,availability,cluster,clusters,1896,"core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memor",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1471,deployability,cluster,cluster,1471,"ldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will sta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1805,deployability,cluster,clusters,1805,"://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1896,deployability,cluster,clusters,1896,"core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memor",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2615,deployability,depend,depending,2615," each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMyp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:3060,deployability,stack,stack,3060,"r_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2615,integrability,depend,depending,2615," each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMyp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2829,integrability,buffer,buffer,2829," increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2D",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2615,modifiability,depend,depending,2615," each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMyp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2887,modifiability,reu,reusing,2887,"Tree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1271,performance,memor,memory,1271,"ata. For the TBasket, yes we are investigating how to do it but it is not as easy nor as painless nor as 'cheap' as it might look. > but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2480,performance,memor,memory,2480,"ld be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2794,performance,memor,memory,2794,"ing the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2895,performance,memor,memory,2895,"usters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2615,safety,depend,depending,2615," each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMyp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:4493,safety,review,review,4493,"e_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. —. You are receiving this because your review was requested. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_pull_3385-23issuecomment-2D461313663&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=ww1eohY5pilHq7SNozwMmzPGOlWrzkLz0Qosc4RQifs&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AE73L1m0FrWqi-5F47CQLIh-2DOM2l0TbIajks5vK9TlgaJpZM4altU-5F&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=r2W6hjjLx2C3t-1JKmo-rFZVl9vPLVBKIl9KBigkLko&e=>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2615,testability,depend,depending,2615," each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMyp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:4493,testability,review,review,4493,"e_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. —. You are receiving this because your review was requested. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_pull_3385-23issuecomment-2D461313663&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=ww1eohY5pilHq7SNozwMmzPGOlWrzkLz0Qosc4RQifs&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AE73L1m0FrWqi-5F47CQLIh-2DOM2l0TbIajks5vK9TlgaJpZM4altU-5F&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=r2W6hjjLx2C3t-1JKmo-rFZVl9vPLVBKIl9KBigkLko&e=>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1271,usability,memor,memory,1271,"ata. For the TBasket, yes we are investigating how to do it but it is not as easy nor as painless nor as 'cheap' as it might look. > but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=MaH3q8Fk1VuE51JjPtjyEwT4SKZnDYMgA4ZLzN8hdS4&e=>, which then creates a TBB task arena on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_core_imt_src_TTaskGroup.cxx-23L67&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=FG0dQHcDrTCI43mlYwG1fvJuB7MdFKtSOo4TSE0HqUA&e=> on every call to TTree::Fill(). This is a big problem in my opinion. I agree ;). > which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. That might be 'easier' for the programming but really the trigger or flushing/creating-a-cluster should be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2480,usability,memor,memory,2480,"ld be on amount of data produced. Cheers,. Philippe. On 2/7/19 1:25 AM, Guilherme Amadio wrote:. Not that I know off. They are limited to each TBuffer/TBasket. Then we should try to fix that, so that each TBranch is a single zlib stream when compressed with zlib. Yes and the chunking of the generation is determining the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2794,usability,memor,memory,2794,"ing the clusters size. We wanted to increase the number of tasks based on that idea, but the TTree clusters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2895,usability,memor,memory,2895,"usters are not actually set by this. It is set by the auto-save option<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_dataframe_inc_ROOT_RSnapshotOptions.hxx-23L35&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=txfsLH9Ss0Rd1-_XgaCU94eGPUrmNZ7w20xQN3AMsyw&e=> in RSnapshotOptions. The problem is that the default is to not auto-save, but save only when calling Write(), which then happens only at the end of a full task that may generate lots of data that will stay in memory until the end. It's probably enough to make auto-save default to save at every 5-10% of generated data. We already call Write() depending on this setting, so in principle there's no need to increase the number of tasks. This is a bit surprising. The TTree is supposed to be re-using as much as possible the memory chunk (both the compression buffer and the TBuffer) as much as possible. The TTree is reusing memory chunks for the baskets, but the TBB task arenas that are created for each TTree:Fill() are not. They are created by a TBranchIMTHelper that is created on the stack<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TTree.cxx-23L4406&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=9vBGU4V_H1c-CBOJQ2AX0dDxhzuNM6Jn0jE9OHzgqgk&e=> in TTree::Fill(). I had already noticed this before (see 5ba88aa<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_commit_5ba88aa3bf2e0ffe222968f9b6f029bf8f4ead57&d=DwMFaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=UWfwI6PGOKY1hmtnuMh4_A&m=xs3jkKpmLeMypw1lXllSZjdULkrCzzEkzX8vpGMM9yc&s=uOitT8XpwlQYX0M2vv2NUsX5YNAjmRSblGEK8n7OjFk&e=>), but now TBranchIMTHelper creates a TTaskGroup on the heap<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_blob_master_tree_tree_src_TBranchIMTHelper.h-23L35&d=",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3386:67,integrability,repositor,repository,67,"As discussed by e-mail, this needs to be a PR to the cppyy-backend repository:. https://bitbucket.org/wlav/cppyy-backend",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3386:67,interoperability,repositor,repository,67,"As discussed by e-mail, this needs to be a PR to the cppyy-backend repository:. https://bitbucket.org/wlav/cppyy-backend",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3386:46,integrability,repositor,repository,46,@etejedor Can you create PR for cppyy-backend repository yourself?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3386:46,interoperability,repositor,repository,46,@etejedor Can you create PR for cppyy-backend repository yourself?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3386:25,deployability,continu,continue,25,"Thank you @linev , let's continue the discussion there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3386:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3386
https://github.com/root-project/root/pull/3392:135,safety,review,reviews,135,"> Actually, I prefer it that way if that’s possible. Looks like we need `no_undeclared_includes` to solve the same issue as in https://reviews.llvm.org/rL284797",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3392
https://github.com/root-project/root/pull/3392:135,testability,review,reviews,135,"> Actually, I prefer it that way if that’s possible. Looks like we need `no_undeclared_includes` to solve the same issue as in https://reviews.llvm.org/rL284797",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3392
https://github.com/root-project/root/pull/3392:14,usability,prefer,prefer,14,"> Actually, I prefer it that way if that’s possible. Looks like we need `no_undeclared_includes` to solve the same issue as in https://reviews.llvm.org/rL284797",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3392
https://github.com/root-project/root/pull/3394:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3394
https://github.com/root-project/root/pull/3395:92,modifiability,inherit,inherit,92,"The idea for later is to create the dictionary source after creating the library target (to inherit properties like include dirs, etc), and then use `target_sources()` to append the source file to the library target. However, it seems that this check only works if the dictionary is created before the library, so I think it should not be enabled by default.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3395
https://github.com/root-project/root/pull/3395:150,performance,perform,perform,150,"As explained above, we will move to creating the dictionary sources after the library, so this will unfortunately not work. We will think of a way to perform a similar check once the new system is in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3395
https://github.com/root-project/root/pull/3395:150,usability,perform,perform,150,"As explained above, we will move to creating the dictionary sources after the library, so this will unfortunately not work. We will think of a way to perform a similar check once the new system is in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3395
https://github.com/root-project/root/pull/3396:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:274,availability,error,errors,274,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:556,availability,error,error,556,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:577,availability,error,error,577,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:398,deployability,continu,continue,398,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:438,deployability,version,version,438,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:487,deployability,version,version,487,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:110,energy efficiency,load,loaded,110,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:179,energy efficiency,load,load,179,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:299,energy efficiency,load,loaded,299,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:633,energy efficiency,load,loaded,633,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:438,integrability,version,version,438,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:487,integrability,version,version,487,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:360,interoperability,compatib,compatible,360,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:429,interoperability,specif,specific,429,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:594,interoperability,incompatib,incompatible,594,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:89,modifiability,extens,extension,89,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:151,modifiability,extens,extension,151,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:438,modifiability,version,version,438,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:487,modifiability,version,version,487,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:110,performance,load,loaded,110,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:179,performance,load,load,179,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:274,performance,error,errors,274,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:299,performance,load,loaded,299,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:556,performance,error,error,556,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:577,performance,error,error,577,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:633,performance,load,loaded,633,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:274,safety,error,errors,274,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:556,safety,error,error,556,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:577,safety,error,error,577,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:274,usability,error,errors,274,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:460,usability,user,users,460,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:556,usability,error,error,556,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:577,usability,error,error,577,"I'm not quite convinced of this. From the link:. > The symbols will be resolved when the extension library is loaded into a Python binary. What is the extension library what will load the right Python library for ROOT? Also, how can you guarantee this won't generate silent errors if the ABI of the loaded library and the one ROOT built itself against are not compatible? ROOT should probably just continue to be built against a specific version of Python and users should stick to that version when using ROOT. I'm also afraid this will just delay a link error into a runtime error when wrong/incompatible libraries are tried to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:55,deployability,modul,modules-os-x,55,"See https://blog.tim-smith.us/2015/09/python-extension-modules-os-x/. I could be convinced otherwise, but this fixes a bad segfault in Python3 + ROOT on conda-forge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:45,modifiability,extens,extension-modules-os-x,45,"See https://blog.tim-smith.us/2015/09/python-extension-modules-os-x/. I could be convinced otherwise, but this fixes a bad segfault in Python3 + ROOT on conda-forge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:55,safety,modul,modules-os-x,55,"See https://blog.tim-smith.us/2015/09/python-extension-modules-os-x/. I could be convinced otherwise, but this fixes a bad segfault in Python3 + ROOT on conda-forge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:15,energy efficiency,load,loading,15,"This may break loading PyROOT *from* ROOT, however, since Python would also need to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:87,energy efficiency,load,loaded,87,"This may break loading PyROOT *from* ROOT, however, since Python would also need to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:15,performance,load,loading,15,"This may break loading PyROOT *from* ROOT, however, since Python would also need to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:87,performance,load,loaded,87,"This may break loading PyROOT *from* ROOT, however, since Python would also need to be loaded.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:56,deployability,patch,patch,56,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:448,deployability,version,version,448,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:464,deployability,build,build,464,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:48,energy efficiency,current,current,48,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:189,energy efficiency,load,loading,189,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:231,energy efficiency,load,load,231,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:551,energy efficiency,load,load,551,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:448,integrability,version,version,448,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:329,modifiability,pac,package,329,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:448,modifiability,version,version,448,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:519,modifiability,extens,extension,519,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:189,performance,load,loading,189,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:231,performance,load,load,231,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:551,performance,load,load,551,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:56,safety,patch,patch,56,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:56,security,patch,patch,56,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:254,usability,user,user,254,"Looking for general direction here. This is the current patch:. * Add a new hidden option, `ROOT_PYTHON_NO_LINK`, that turns off linking to Python. * This option also turns on a check when loading libraries, to manually attempt to load libpython for the user. The directory that libpython is in should be searched (it will be on package systems like conda). * The name of libpython is stored in RConfigure.h (since you need to know both the python version and the build flags to determine it). We could strip the final extension as it's not needed to load. Names, etc. can easily be changed if this looks like the right way to do it. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:11,deployability,build,build,11,@phsft-bot build with flags -DROOT_PYTHON_NO_LINK=TRUE,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:13,usability,close,close,13,I'm going to close this and open an issue in JIRA instead unless there are any objections.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:87,deployability,version,version,87,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:138,deployability,version,versions,138,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:388,energy efficiency,load,loaded,388,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:87,integrability,version,version,87,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:138,integrability,version,versions,138,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:151,interoperability,compatib,compatible,151,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:87,modifiability,version,version,87,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:138,modifiability,version,versions,138,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:388,performance,load,loaded,388,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:254,testability,understand,understand,254,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:45,usability,support,support,45,"Sounds good. I think it will be nice to have support in ROOT to use a different Python version than it was compiled against, provided the versions are compatible. Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:126,deployability,version,version,126,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:219,deployability,version,versions,219,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:151,energy efficiency,reduc,reduce,151,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:126,integrability,version,version,126,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:219,integrability,version,versions,219,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:126,modifiability,version,version,126,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:219,modifiability,version,versions,219,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:195,usability,support,support,195,"Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:39,deployability,version,versions,39,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:118,deployability,version,version,118,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:162,deployability,version,versions,162,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:177,deployability,contain,contains,177,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:212,energy efficiency,current,current,212,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:39,integrability,version,versions,39,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:118,integrability,version,version,118,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:162,integrability,version,versions,162,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:39,modifiability,version,versions,39,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:118,modifiability,version,version,118,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:162,modifiability,version,versions,162,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:126,performance,lock,locked,126,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:126,security,lock,locked,126,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:19,usability,support,supporting,19,"Okay, I would love supporting multiple versions for places like Homebrew, but for the Conda work I'm doing now, it is version locked (if you have multiple python versions, each contains its own copy of ROOT). My current interest is just getting to work with a single statically linked Python + a single libpythonX.dylib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:307,deployability,modul,modules,307,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:443,deployability,API,APIs,443,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:456,deployability,version,versions,456,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:483,deployability,version,versions,483,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:227,energy efficiency,load,loaded,227,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:357,integrability,interfac,interface,357,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:443,integrability,API,APIs,443,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:456,integrability,version,versions,456,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:483,integrability,version,versions,483,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:357,interoperability,interfac,interface,357,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:443,interoperability,API,APIs,443,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:297,modifiability,extens,extension,297,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:307,modifiability,modul,modules,307,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:357,modifiability,interfac,interface,357,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:456,modifiability,version,versions,456,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:483,modifiability,version,versions,483,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:227,performance,load,loaded,227,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:307,safety,modul,modules,307,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:93,testability,understand,understand,93,"> Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:128,deployability,version,version,128,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:221,deployability,version,versions,221,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:259,deployability,build,build,259,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:286,deployability,version,versions,286,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:432,deployability,version,versions,432,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:548,deployability,version,version,548,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:648,deployability,version,versions,648,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:153,energy efficiency,reduc,reduce,153,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:484,energy efficiency,Load,Load,484,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:128,integrability,version,version,128,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:221,integrability,version,versions,221,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:286,integrability,version,versions,286,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:432,integrability,version,versions,432,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:548,integrability,version,version,548,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:648,integrability,version,versions,648,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:128,modifiability,version,version,128,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:221,modifiability,version,versions,221,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:286,modifiability,version,versions,286,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:432,modifiability,version,versions,432,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:548,modifiability,version,version,548,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:648,modifiability,version,versions,648,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:484,performance,Load,Load,484,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:319,security,hack,hack,319,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:406,security,access,accessing,406,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:197,usability,support,support,197,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:398,usability,support,support,398,"> Just had a quick look, and I think that we have too many `#if PY_VERSION_HEX ...` to make ROOT work with more than one Python version. We will need to reduce those or use a different strategy to support multiple Python versions. I think using a single ROOT build from multiple python versions [is already possible to hack in](https://github.com/willsALMANJ/pyroot_link_to_binary). It's harder to support accessing multiple Python versions from C++ (i.e. `TPython`). Could `gSystem->Load(""..."")` be used to replace `libPyROOT.so` with a different version like `libPyROOT37.so`? Or are there differences in the `libPyROOT` ABI for different Python versions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:315,deployability,modul,modules,315,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:451,deployability,API,APIs,451,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:464,deployability,version,versions,464,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:491,deployability,version,versions,491,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:229,energy efficiency,load,loaded,229,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:365,integrability,interfac,interface,365,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:451,integrability,API,APIs,451,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:464,integrability,version,versions,464,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:491,integrability,version,versions,491,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:365,interoperability,interfac,interface,365,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:451,interoperability,API,APIs,451,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:305,modifiability,extens,extension,305,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:315,modifiability,modul,modules,315,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:365,modifiability,interfac,interface,365,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:464,modifiability,version,versions,464,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:491,modifiability,version,versions,491,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:229,performance,load,loaded,229,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:315,safety,modul,modules,315,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:95,testability,understand,understand,95,"> > Or even make a single libPyROOT work both with Python 2.x and 3.x if possible. As far as I understand, that should be possible too if we don't link directly to the Python library, but let symbols be resolved from the already loaded Python interpreter. > . > I don't think that is even possible, since extension modules like libPyROOT need to define a different interface for Python2 and Python3. Moreover, there are differences also in the Python APIs between versions (even between 3.X versions) that also impose those `#if`s in our PyROOT code. If the differences are only symbol names, then providing both symbols should be ok if we're not linking to Python. If the implementation needs to change, we can get rid of all the `#if PY_VERSION_HEX ...` by replacing them with a regular `if (Py_GetVersion() ...)`, which is computed at runtime.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:105,energy efficiency,power,powerful,105,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:200,energy efficiency,load,load,200,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:248,energy efficiency,load,loading,248,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:200,performance,load,load,200,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:248,performance,load,loading,248,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:63,safety,avoid,avoids,63,This change could be quite interesting; a proper solution that avoids the link everywhere could be quite powerful if combined with runtime checks. The biggest issue is probably that ROOT will need to load (and potentially pick?) a pythonlib before loading PyROOT and PyMVA.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:279,availability,avail,available,279,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:18,energy efficiency,Load,Load,18,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:82,energy efficiency,load,load,82,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:134,energy efficiency,load,load,134,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:247,energy efficiency,load,load,247,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:18,performance,Load,Load,18,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:82,performance,load,load,82,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:134,performance,load,load,134,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:247,performance,load,load,247,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:279,reliability,availab,available,279,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:279,safety,avail,available,279,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:198,security,hack,hacky,198,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:279,security,availab,available,279,"> Could `gSystem->Load(""..."")` be used... Could libPyROOT be the unlinked one you load from Python, and libPyROOT37, etc. be ones you load from ROOT and are linked to a particular Python? Then the ""hacky"" part would just be replacing a request to load libPyROOT with the largest available libPyROOTXX.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:339,interoperability,share,shared,339,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:322,modifiability,extens,extension,322,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:473,modifiability,extens,extension,473,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:384,reliability,doe,does,384,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:26,safety,review,review,26,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:26,testability,review,review,26,"Two things:. - this needs review by @etejedor . - please do not create a problem for `root [0] TPython::`... If this is really needed (I question the relevance of the use cases, given that we have never ever heard / seen of this issue for what - 20 years of PyROOT?) then please consider the following:. - have the python-extension in one shared library, that according to your needs does not link to libpython. - have libPyROOT link against libpython and the above python extension library. IIUC that's what experimental PyROOT is doing, but @etejedor knows better. Alternatively, and IIUC, we could just fix the link line for libPyROOT and not link both statically and dynamically?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:35,safety,review,reviewed,35,"""do-not-merge"" until @etejedor has reviewed, please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:35,testability,review,reviewed,35,"""do-not-merge"" until @etejedor has reviewed, please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:6,deployability,continu,continue,6,Let's continue the discussion in the JIRA issue that @henryiii opened. @dpiparo already posted what we just discussed with him and @amadio .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3402:11,deployability,build,build,11,@phsft-bot build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3402
https://github.com/root-project/root/pull/3402:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3402
https://github.com/root-project/root/pull/3402:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3402
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:22,deployability,modul,modules,22,I think it is good on modules side as long as the tests passes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:22,modifiability,modul,modules,22,I think it is good on modules side as long as the tests passes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:22,safety,modul,modules,22,I think it is good on modules side as long as the tests passes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:50,safety,test,tests,50,I think it is good on modules side as long as the tests passes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:50,testability,test,tests,50,I think it is good on modules side as long as the tests passes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:107,availability,failur,failure,107,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:107,deployability,fail,failure,107,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:107,performance,failur,failure,107,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:107,reliability,fail,failure,107,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:102,safety,test,test,102,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:102,testability,test,test,102,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -Dctest_test_exclude_none=On. because that test failure was due to a stale old file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:11,deployability,build,build,11,@phsft-bot build just on mac1014/cxx17 with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3405:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:160,availability,error,error,160,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:2,deployability,Build,Build,2,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:8,deployability,fail,failed,8,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:112,deployability,build,build,112,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:166,deployability,log,logs,166,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:176,deployability,build,building,176,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:160,performance,error,error,160,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:8,reliability,fail,failed,8,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:160,safety,error,error,160,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:166,safety,log,logs,166,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:225,safety,permiss,permission,225,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:166,security,log,logs,166,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:166,testability,log,logs,166,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:160,usability,error,error,160,> Build failed on windows10/default. > [See console output](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/53471/console). Could someone show me the error logs when building on Windows? (I do not have the relevant permission),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:910,availability,Error,Error,910,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1044,availability,error,error,1044,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:219,deployability,build,build,219,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:253,deployability,build,build,253,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:296,deployability,Build,BuildDirectory,296,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:314,deployability,build,build,314,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:348,deployability,build,build,348,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:354,deployability,build,build,354,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:439,deployability,build,build,439,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:473,deployability,build,build,473,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:494,deployability,Build,Build,494,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:514,deployability,build,build,514,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:548,deployability,build,build,548,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:554,deployability,build,build,554,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:685,deployability,build,build,685,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:719,deployability,build,build,719,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:820,deployability,build,build,820,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:854,deployability,build,build,854,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:887,deployability,fail,failed,887,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:922,deployability,build,build,922,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:956,deployability,build,build,956,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:983,deployability,build,build,983,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:389,energy efficiency,model,model,389,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:606,performance,perform,perform,606,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:786,performance,Perform,Perform,786,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:910,performance,Error,Error,910,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1044,performance,error,error,1044,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:3,reliability,Pra,Pratyush,3,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:887,reliability,fail,failed,887,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:910,safety,Error,Error,910,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1044,safety,error,error,1044,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:389,security,model,model,389,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:69,usability,help,help,69,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:116,usability,User,Username,116,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:606,usability,perform,perform,606,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:786,usability,Perform,Perform,786,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:910,usability,Error,Error,910,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1044,usability,error,error,1044,"Hi Pratyush, . I am not sure what happened here, maybe @bellenot can help you here? `22:02:36 fatal: could not read Username for 'https://github.com': Invalid argument. 22:02:36 SetCTestConfiguration:SourceDirectory:C:/build/workspace/root-pullrequests-build/root. 22:02:36 SetCTestConfiguration:BuildDirectory:C:/build/workspace/root-pullrequests-build/build. 22:02:36 Run dashboard with model Pullrequests. 22:02:36 Source directory: C:/build/workspace/root-pullrequests-build/root. 22:02:36 Build directory: C:/build/workspace/root-pullrequests-build/build. 22:02:36 Track: Pullrequests. 22:02:36 First perform the initial checkout: C:/Program Files/CMake/bin/cmake.exe -E chdir C:/build/workspace/root-pullrequests-build/root C:/Program Files/Git/cmd/git.exe checkout -f . 22:02:36 Perform checkout in directory: C:/build/workspace/root-pullrequests-build. 22:02:36 Initial checkout failed! 22:02:36 CMake Error at C:/build/workspace/root-pullrequests-build/rootspi/jenkins/root-build.cmake:803 (ctest_start):. 22:02:36 ctest_start unknown error. `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:135,availability,error,errors,135,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:8,deployability,build,build,8,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:135,performance,error,errors,135,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:243,performance,time,time,243,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:135,safety,error,errors,135,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:135,usability,error,errors,135,"No, the build bot looks for a fork of roottest in your account to possibly take a matching branch and use for the pull request, but it errors out if you don't have roottest forked. @vgvassilev you may want to have a look at this when you have time. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:49,energy efficiency,adapt,adapted,49,Could you please leave a note where you copied / adapted this code from?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:49,integrability,adapt,adapted,49,Could you please leave a note where you copied / adapted this code from?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:49,interoperability,adapt,adapted,49,Could you please leave a note where you copied / adapted this code from?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:49,modifiability,adapt,adapted,49,Could you please leave a note where you copied / adapted this code from?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:352,deployability,build,build,352,"We could also tell people this (which is shown in the FAQ as well):. > Instead of creating an ""uninstall"" target, Unix users could enter this command in the shell:. ```sh. xargs rm < install_manifest.txt. ```. I think that having the uninstall target makes us liable if users end up deleting important files with `make uninstall`. For example, you may build ROOT with the default prefix `/usr/local`, and then inadvertently call only `make uninstall`, which may irreparably break, e.g., on Mac OS a ROOT that has been installed with Homebrew. @Axel-Naumann, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:518,deployability,instal,installed,518,"We could also tell people this (which is shown in the FAQ as well):. > Instead of creating an ""uninstall"" target, Unix users could enter this command in the shell:. ```sh. xargs rm < install_manifest.txt. ```. I think that having the uninstall target makes us liable if users end up deleting important files with `make uninstall`. For example, you may build ROOT with the default prefix `/usr/local`, and then inadvertently call only `make uninstall`, which may irreparably break, e.g., on Mac OS a ROOT that has been installed with Homebrew. @Axel-Naumann, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:119,usability,user,users,119,"We could also tell people this (which is shown in the FAQ as well):. > Instead of creating an ""uninstall"" target, Unix users could enter this command in the shell:. ```sh. xargs rm < install_manifest.txt. ```. I think that having the uninstall target makes us liable if users end up deleting important files with `make uninstall`. For example, you may build ROOT with the default prefix `/usr/local`, and then inadvertently call only `make uninstall`, which may irreparably break, e.g., on Mac OS a ROOT that has been installed with Homebrew. @Axel-Naumann, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:142,usability,command,command,142,"We could also tell people this (which is shown in the FAQ as well):. > Instead of creating an ""uninstall"" target, Unix users could enter this command in the shell:. ```sh. xargs rm < install_manifest.txt. ```. I think that having the uninstall target makes us liable if users end up deleting important files with `make uninstall`. For example, you may build ROOT with the default prefix `/usr/local`, and then inadvertently call only `make uninstall`, which may irreparably break, e.g., on Mac OS a ROOT that has been installed with Homebrew. @Axel-Naumann, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:270,usability,user,users,270,"We could also tell people this (which is shown in the FAQ as well):. > Instead of creating an ""uninstall"" target, Unix users could enter this command in the shell:. ```sh. xargs rm < install_manifest.txt. ```. I think that having the uninstall target makes us liable if users end up deleting important files with `make uninstall`. For example, you may build ROOT with the default prefix `/usr/local`, and then inadvertently call only `make uninstall`, which may irreparably break, e.g., on Mac OS a ROOT that has been installed with Homebrew. @Axel-Naumann, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:132,deployability,instal,install,132,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:158,deployability,instal,install,158,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:192,deployability,instal,install,192,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:347,deployability,instal,install,347,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:373,deployability,version,versions,373,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:401,deployability,instal,install,401,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:423,deployability,instal,installing,423,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:500,deployability,instal,installed,500,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:572,deployability,instal,install,572,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:613,deployability,manag,manager,613,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:643,deployability,manag,manager,643,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:665,deployability,Instal,Installing,665,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:687,deployability,instal,install,687,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:734,deployability,instal,installation,734,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:762,deployability,manag,manager,762,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:885,deployability,configurat,configuration,885,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1027,deployability,instal,install,1027,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1102,deployability,depend,depending,1102,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:613,energy efficiency,manag,manager,613,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:643,energy efficiency,manag,manager,643,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:762,energy efficiency,manag,manager,762,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:373,integrability,version,versions,373,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:885,integrability,configur,configuration,885,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1102,integrability,depend,depending,1102,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:373,modifiability,version,versions,373,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:605,modifiability,pac,package,605,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:635,modifiability,pac,package,635,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:754,modifiability,pac,package,754,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:885,modifiability,configur,configuration,885,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1093,modifiability,pac,packages,1093,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1102,modifiability,depend,depending,1102,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:48,performance,time,times,48,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:613,safety,manag,manager,613,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:643,safety,manag,manager,643,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:762,safety,manag,manager,762,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1102,safety,depend,depending,1102,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:885,security,configur,configuration,885,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:1102,testability,depend,depending,1102,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:698,usability,custom,custom,698,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:833,usability,help,help,833,"I recommend not sourcing `thisroot.sh` multiple times in the same shell. That will mess up your environment. This is not related to install/uninstall. If you install ROOT somewhere with `make install`, just add `<prefix>/bin` to your `$PATH` and `<prefix>/lib` to your `$PYTHONPATH` and you should never need to `source thisroot.sh`. Also, if you install your own multiple versions of ROOT with `make install`, I recommend installing into an empty directory, not `/usr/local` where Homebrew may have installed it. Then you can just `rm -rf` if needed to uninstall. If you install into `/usr/local` with a package manager, just use the package manager to uninstall. Installing with `make install` a custom ROOT that overwrites another installation with a package manager is going to get you into trouble and `make uninstall` will not help much. With the uninstall target, if you change configuration before uninstalling, you may have half-uninstalled ROOT left over (e.g by enabling/disabling `pyroot_experimental` between make install/make uninstall), or may remove important files from other packages depending on what builtins you had enabled when you built ROOT. CMake has this disabled by default for this reason, and I'm reluctant to provide this uninstall target in ROOT for the same reason.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:160,availability,down,download,160,"...plus ""many of us"" recommend to simply not do `make install`, but use ROOT right where it was built, or better yet grab a binary build from https://root.cern/download/nightly/ and untar it. As Guilherme says: if you want to get rid of that, just `rm -rf`, done!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:54,deployability,instal,install,54,"...plus ""many of us"" recommend to simply not do `make install`, but use ROOT right where it was built, or better yet grab a binary build from https://root.cern/download/nightly/ and untar it. As Guilherme says: if you want to get rid of that, just `rm -rf`, done!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:131,deployability,build,build,131,"...plus ""many of us"" recommend to simply not do `make install`, but use ROOT right where it was built, or better yet grab a binary build from https://root.cern/download/nightly/ and untar it. As Guilherme says: if you want to get rid of that, just `rm -rf`, done!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:34,testability,simpl,simply,34,"...plus ""many of us"" recommend to simply not do `make install`, but use ROOT right where it was built, or better yet grab a binary build from https://root.cern/download/nightly/ and untar it. As Guilherme says: if you want to get rid of that, just `rm -rf`, done!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:34,usability,simpl,simply,34,"...plus ""many of us"" recommend to simply not do `make install`, but use ROOT right where it was built, or better yet grab a binary build from https://root.cern/download/nightly/ and untar it. As Guilherme says: if you want to get rid of that, just `rm -rf`, done!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:60,deployability,build,building-root,60,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:124,deployability,instal,install,124,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:156,deployability,build,build,156,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:194,deployability,instal,install,194,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:361,deployability,instal,install,361,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:337,reliability,doe,does,337,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3405:88,usability,prefer,preferred,88,Would it be possible to mention on the https://root.cern.ch/building-root page that the preferred method is to not do `make install` but to use it from the build directory(or that one shouldn't install it in /usr/local but in an empty directory)? And also that `xargs rm < install_manifest.txt` is the way to remove the files if someone does decide to do `make install` ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3406:32,safety,compl,complicated,32,Well this turned out to be more complicated than expected,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3406
https://github.com/root-project/root/pull/3406:32,security,compl,complicated,32,Well this turned out to be more complicated than expected,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3406
https://github.com/root-project/root/pull/3407:9,availability,failur,failures,9,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:22,availability,error,errors,22,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:9,deployability,fail,failures,9,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:9,performance,failur,failures,9,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:22,performance,error,errors,22,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:9,reliability,fail,failures,9,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:4,safety,test,test,4,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:22,safety,error,errors,22,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:4,testability,test,test,4,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:22,usability,error,errors,22,The test failures are errors that were previously silent and are there at least since the switch to lexertk. Not sure what to do about them.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3408:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3408
https://github.com/root-project/root/pull/3409:11,deployability,build,build,11,@phsft-bot build just on mac1014/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:11,deployability,build,build,11,@phsft-bot build just on mac1014/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:207,deployability,configurat,configuration,207,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:207,integrability,configur,configuration,207,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:68,modifiability,variab,variables,68,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:207,modifiability,configur,configuration,207,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:102,performance,cach,cache,102,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:7,safety,test,test,7,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:207,security,configur,configuration,207,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:7,testability,test,test,7,Please test changing options in CMake that change the values of the variables that you now set in the cache. I suspect that calling cmake later to change options (i.e. enabling/disabling root7 after initial configuration) might not work after these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:27,integrability,messag,message,27,"@amadio sorry, I lost your message and yes, I tested it works fine (even in case of root7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:27,interoperability,messag,message,27,"@amadio sorry, I lost your message and yes, I tested it works fine (even in case of root7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:46,safety,test,tested,46,"@amadio sorry, I lost your message and yes, I tested it works fine (even in case of root7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:46,testability,test,tested,46,"@amadio sorry, I lost your message and yes, I tested it works fine (even in case of root7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3409:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3409
https://github.com/root-project/root/pull/3410:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3410
https://github.com/root-project/root/pull/3411:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3411
https://github.com/root-project/root/pull/3411:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3411
https://github.com/root-project/root/pull/3413:28,safety,review,review,28,@Axel-Naumann might want to review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:28,testability,review,review,28,@Axel-Naumann might want to review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:11,deployability,build,build,11,"@phsft-bot build, please",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:52,deployability,patch,patches,52,Is this a candidate for 6.16.02 as well? I'm naming patches in the conda recipe based on when they will be no longer needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:52,safety,patch,patches,52,Is this a candidate for 6.16.02 as well? I'm naming patches in the conda recipe based on when they will be no longer needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:52,security,patch,patches,52,Is this a candidate for 6.16.02 as well? I'm naming patches in the conda recipe based on when they will be no longer needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:38,deployability,patch,patches,38,"I've manually merged it into v6-16-00-patches; this will be part of a future v6.16/02. Thanks for your contribution, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:38,safety,patch,patches,38,"I've manually merged it into v6-16-00-patches; this will be part of a future v6.16/02. Thanks for your contribution, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3413:38,security,patch,patches,38,"I've manually merged it into v6-16-00-patches; this will be part of a future v6.16/02. Thanks for your contribution, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3414:162,usability,help,help,162,"Hi, Thanks for the PR! Could you elaborate on your usecase where you find this change beneficial and show us a small code sample where this is useful? This would help evaluating the PR :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:203,energy efficiency,Optim,OptimizeAllMethods,203,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:320,energy efficiency,Optim,OptimizeAllMethods,320,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:659,energy efficiency,Optim,OptimizeAllMethods,659,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:53,modifiability,paramet,parameters,53,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:203,performance,Optimiz,OptimizeAllMethods,203,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:320,performance,Optimiz,OptimizeAllMethods,320,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:384,performance,perform,performance,384,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:659,performance,Optimiz,OptimizeAllMethods,659,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:736,safety,test,tested,736,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:745,safety,Test,Test,745,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:1085,safety,Test,Test,1085,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:736,testability,test,tested,736,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:745,testability,Test,Test,745,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:1085,testability,Test,Test,1085,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:14,usability,tool,tool,14,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:384,usability,perform,performance,384,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:629,usability,user,users,629,"Hi,. The TMVA tool set has functionality to scan the parameters for boosted decision trees. In the tutorial: https://root.cern.ch/doc/v614/TMVAClassification_8C.html one can uncomment line . // factory->OptimizeAllMethods(""SigEffAt001"",""Scan"");. Infact, while I look at this tutorial, the line should read:. // factory->OptimizeAllMethods(""SigEffAtBkgEff001"",""Scan"");. To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:. // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");. The string handling can be tested:. Test 0.1% without decimal:. root [0] TString fFOMType=""SigEffAtBkgEff0001"" //Set at 0.1%. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof())); //extract number. root [2] if (!percent.CountChar('.')) percent.Insert(1,"".""); //If there isnt a decimal point add it. root [3] percent.Atof() //Get the result. (double) 0.0010000000. Test 0.1% with decimal point:. root [0] TString fFOMType=""SigEffAtBkgEff0.001"". (TString &) ""SigEffAtBkgEff0.001""[19]. root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.0010000000. Try the 10% case:. root [0] TString fFOMType=""SigEffAtBkgEff01"". root [1] TString percent=TString(fFOMType(14,fFOMType.Sizeof()));. root [2] if (!percent.CountChar('.')) percent.Insert(1,""."");. root [3] percent.Atof(). (double) 0.10000000.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:44,availability,sli,slightly,44,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:64,deployability,version,version,64,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:301,deployability,continu,continue,301,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:64,integrability,version,version,64,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:64,modifiability,version,version,64,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:44,reliability,sli,slightly,44,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:245,safety,test,testing,245,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:245,testability,test,testing,245,Thanks for the contribution! There is now a slightly cleaned up version of this ([PR#3493](https://github.com/root-project/root/pull/3493)). (Your commits are still part of that PR ;). The main reason for creating a new PR was that the required testing code was a bit involved in getting right. Let's continue the discussion there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3415:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3415
https://github.com/root-project/root/pull/3415:106,deployability,build,build,106,"Thank you @stwunsch , it is great that this has already been merged into Cppyy. Let's see what the Ubuntu build says with PyROOT experimental and we can merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3415
https://github.com/root-project/root/pull/3416:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3416
https://github.com/root-project/root/pull/3416:73,integrability,rout,routines,73,superseeded by the new tutorial taking advantage of the mass calculation routines,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3416
https://github.com/root-project/root/pull/3420:54,integrability,event,eventual,54,Can you enter a JIRA task to keep track of this leak [eventual resolution]?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3420
https://github.com/root-project/root/pull/3420:56,integrability,event,eventual,56,"> Can you enter a JIRA task to keep track of this leak [eventual resolution]? Sure, that was the plan. ROOT-9955.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3420
https://github.com/root-project/root/pull/3420:97,testability,plan,plan,97,"> Can you enter a JIRA task to keep track of this leak [eventual resolution]? Sure, that was the plan. ROOT-9955.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3420
https://github.com/root-project/root/pull/3424:206,reliability,doe,does,206,I'm also not 100% happy with the name. I put the `Make` in front since it is a factory and fits the STL language. Your proposal looks fine to me though it's still not completely clear (by the name) what it does.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:167,safety,compl,completely,167,I'm also not 100% happy with the name. I put the `Make` in front since it is a factory and fits the STL language. Your proposal looks fine to me though it's still not completely clear (by the name) what it does.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:167,security,compl,completely,167,I'm also not 100% happy with the name. I put the `Make` in front since it is a factory and fits the STL language. Your proposal looks fine to me though it's still not completely clear (by the name) what it does.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:178,usability,clear,clear,178,I'm also not 100% happy with the name. I put the `Make` in front since it is a factory and fits the STL language. Your proposal looks fine to me though it's still not completely clear (by the name) what it does.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:122,reliability,doe,does,122,"Alternatively: it might be an uglier pythonization, but this might just be a constructor ""overload"" (unfortunately python does not believe in overloading):. ```python. df = ROOT.ROOT.RDataFrame(data). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:17,usability,prefer,prefer,17,I would actually prefer the constructor overload. Unfortunately it's not yet clear to me how this could be done...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:77,usability,clear,clear,77,I would actually prefer the constructor overload. Unfortunately it's not yet clear to me how this could be done...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:48,safety,reme,remember,48,We need to check how cppyy handles the ctors. I remember there some weirdness...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:156,integrability,inject,injected,156,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:251,integrability,inject,inject,251,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:100,interoperability,prox,proxies,100,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:174,interoperability,prox,proxies,174,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:156,security,inject,injected,156,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:251,security,inject,inject,251,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:64,usability,custom,customization,64,"I also thought that Cppyy was handling the construction via the customization of `tp_call` in class proxies, but it turns out there is an `__init__` method injected in class proxies (which is a `CPPOverload`). So in principle it should be possible to inject a pythonisation such as the one Enrico proposed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3426:60,deployability,version,version,60,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:118,deployability,version,version,118,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:146,deployability,version,version,146,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:199,deployability,version,version,199,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:60,integrability,version,version,60,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:118,integrability,version,version,118,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:146,integrability,version,version,146,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:199,integrability,version,version,199,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:278,integrability,interfac,interface,278,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:278,interoperability,interfac,interface,278,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:60,modifiability,version,version,60,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:118,modifiability,version,version,118,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:146,modifiability,version,version,146,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:199,modifiability,version,version,199,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:278,modifiability,interfac,interface,278,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:18,safety,test,tests,18,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:254,safety,test,testing,254,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:18,testability,test,tests,18,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:254,testability,test,testing,254,"> Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Since the compiled version is (presummably) faster than the interpreted version, should we do the reverse or do you think that testing the interpreted interface is also essential?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:51,deployability,version,version,51,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:51,integrability,version,version,51,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:51,modifiability,version,version,51,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:165,performance,execution time,execution times,165,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:27,safety,test,testing,27,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:80,safety,test,testing,80,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:136,safety,test,testing,136,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:27,testability,test,testing,27,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:70,testability,coverag,coverage,70,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:80,testability,test,testing,80,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:136,testability,test,testing,136,@lmoneta and I agreed that testing the interpreted version gives more coverage (testing feature X + interpreter) than the compiled one (testing only feature X). The execution times are very similar.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3427:32,safety,test,test,32,@phsft-bot Nice bot! Anyone can test it. I just put a missing part in.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:32,testability,test,test,32,@phsft-bot Nice bot! Anyone can test it. I just put a missing part in.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:11,deployability,build,build,11,@phsft-bot build! Looks like it doesn't work for me :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:32,reliability,doe,doesn,32,@phsft-bot build! Looks like it doesn't work for me :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:30,safety,review,review,30,Grate! Now we should wait for review of Lorenzo @lmoneta - hope he can merge your changes soon,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:30,testability,review,review,30,Grate! Now we should wait for review of Lorenzo @lmoneta - hope he can merge your changes soon,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3427:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3428:58,safety,test,test,58,"Hi @ktf , thanks for finding+fixing the problem. Could we test this usecase in ROOT, so we are sure to not break it in the future?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:58,testability,test,test,58,"Hi @ktf , thanks for finding+fixing the problem. Could we test this usecase in ROOT, so we are sure to not break it in the future?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:226,integrability,pub,public,226,"Yes, sure, but the easiest way to do this is that we agree on how to proceed with:. https://github.com/AliceO2Group/AliceO2/pull/1701. I am not sure it's possible to expose the issue right now without doing a `#define private public` in the test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:241,safety,test,test,241,"Yes, sure, but the easiest way to do this is that we agree on how to proceed with:. https://github.com/AliceO2Group/AliceO2/pull/1701. I am not sure it's possible to expose the issue right now without doing a `#define private public` in the test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:166,security,expos,expose,166,"Yes, sure, but the easiest way to do this is that we agree on how to proceed with:. https://github.com/AliceO2Group/AliceO2/pull/1701. I am not sure it's possible to expose the issue right now without doing a `#define private public` in the test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:241,testability,test,test,241,"Yes, sure, but the easiest way to do this is that we agree on how to proceed with:. https://github.com/AliceO2Group/AliceO2/pull/1701. I am not sure it's possible to expose the issue right now without doing a `#define private public` in the test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:20,modifiability,layer,layer,20,@ktf could an extra layer of inheritance help circumventing the `protected` access in your case? See https://godbolt.org/z/o5X_r-,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:29,modifiability,inherit,inheritance,29,@ktf could an extra layer of inheritance help circumventing the `protected` access in your case? See https://godbolt.org/z/o5X_r-,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:76,security,access,access,76,@ktf could an extra layer of inheritance help circumventing the `protected` access in your case? See https://godbolt.org/z/o5X_r-,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:41,usability,help,help,41,@ktf could an extra layer of inheritance help circumventing the `protected` access in your case? See https://godbolt.org/z/o5X_r-,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,deployability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,integrability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,interoperability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:10,modifiability,variab,variable,10,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,modifiability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,reliability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,security,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:193,testability,integr,integrate,193,"Well, the variable is private and the whole class is in the .cxx because it's an implementation detail. I can of course change it, but IMHO this is better checked if we start discussing how to integrate the `RCombinedDS` and we have an example for that to work correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:35,energy efficiency,current,currently,35,"Also notice it's not an actual bug currently, because so far no datasource gets rewinded while running, AFAICT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:102,energy efficiency,current,currently,102,"Alright, I think the easiest way is an in-person chat with @dpiparo . > notice it's not an actual bug currently. I'm aware it's a new feature, but it still demands testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:164,safety,test,testing,164,"Alright, I think the easiest way is an in-person chat with @dpiparo . > notice it's not an actual bug currently. I'm aware it's a new feature, but it still demands testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:164,testability,test,testing,164,"Alright, I think the easiest way is an in-person chat with @dpiparo . > notice it's not an actual bug currently. I'm aware it's a new feature, but it still demands testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:42,usability,person,person,42,"Alright, I think the easiest way is an in-person chat with @dpiparo . > notice it's not an actual bug currently. I'm aware it's a new feature, but it still demands testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:60,energy efficiency,current,current,60,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:34,reliability,doe,does,34,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:5,safety,test,tested,5,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:73,safety,test,tests,73,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:5,testability,test,tested,5,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:68,testability,unit,unit,68,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:73,testability,test,tests,73,"It's tested, in the sense that it does not break any of the current unit tests, nor it did before this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:28,energy efficiency,current,current,28,"In order to demonstrate the current problem, please have a look at #3443 which implements the ability to do a double loop on two sources, highlighting the issue. Without this the result of the double loop test is wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:205,safety,test,test,205,"In order to demonstrate the current problem, please have a look at #3443 which implements the ability to do a double loop on two sources, highlighting the issue. Without this the result of the double loop test is wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:205,testability,test,test,205,"In order to demonstrate the current problem, please have a look at #3443 which implements the ability to do a double loop on two sources, highlighting the issue. Without this the result of the double loop test is wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:50,integrability,sub,submits,50,I am merging this one with the understanding @ktf submits a PR with a test soon-ish.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:70,safety,test,test,70,I am merging this one with the understanding @ktf submits a PR with a test soon-ish.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:31,testability,understand,understanding,31,I am merging this one with the understanding @ktf submits a PR with a test soon-ish.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:70,testability,test,test,70,I am merging this one with the understanding @ktf submits a PR with a test soon-ish.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3429:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:79,interoperability,bind,bindings,79,No it's not fixed in master:. https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/python/ROOT/pythonization/_tcollection.py,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:79,modifiability,bind,bindings,79,No it's not fixed in master:. https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/python/ROOT/pythonization/_tcollection.py,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:7,deployability,build,build,7,Is the build now with experimental pyroot enabled?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:9,deployability,build,build,9,> Is the build now with experimental pyroot enabled? You just need to enable the option `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:50,deployability,build,builds,50,"Yep, but do I see whether this happened in the PR builds?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:52,deployability,build,builds,52,"> Yep, but do I see whether this happened in the PR builds? Yes, you just need to check that the `pyz` tests ran, then you are sure it is an experimental PyROOT build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:161,deployability,build,build,161,"> Yep, but do I see whether this happened in the PR builds? Yes, you just need to check that the `pyz` tests ran, then you are sure it is an experimental PyROOT build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:103,safety,test,tests,103,"> Yep, but do I see whether this happened in the PR builds? Yes, you just need to check that the `pyz` tests ran, then you are sure it is an experimental PyROOT build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3429:103,testability,test,tests,103,"> Yep, but do I see whether this happened in the PR builds? Yes, you just need to check that the `pyz` tests ran, then you are sure it is an experimental PyROOT build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3429
https://github.com/root-project/root/pull/3430:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3430
https://github.com/root-project/root/pull/3432:107,interoperability,conflict,conflict,107,"Rebased, ready for review @Axel-Naumann, @bluehood (should be what you already saw, just without the merge conflict).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:19,safety,review,review,19,"Rebased, ready for review @Axel-Naumann, @bluehood (should be what you already saw, just without the merge conflict).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:19,testability,review,review,19,"Rebased, ready for review @Axel-Naumann, @bluehood (should be what you already saw, just without the merge conflict).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:36,safety,test,test,36,I forgot to delete the endif in the test. Fixed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:36,testability,test,test,36,I forgot to delete the endif in the test. Fixed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:12,availability,failur,failure,12,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:12,deployability,fail,failure,12,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:12,performance,failur,failure,12,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:32,performance,time,timeout,32,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:12,reliability,fail,failure,12,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:32,safety,timeout,timeout,32,I think the failure is due to a timeout?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:10,reliability,doe,does,10,Sure. Why does only Windows care?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:38,deployability,infrastructur,infrastructure,38,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:207,deployability,fail,fails,207,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:366,deployability,build,build,366,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:73,performance,time,time,73,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:207,reliability,fail,fails,207,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:150,security,auth,author,150,"Windows cares because... of broken CI infrastructure that nobody had the time to fix yet :-( It's trying to pick up an equally named branch by the PR author from roottest, and if not even the repo exists it fails fatally on Windows. The bug is somewhere around here: https://github.com/root-project/rootspi/blob/3c01a0de7eb7e79ec7fe18104365ee21a7a09a03/jenkins/root-build.cmake#L778",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:29,safety,test,test,29,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:126,safety,test,testing,126,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:138,safety,test,test,138,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:29,testability,test,test,29,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:126,testability,test,testing,126,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:138,testability,test,test,138,"> Should be fixed. Isn't the test still running for the stdlib implementation? I don't see any `#ifdef` in it anymore? OK for testing the test, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:155,availability,error,error,155,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:497,availability,error,error,497,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:58,deployability,build,build,58,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:175,deployability,build,build,175,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:216,deployability,build,build,216,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:270,deployability,build,build,270,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:311,deployability,build,build,311,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:411,deployability,build,build,411,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:585,deployability,fail,fail,585,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:3,energy efficiency,current,currently,3,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:317,energy efficiency,core,core,317,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:457,energy efficiency,core,core,457,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:155,performance,error,error,155,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:497,performance,error,error,497,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:50,reliability,doe,doesn,50,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:585,reliability,fail,fail,585,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:155,safety,error,error,155,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:333,safety,test,test,333,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:338,safety,test,testNotFn,338,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:473,safety,test,test,473,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:478,safety,test,testNotFn,478,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:497,safety,error,error,497,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:124,testability,verif,verify,124,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:333,testability,test,test,333,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:338,testability,test,testNotFn,338,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:473,testability,test,test,473,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:478,testability,test,testNotFn,478,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:155,usability,error,error,155,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:497,usability,error,error,497,"We currently have an issue on Windows, the master doesn't build due to our changes in `not_fn`. Could you clone roottest to verify that this fixes it? The error is:. ```. ""C:\build\night\LABEL\windows10\SPEC\default\build\ALL_BUILD.vcxproj"" (default target) (1) ->. ""C:\build\night\LABEL\windows10\SPEC\default\build\core\foundation\test\testNotFn.vcxproj"" (default target) (527) ->. (ClCompile target) -> . C:\build\night\LABEL\windows10\SPEC\default\root\core\foundation\test\testNotFn.cxx(16): error C2039: 'not_fn': is not a member of 'std' . ```. I don't know why this started to fail. Insights welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:349,availability,error,error,349,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:389,availability,avail,available,389,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:224,performance,time,time,224,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:349,performance,error,error,349,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:60,reliability,doe,does,60,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:160,reliability,doe,doesn,160,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:389,reliability,availab,available,389,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:349,safety,error,error,349,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:389,safety,avail,available,389,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:389,security,availab,available,389,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:168,usability,support,support,168,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:349,usability,error,error,349,"https://en.cppreference.com/w/cpp/utility/feature_test - it does bother me that this is a C++20 addition. Could that be a problem in C++17 mode if the compiler doesn't support this? It was added to most compilers quite some time ago. Not sure if this could be the issue with Windows, it seems like if something went wrong here that you should get a error due to defining something already available, not the other way around.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:23,deployability,fail,fails,23,"I believe Windows just fails in master due to the `!defined(_MSC_VER)` part of. ```. #if __cplusplus < 201703L && !defined(_MSC_VER). ```. in `core/foundation/inc/ROOT/RNotFn.hxx`. Your PR here should fix that; I've asked @bellenot to have a look at the Windows node. Once fixed I'll restart the build and then merge. Thanks, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:296,deployability,build,build,296,"I believe Windows just fails in master due to the `!defined(_MSC_VER)` part of. ```. #if __cplusplus < 201703L && !defined(_MSC_VER). ```. in `core/foundation/inc/ROOT/RNotFn.hxx`. Your PR here should fix that; I've asked @bellenot to have a look at the Windows node. Once fixed I'll restart the build and then merge. Thanks, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:143,energy efficiency,core,core,143,"I believe Windows just fails in master due to the `!defined(_MSC_VER)` part of. ```. #if __cplusplus < 201703L && !defined(_MSC_VER). ```. in `core/foundation/inc/ROOT/RNotFn.hxx`. Your PR here should fix that; I've asked @bellenot to have a look at the Windows node. Once fixed I'll restart the build and then merge. Thanks, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:23,reliability,fail,fails,23,"I believe Windows just fails in master due to the `!defined(_MSC_VER)` part of. ```. #if __cplusplus < 201703L && !defined(_MSC_VER). ```. in `core/foundation/inc/ROOT/RNotFn.hxx`. Your PR here should fix that; I've asked @bellenot to have a look at the Windows node. Once fixed I'll restart the build and then merge. Thanks, @henryiii !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:34,deployability,patch,patches,34,Thanks! Merged also into v6-16-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:34,safety,patch,patches,34,Thanks! Merged also into v6-16-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3432:34,security,patch,patches,34,Thanks! Merged also into v6-16-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3433:131,interoperability,conflict,conflict,131,"Hi @ktf , I'm finally back on RDF duty. I think this can just go in if you are still interested in having the changes in ROOT. The conflict is trivial to resolve but I don't think I have permission to do a rebase of your branch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3433
https://github.com/root-project/root/pull/3433:187,safety,permiss,permission,187,"Hi @ktf , I'm finally back on RDF duty. I think this can just go in if you are still interested in having the changes in ROOT. The conflict is trivial to resolve but I don't think I have permission to do a rebase of your branch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3433
https://github.com/root-project/root/pull/3433:5,availability,ping,ping,5,@ktf ping,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3433
https://github.com/root-project/root/pull/3434:84,safety,review,review,84,I see you also changed some a the python tutorials. I will ask our python expert to review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:84,testability,review,review,84,I see you also changed some a the python tutorials. I will ask our python expert to review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:238,usability,support,support,238,You can see in the following pages that the images are missing:. https://root.cern/doc/v616/df003__profiles_8py.html. https://root.cern/doc/v616/df017__vecOpsHEP_8py.html. So the issue with the scope is not due to the proposed changes to support python 3.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:122,integrability,messag,message,122,"Hi @ellert , thank you for the explanations! I would go ahead with it, but first I would add an explanation to the commit message about the change of scope when running with the `makeimage.py` script, which motivates the changes. The changes to the tutorials could even be in a separate commit that included also the explanation about the list comprehension in Python3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:122,interoperability,messag,message,122,"Hi @ellert , thank you for the explanations! I would go ahead with it, but first I would add an explanation to the commit message about the change of scope when running with the `makeimage.py` script, which motivates the changes. The changes to the tutorials could even be in a separate commit that included also the explanation about the list comprehension in Python3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:62,integrability,messag,message,62,"I have split the PR into two commits, and extended the commit message for the commit that changes the tutorials.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:62,interoperability,messag,message,62,"I have split the PR into two commits, and extended the commit message for the commit that changes the tutorials.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:42,modifiability,exten,extended,42,"I have split the PR into two commits, and extended the commit message for the commit that changes the tutorials.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3434:0,availability,Ping,Ping,0,Ping?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3434
https://github.com/root-project/root/pull/3435:60,safety,test,test,60,"Mattias, why you want to change example? It is dedicated to test capability of new web-based graphics to create images.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:60,testability,test,test,60,"Mattias, why you want to change example? It is dedicated to test capability of new web-based graphics to create images.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:350,availability,Error,Error,350,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:655,availability,Error,Error,655,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:77,deployability,build,builddir,77,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:86,deployability,build,build,86,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:92,deployability,BUILD,BUILD,92,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:378,deployability,Log,Log,378,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:383,deployability,build,builddir,383,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:392,deployability,build,build,392,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:398,deployability,BUILD,BUILD,398,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:739,deployability,fail,fail,739,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:754,deployability,fail,fails,754,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:350,performance,Error,Error,350,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:655,performance,Error,Error,655,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:739,reliability,fail,fail,739,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:754,reliability,fail,fails,754,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:350,safety,Error,Error,350,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:378,safety,Log,Log,378,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:655,safety,Error,Error,655,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:712,safety,test,test,712,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:734,safety,test,test,734,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:749,safety,test,test,749,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:378,security,Log,Log,378,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:378,testability,Log,Log,378,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:712,testability,test,test,712,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:734,testability,test,test,734,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:749,testability,test,test,749,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:350,usability,Error,Error,350,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:655,usability,Error,Error,655,"$ root -b -q -l line.cxx . Processing line.cxx... Info in <ROOT [Gpad] Info /builddir/build/BUILD/root-6.16.00/graf2d/primitives/v7/src/RStyle.cxx:71 in ROOT::Experimental::RStyle {anonymous}::GetInitialCurrent()>: Cannot find initial default style named ""plain"", using an empty one. Info in <THttpEngine::Create>: Starting HTTP server on port 8979. Error in <ROOT [WebDisplay] Log /builddir/build/BUILD/root-6.16.00/gui/webdisplay/src/RWebWindowsManager.cxx:406 in unsigned int ROOT::Experimental::RWebWindowsManager::ShowWindow(ROOT::Experimental::RWebWindow&, bool, const ROOT::Experimental::RWebDisplayArgs&)>: Cannot display window in native. Since ""Error in <"" is one of the strings that if present in the test output makes the test fail, the test fails.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:51,deployability,instal,installed,51,Strange. Do you have any Chrome or Firefox browser installed on your machine? That are the values for WebGui.Chrome and WebGui.Firefox in you etc/system.rootrc file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:28,deployability,instal,installed,28,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:71,deployability,build,build,71,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:112,deployability,instal,installed,112,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:81,safety,test,test,81,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:49,testability,mock,mock,49,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:81,testability,test,test,81,"I didn't have a web browser installed inside the mock chroot where the build and test are run, no. With firefox installed inside the chroot it seems to work though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:142,usability,close,close,142,"For web-based graphics one need web browser :(. In this special case web browser used in ""headless"" mode - without starting any window. Can I close PR?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3436:536,availability,reliab,reliably,536,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:244,energy efficiency,current,current,244,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:220,integrability,sub,subfolder,220,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:274,integrability,compon,components,274,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:473,integrability,sub,subfolder,473,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:274,interoperability,compon,components,274,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:558,interoperability,platform,platforms,558,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:274,modifiability,compon,components,274,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:386,performance,time,time,386,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:590,performance,time,time,590,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:536,reliability,reliab,reliably,536,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:127,testability,plan,plan,127,"Hi @amadio and @ellert . Next days I want to reorganize eve7, canvas7, fitpanel7 code. . At least location will be changed - I plan to move JavaScript/HTML/CSS code in `etc/http/ui5` folder. . One still can exclude this subfolder, but not with current conditions. Web-based components comipled not only with root7 flags, but already when c++14 or c++17 enabled. Another question - some time ago we were discussing with @amadio that JSROOT code should be removed from `etc` subfolder. Are there ideas which location could be used, which reliably works on all platforms. Probably now is good time to try it. @amadio, can you make some proposal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:151,interoperability,architectur,architecture,151,"@linev Please consult the [FHS](http://refspecs.linuxfoundation.org/FHS_3.0/index.html) to decide which directory is most appropriate. Since these are architecture independent files, they should probably be somewhere inside `/usr/share`, or, more generically, in `<prefix>/share`. In ROOT speak, that's `CMAKE_INSTALL_DATADIR`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:230,interoperability,share,share,230,"@linev Please consult the [FHS](http://refspecs.linuxfoundation.org/FHS_3.0/index.html) to decide which directory is most appropriate. Since these are architecture independent files, they should probably be somewhere inside `/usr/share`, or, more generically, in `<prefix>/share`. In ROOT speak, that's `CMAKE_INSTALL_DATADIR`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:273,interoperability,share,share,273,"@linev Please consult the [FHS](http://refspecs.linuxfoundation.org/FHS_3.0/index.html) to decide which directory is most appropriate. Since these are architecture independent files, they should probably be somewhere inside `/usr/share`, or, more generically, in `<prefix>/share`. In ROOT speak, that's `CMAKE_INSTALL_DATADIR`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:68,deployability,patch,patch,68,@linev Thanks! @ellert Could you check once Sergei finishes if this patch will still be needed? I guess we can still just remove the obsolete rules now and adjust the eve7 parts later.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:68,safety,patch,patch,68,@linev Thanks! @ellert Could you check once Sergei finishes if this patch will still be needed? I guess we can still just remove the obsolete rules now and adjust the eve7 parts later.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:68,security,patch,patch,68,@linev Thanks! @ellert Could you check once Sergei finishes if this patch will still be needed? I guess we can still just remove the obsolete rules now and adjust the eve7 parts later.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:108,deployability,build,build,108,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:118,deployability,instal,installed,118,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:32,integrability,sub,sub-folders,32,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:152,integrability,compon,component,152,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:152,interoperability,compon,component,152,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:152,modifiability,compon,component,152,"#3498 - this is new PR with new sub-folders organization. Now JSROOT, eve7 and other ui5-based code will be build and installed only when correspondent component is enabled and compiled",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:192,availability,consist,consistent,192,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:147,deployability,build,building,147,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:222,deployability,instal,installing,222,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:22,energy efficiency,current,currently,22,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:125,energy efficiency,current,current,125,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:192,usability,consist,consistent,192,"graf3d/CMakeLists.txt currently says:. ```. if(root7). add_subdirectory(eve7) # special CMakeLists.txt. endif(). ```. So the current condition for building the eve7 is ""root7"". In order to be consistent, the condition for installing the eve7 files should be the same.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:47,deployability,instal,install,47,"In #3498 PR I am using now . ```. if (webui) . install all ui5 files. endif(). ````. If somebody does not like these files, just do. ```. cmake -Droot7=ON -Dwebui=OFF. ```. There are some webui components, which also works without root7, but it we really difficult to differentiate between `root7-ui5` and `root6-ui5`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:194,integrability,compon,components,194,"In #3498 PR I am using now . ```. if (webui) . install all ui5 files. endif(). ````. If somebody does not like these files, just do. ```. cmake -Droot7=ON -Dwebui=OFF. ```. There are some webui components, which also works without root7, but it we really difficult to differentiate between `root7-ui5` and `root6-ui5`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:194,interoperability,compon,components,194,"In #3498 PR I am using now . ```. if (webui) . install all ui5 files. endif(). ````. If somebody does not like these files, just do. ```. cmake -Droot7=ON -Dwebui=OFF. ```. There are some webui components, which also works without root7, but it we really difficult to differentiate between `root7-ui5` and `root6-ui5`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:194,modifiability,compon,components,194,"In #3498 PR I am using now . ```. if (webui) . install all ui5 files. endif(). ````. If somebody does not like these files, just do. ```. cmake -Droot7=ON -Dwebui=OFF. ```. There are some webui components, which also works without root7, but it we really difficult to differentiate between `root7-ui5` and `root6-ui5`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:97,reliability,doe,does,97,"In #3498 PR I am using now . ```. if (webui) . install all ui5 files. endif(). ````. If somebody does not like these files, just do. ```. cmake -Droot7=ON -Dwebui=OFF. ```. There are some webui components, which also works without root7, but it we really difficult to differentiate between `root7-ui5` and `root6-ui5`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:51,deployability,build,build,51,I merged #3498. Now openui files will be copied to build directory only when `webui` is enabled (with or without root7). Same is true for JSROOT - it will be copied into build directory when `http` is enabled.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:170,deployability,build,build,170,I merged #3498. Now openui files will be copied to build directory only when `webui` is enabled (with or without root7). Same is true for JSROOT - it will be copied into build directory when `http` is enabled.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3438:34,energy efficiency,gpu,gpu,34,Enabled the cuda flag if the tmva-gpu flag is enabled with regards to this forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764/4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:34,performance,gpu,gpu,34,Enabled the cuda flag if the tmva-gpu flag is enabled with regards to this forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764/4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:148,safety,detect,detected,148,Enabled the cuda flag if the tmva-gpu flag is enabled with regards to this forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764/4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:148,security,detect,detected,148,Enabled the cuda flag if the tmva-gpu flag is enabled with regards to this forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764/4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:24,energy efficiency,gpu,gpu,24,"As per master, the tmva-gpu flag does not work unless the cuda flag is also enabled(the opposite is true - enabling the cuda flag enables the tmva-gpu flag by default). Do we want to keep it like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:147,energy efficiency,gpu,gpu,147,"As per master, the tmva-gpu flag does not work unless the cuda flag is also enabled(the opposite is true - enabling the cuda flag enables the tmva-gpu flag by default). Do we want to keep it like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:24,performance,gpu,gpu,24,"As per master, the tmva-gpu flag does not work unless the cuda flag is also enabled(the opposite is true - enabling the cuda flag enables the tmva-gpu flag by default). Do we want to keep it like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:147,performance,gpu,gpu,147,"As per master, the tmva-gpu flag does not work unless the cuda flag is also enabled(the opposite is true - enabling the cuda flag enables the tmva-gpu flag by default). Do we want to keep it like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:33,reliability,doe,does,33,"As per master, the tmva-gpu flag does not work unless the cuda flag is also enabled(the opposite is true - enabling the cuda flag enables the tmva-gpu flag by default). Do we want to keep it like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:135,energy efficiency,gpu,gpu,135,"This behavior will be fixed today. The file `tmva/tmva/CMakeLists.txt` is using `if(CUDA_FOUND)`, so that will have to change to `tmva-gpu` instead, among other things.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:135,performance,gpu,gpu,135,"This behavior will be fixed today. The file `tmva/tmva/CMakeLists.txt` is using `if(CUDA_FOUND)`, so that will have to change to `tmva-gpu` instead, among other things.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:5,usability,behavi,behavior,5,"This behavior will be fixed today. The file `tmva/tmva/CMakeLists.txt` is using `if(CUDA_FOUND)`, so that will have to change to `tmva-gpu` instead, among other things.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3442:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:42,availability,failur,failure,42,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:42,deployability,fail,failure,42,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:143,deployability,build,build,143,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:42,performance,failur,failure,42,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:42,reliability,fail,failure,42,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:129,security,access,access,129,"Hey, is there any way for me to view that failure output? I have a cern lightweight account under 0xloem@gmail.com but am denied access to the build output with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:33,availability,fault,fault,33,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:74,availability,failur,failure,74,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:96,availability,error,errors,96,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:59,deployability,infrastructur,infrastructure,59,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:74,deployability,fail,failure,74,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:90,deployability,build,build,90,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:201,deployability,build,builds,201,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:260,deployability,build,build,260,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:299,deployability,build,buildSummary,299,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:316,deployability,build,buildid,316,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:33,energy efficiency,fault,fault,33,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:33,performance,fault,fault,33,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:74,performance,failur,failure,74,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:96,performance,error,errors,96,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:33,reliability,fault,fault,33,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:74,reliability,fail,failure,74,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:33,safety,fault,fault,33,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:96,safety,error,errors,96,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:96,usability,error,errors,96,"@xloem I don't think it was your fault. It was probably an infrastructure failure. To see build errors, you can go to cdash.cern.ch and look on the day the PR was built at the very end you can see the builds by PR number. For example, here's a link to the mac build of this PR: http://cdash.cern.ch/buildSummary.php?buildid=628427.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:11,deployability,build,build,11,@phsft-bot build just on windows10/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3443:5,deployability,updat,updated,5,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:291,integrability,event,event,291,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:121,performance,perform,performing,121,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:5,safety,updat,updated,5,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:322,safety,test,tested,322,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:5,security,updat,updated,5,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:322,testability,test,tested,322,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:121,usability,perform,performing,121,"I've updated the PR with today's developments. Apart from the changes requested I've introduced a new index which allows performing all sort of block diagonal combinations between the indices of two tables, where each block represent a category of objects, e.g. tracks belonging to the same event. This is still not fully tested, but it should give an idea of the possibilities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:146,interoperability,conflict,conflict,146,"OK let's get this merged. We need two things:. - find a better name than ""combined"". I suggest `RCrossJoinDS` or `RCartesianProductDS`. - fix the conflict. I can certainly do that myself. @ktf let me know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:114,reliability,RCa,RCartesianProductDS,114,"OK let's get this merged. We need two things:. - find a better name than ""combined"". I suggest `RCrossJoinDS` or `RCartesianProductDS`. - fix the conflict. I can certainly do that myself. @ktf let me know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:110,integrability,configur,configurable,110,"Notice this is not limited to provide Cross Join / Cartesian Products kind of joins (i.e. MxN) but it's fully configurable via the index, that's why I chose ""Combined"". In principle one could have an index which repeats ten times the same pair of ""rows"" or whatever. RAssociativeDS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:110,modifiability,configur,configurable,110,"Notice this is not limited to provide Cross Join / Cartesian Products kind of joins (i.e. MxN) but it's fully configurable via the index, that's why I chose ""Combined"". In principle one could have an index which repeats ten times the same pair of ""rows"" or whatever. RAssociativeDS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:224,performance,time,times,224,"Notice this is not limited to provide Cross Join / Cartesian Products kind of joins (i.e. MxN) but it's fully configurable via the index, that's why I chose ""Combined"". In principle one could have an index which repeats ten times the same pair of ""rows"" or whatever. RAssociativeDS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:110,security,configur,configurable,110,"Notice this is not limited to provide Cross Join / Cartesian Products kind of joins (i.e. MxN) but it's fully configurable via the index, that's why I chose ""Combined"". In principle one could have an index which repeats ten times the same pair of ""rows"" or whatever. RAssociativeDS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:135,interoperability,conflict,conflict,135,"Hi, I'm picking this up (thanks @linev for assigning me). #3433 should be merged first. It just requires rebasing and fixing a trivial conflict. For this PR: I will review the code one last time before approving, mostly to be familiar with the code myself. I don't expect any issue. I think `RCombinedDS` is not a bad name given that it really provides arbitrary combinations of datasources. What do you think @Axel-Naumann ? @ktf proposed `RAssociativeDS` as an alternative but I don't think it's clearer.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:190,performance,time,time,190,"Hi, I'm picking this up (thanks @linev for assigning me). #3433 should be merged first. It just requires rebasing and fixing a trivial conflict. For this PR: I will review the code one last time before approving, mostly to be familiar with the code myself. I don't expect any issue. I think `RCombinedDS` is not a bad name given that it really provides arbitrary combinations of datasources. What do you think @Axel-Naumann ? @ktf proposed `RAssociativeDS` as an alternative but I don't think it's clearer.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:165,safety,review,review,165,"Hi, I'm picking this up (thanks @linev for assigning me). #3433 should be merged first. It just requires rebasing and fixing a trivial conflict. For this PR: I will review the code one last time before approving, mostly to be familiar with the code myself. I don't expect any issue. I think `RCombinedDS` is not a bad name given that it really provides arbitrary combinations of datasources. What do you think @Axel-Naumann ? @ktf proposed `RAssociativeDS` as an alternative but I don't think it's clearer.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:165,testability,review,review,165,"Hi, I'm picking this up (thanks @linev for assigning me). #3433 should be merged first. It just requires rebasing and fixing a trivial conflict. For this PR: I will review the code one last time before approving, mostly to be familiar with the code myself. I don't expect any issue. I think `RCombinedDS` is not a bad name given that it really provides arbitrary combinations of datasources. What do you think @Axel-Naumann ? @ktf proposed `RAssociativeDS` as an alternative but I don't think it's clearer.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:498,usability,clear,clearer,498,"Hi, I'm picking this up (thanks @linev for assigning me). #3433 should be merged first. It just requires rebasing and fixing a trivial conflict. For this PR: I will review the code one last time before approving, mostly to be familiar with the code myself. I don't expect any issue. I think `RCombinedDS` is not a bad name given that it really provides arbitrary combinations of datasources. What do you think @Axel-Naumann ? @ktf proposed `RAssociativeDS` as an alternative but I don't think it's clearer.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:115,integrability,pub,public,115,"Discussing with @ktf, we decided to add `RCombinedDS` as a friend of `RDataSource` to avoid the `#define protected public` that is now required to call `GetColumnReadersImpl` from `RCombinedDS`. I will do that and resolve the few conflicts this PR now has before merging. I don't think the other comments still apply (right @pcanal ?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:230,interoperability,conflict,conflicts,230,"Discussing with @ktf, we decided to add `RCombinedDS` as a friend of `RDataSource` to avoid the `#define protected public` that is now required to call `GetColumnReadersImpl` from `RCombinedDS`. I will do that and resolve the few conflicts this PR now has before merging. I don't think the other comments still apply (right @pcanal ?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:86,safety,avoid,avoid,86,"Discussing with @ktf, we decided to add `RCombinedDS` as a friend of `RDataSource` to avoid the `#define protected public` that is now required to call `GetColumnReadersImpl` from `RCombinedDS`. I will do that and resolve the few conflicts this PR now has before merging. I don't think the other comments still apply (right @pcanal ?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:21,integrability,coupl,couple,21,"@pcanal also needs a couple more things, see my last comment. It's on my to do list.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:21,modifiability,coupl,couple,21,"@pcanal also needs a couple more things, see my last comment. It's on my to do list.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:21,testability,coupl,couple,21,"@pcanal also needs a couple more things, see my last comment. It's on my to do list.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:48,usability,close,closed,48,"@ktf, what should we do with this PR? Should we closed it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3443:206,availability,operat,operations,206,"Up to you what you want to do. We have decided to go a different way than RDataFrame for our analysis framework, so it's not critical for us. Still I think some way of combining RDataSources with JOIN like operations is probably something useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3443
https://github.com/root-project/root/pull/3444:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3444
https://github.com/root-project/root/pull/3446:37,deployability,instal,installation,37,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,deployability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:82,deployability,build,builds,82,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,integrability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,interoperability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,modifiability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,reliability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,security,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:70,testability,integr,integration,70,"Hi @amadio . This PR breaks the Cuda installation. We don't have Cuda integration builds, so can you please check it or notify me before merging it so I can check it .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:43,safety,test,tests,43,The problem was in the CMake files for the tests. It is now fixed by this commit: . https://github.com/root-project/root/commit/697630162003a80570d62fdff07c29805bee84e4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:43,testability,test,tests,43,The problem was in the CMake files for the tests. It is now fixed by this commit: . https://github.com/root-project/root/commit/697630162003a80570d62fdff07c29805bee84e4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:47,safety,test,testing,47,Hi @lmoneta. Sorry about that. I thought I had testing enabled. I would have seen the breakage. I will let you know if I make other changes to let you check first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3446:47,testability,test,testing,47,Hi @lmoneta. Sorry about that. I thought I had testing enabled. I would have seen the breakage. I will let you know if I make other changes to let you check first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3446
https://github.com/root-project/root/pull/3452:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:43,availability,error,error,43,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:680,availability,servic,service,680,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:854,availability,error,error,854,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:22,deployability,build,build,22,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:28,deployability,fail,fails,28,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:623,deployability,fail,fail,623,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:680,deployability,servic,service,680,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:796,deployability,fail,failed,796,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:680,integrability,servic,service,680,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:680,modifiability,servic,service,680,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:699,modifiability,pac,pack,699,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:43,performance,error,error,43,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:189,performance,Content,Content-Type,189,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:228,performance,Content,Content-Length,228,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:524,performance,time,timeout,524,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:854,performance,error,error,854,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:28,reliability,fail,fails,28,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:623,reliability,fail,fail,623,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:796,reliability,fail,failed,796,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:43,safety,error,error,43,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:524,safety,timeout,timeout,524,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:854,safety,error,error,854,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:113,security,Authoriz,Authorization,113,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:265,security,Authenticat,Authenticate,265,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:43,usability,error,error,43,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:493,usability,Cancel,Cancelling,493,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:854,usability,error,error,854,"Hmm, strange that the build fails, but the error seems to be not connected to the PR:. > 22:53:26 < HTTP/1.1 401 Authorization Required. > 22:53:26 < Server: GitHub Babel 2.0. > 22:53:26 < Content-Type: text/plain. > 22:53:26 < Content-Length: 21. > 22:53:26 < WWW-Authenticate: Basic realm=""GitHub"". > 22:53:26 < X-Frame-Options: DENY. > 22:53:26 < X-GitHub-Request-Id: F8B0:30DD2:1EF7253:2E3CE06:5C79A9D6. > 22:53:26 < . > 22:53:26 * Connection #0 to host github.com left intact. > 02:52:59 Cancelling nested steps due to timeout. A few seconds before a similar request succeded. I found this line a few lines before the fail:. > 22:53:26 > GET /Triple-S/roottest.git/info/refs?service=git-upload-pack HTTP/1.1. At this moment I had no fork of roottest, so this might be the reason the request failed. I just added a fork of roottest so hopefully this error will not occur again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:265,availability,consist,consistent,265,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:723,availability,consist,consistency,723,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:874,availability,error,errors,874,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1134,availability,error,error,1134,"eason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TAr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1308,availability,error,errors,1308,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:798,deployability,version,version,798,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:522,integrability,wrap,wrapper,522,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:798,integrability,version,version,798,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1054,integrability,translat,translate,1054,"ly but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2120,integrability,wrap,wrapper,2120,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:522,interoperability,wrapper,wrapper,522,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1054,interoperability,translat,translate,1054,"ly but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2120,interoperability,wrapper,wrapper,2120,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:381,modifiability,concern,concerns,381,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:798,modifiability,version,version,798,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:874,performance,error,errors,874,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1134,performance,error,error,1134,"eason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TAr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1308,performance,error,errors,1308,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:874,safety,error,errors,874,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1134,safety,error,error,1134,"eason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TAr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1308,safety,error,errors,1308,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:365,testability,understand,understand,365,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:381,testability,concern,concerns,381,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:114,usability,stop,stopped,114,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:265,usability,consist,consistent,265,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:723,usability,consist,consistency,723,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:874,usability,error,errors,874,"Thanks for you comments @lmoneta. I'm sorry for my late reply but since nothing happened here for over a month, I stopped watching. The reason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1134,usability,error,error,1134,"eason I used double pointers for the 2D arrays was to have the most low level datatype possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TAr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1308,usability,error,errors,1308,"pe possible, have full felxibility and stay consistent with the other TGraph classes which are all using pointers for 1D arrays. Nevertheless I understand your concerns since double pointers for arrays are a rather dirty way of programming. I think it might be a good compromise to use the ROOT array wrapper class TArrayD. Then the two dimensional Arrays could be represented by an 1D array of TArrayD objects. The functions SetPointEY, SetPointEYL and SetPointEYH were implemented by me to keep full consistency with the TGraphAsymmErrors class. They are overloaded with one version taking the point and an array in which case the array cointains all errors of the named point for the different dimensions. My idea was to alter the TGraphAsymmErrors notation as little as possible so TGraphAsymmErrors::SetPointEY(i, el, eh) would translate to TGraphMultiErrors::SetPointEY(i, &el, &ey) in the case of only one error dimension which would be equal to a TGraphAsymmErrors. The idea of the function SetDimensionEY, SetDimensionEYL and SetDimensionEYH is basically the same. They set the errors of all points in the given dimension. My idea was to think of a way to convert from multiple TGraphAsymmErrors objects to one single TGraphMultiErrors object like in this small example:. ```. TGraphAsymmErrors* statisticErrors = ... TGraphAsymmErrors* systematicErrors = ... TGraphMultiErrors* theGraph = new TGraphMultiErrors(statisticErrors->GetN(), 2, statisticErrors->GetX(), statisticErrors->GetY(), statisticErrors->GetEXlow(), statisticErrors->GetEXhigh());. theGraph->SetDimensionEY(0, statisticErrors->GetEYlow(), statisticErrors->GetEYhigh());. theGraph->SetDimensionEY(1, systematicErrors->GetEYlow(), systematicErrors->GetEYhigh());. ```. But again I see your point since there is no check whether the passed array has a sufficient size. Maybe here it would also be a good solution to use the wrapper class TArrayD instead since it provides the neccessary information and is rather lightweight.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:119,deployability,version,version,119,@couet @lmoneta is there any news about this pull request? It would be very nice to have this feature in the next ROOT version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:119,integrability,version,version,119,@couet @lmoneta is there any news about this pull request? It would be very nice to have this feature in the next ROOT version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:119,modifiability,version,version,119,@couet @lmoneta is there any news about this pull request? It would be very nice to have this feature in the next ROOT version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:92,modifiability,concern,concerning,92,"I'm still waiting for a reply from @lmoneta to my last comment since he had some objections concerning my use of double pointers for two dimensional arrays and passing an array to a function without passing the corresponding size (which can result in a segmentation violation if the user is not creful). Furthermore, I explained the functions SetPointEY and SetDimensionEY. I proposed a solution, but before I implement it, I want @lmoneta to check and confirm it, because otherwise I might waste my time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:500,performance,time,time,500,"I'm still waiting for a reply from @lmoneta to my last comment since he had some objections concerning my use of double pointers for two dimensional arrays and passing an array to a function without passing the corresponding size (which can result in a segmentation violation if the user is not creful). Furthermore, I explained the functions SetPointEY and SetDimensionEY. I proposed a solution, but before I implement it, I want @lmoneta to check and confirm it, because otherwise I might waste my time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:92,testability,concern,concerning,92,"I'm still waiting for a reply from @lmoneta to my last comment since he had some objections concerning my use of double pointers for two dimensional arrays and passing an array to a function without passing the corresponding size (which can result in a segmentation violation if the user is not creful). Furthermore, I explained the functions SetPointEY and SetDimensionEY. I proposed a solution, but before I implement it, I want @lmoneta to check and confirm it, because otherwise I might waste my time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:283,usability,user,user,283,"I'm still waiting for a reply from @lmoneta to my last comment since he had some objections concerning my use of double pointers for two dimensional arrays and passing an array to a function without passing the corresponding size (which can result in a segmentation violation if the user is not creful). Furthermore, I explained the functions SetPointEY and SetDimensionEY. I proposed a solution, but before I implement it, I want @lmoneta to check and confirm it, because otherwise I might waste my time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:453,usability,confirm,confirm,453,"I'm still waiting for a reply from @lmoneta to my last comment since he had some objections concerning my use of double pointers for two dimensional arrays and passing an array to a function without passing the corresponding size (which can result in a segmentation violation if the user is not creful). Furthermore, I explained the functions SetPointEY and SetDimensionEY. I proposed a solution, but before I implement it, I want @lmoneta to check and confirm it, because otherwise I might waste my time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:615,availability,error,error,615,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:747,availability,error,errors,747,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:262,deployability,API,API,262,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:281,energy efficiency,current,current,281,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:229,integrability,interfac,interface,229,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:262,integrability,API,API,262,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:179,interoperability,standard,standard,179,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:229,interoperability,interfac,interface,229,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:262,interoperability,API,API,262,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:229,modifiability,interfac,interface,229,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:615,performance,error,error,615,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:747,performance,error,errors,747,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:615,safety,error,error,615,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:747,safety,error,errors,747,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:540,security,modif,modified,540,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:205,testability,understand,understand,205,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:244,usability,prefer,preference,244,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:393,usability,clear,clear,393,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:615,usability,error,error,615,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:747,usability,error,errors,747,"Sorry for my late reply. Thank you very much for your answer. . I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. . I understand also for the interface your preference for an API similar to the current TGraphAsymmError. Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. . One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. . One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1428,availability,error,error,1428,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1560,availability,error,errors,1560,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2076,availability,error,error,2076,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2176,availability,error,error,2176,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:200,deployability,API,API,200,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:372,deployability,contain,containers,372,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:753,deployability,contain,containers,753,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:786,deployability,automat,automatically,786,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:219,energy efficiency,current,current,219,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2055,energy efficiency,reduc,reduce,2055,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2207,energy efficiency,Reduc,Reducing,2207,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2259,energy efficiency,reduc,reduces,2259,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:167,integrability,interfac,interface,167,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:200,integrability,API,API,200,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:117,interoperability,standard,standard,117,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:167,interoperability,interfac,interface,167,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:200,interoperability,API,API,200,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:167,modifiability,interfac,interface,167,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1428,performance,error,error,1428,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1560,performance,error,errors,1560,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2076,performance,error,error,2076,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2176,performance,error,error,2176,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1428,safety,error,error,1428,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1560,safety,error,errors,1560,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2076,safety,error,error,2076,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2176,safety,error,error,2176,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1322,security,modif,modified,1322,"ass. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially im",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:143,testability,understand,understand,143,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:498,testability,understand,understand,498,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:786,testability,automat,automatically,786,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1630,testability,understand,understand,1630,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:182,usability,prefer,preference,182,"> I think using TArayD is an improvement than using double pointers, but I don't see any reason why not using a more standard std::vector. > I understand also for the interface your preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimension",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1175,usability,clear,clear,1175,"our preference for an API similar to the current TGraphAsymmError. The reason I really don't want to use std::vector here is the streaming of the class. I know that there are ways to stream STL containers, but I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all er",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1428,usability,error,error,1428,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1560,usability,error,errors,1560,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2076,usability,error,error,2076,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2176,usability,error,error,2176,"t I don't know how they really work and I refuse to make the functionality of my code rely on something I don't understand. Furthermore, using ROOT objects provides the advantage that the streaming of the storage class is fully handled by the class itself and therefore there is no need to think about the correct way to stream it. I'm also not 100% sure whether STL containers can be streamed by an automatically built streamer but ROOT classes can be streamed by them for sure. Last but not least I hold the opinion that ROOT classes should use other ROOT classes anywhere possible, cause we, the programmers, can always change ROOT classes if we need to, but we are not able to change C++ classes. > Thank you for explaining the meaning of SetDimensionEY, I think the name is not super clear, I would maybe just call it SetEY. > One comment on the passed array, I think the pointers should be passed as cont , since they will not be modified. I fully agree on these points. > One other comment I have , I will not have a method to Set the error dimension. I think it will be better instead a AddError method that will increment by one the dimension and add all the point errors. This I think it will be more useful. This point I don't fully understand. To me it sounds like you propose to add a function like this:. ```. void TGraphMultiErrors::AddError(const Double_t *eyL = 0, const Double_t *eyH = 0). {. SetNErrorDimensions(fNErrorDimensions + 1);. if (eyL && eyH). SetDimensionEY(fNErrorDimensions - 1, eyL, eyH);. }. ```. This would definitly be an useful addition, but I would keep the SetNErrorDimensions function, because otherwise there would be no way to reduce the amount of error dimensions which could be problematic when you want to store the object in a file but not all error dimensions are required. Reducing the amount of dimensions in that case also reduces the amount of storage required, which will be especially important using several graphs or graphs with a lot of points.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:398,availability,error,error,398,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:51,deployability,contain,container,51,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:284,energy efficiency,reduc,reduce,284,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:72,interoperability,standard,standard,72,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:398,performance,error,error,398,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:398,safety,error,error,398,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:647,safety,test,test,647,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:660,safety,test,testing,660,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:766,safety,test,test,766,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:801,safety,test,tests,801,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:206,security,auth,author,206,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:141,testability,understand,understand,141,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:257,testability,understand,understand,257,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:647,testability,test,test,647,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:660,testability,test,testing,660,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:766,testability,test,test,766,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:801,testability,test,tests,801,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:166,usability,prefer,preference,166,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:398,usability,error,error,398,"Hi, . Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. But I understand you have this preference, and since you are the class author we accept this. . For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? . And correct, I was proposing before having an AddError function . I think before merging this PR it would be nice to have also two additional things: . - one tutorial showing the usage of the class. - a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:544,availability,error,error,544,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:47,deployability,contain,container,47,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:277,deployability,contain,containers,277,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:430,energy efficiency,reduc,reduce,430,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:68,interoperability,standard,standard,68,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:544,performance,error,error,544,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1050,performance,time,time,1050,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:544,safety,error,error,544,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:811,safety,test,test,811,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:824,safety,test,testing,824,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:930,safety,test,test,930,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:965,safety,test,tests,965,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1072,safety,test,test,1072,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:204,security,auth,author,204,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:139,testability,understand,understand,139,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:403,testability,understand,understand,403,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:811,testability,test,test,811,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:824,testability,test,testing,824,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:930,testability,test,test,930,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:965,testability,test,tests,965,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1072,testability,test,test,1072,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:164,usability,prefer,preference,164,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:544,usability,error,error,544,"> Thank you for your fast reply. Streaming stl container in ROOT of standard types is easly done as doing for native ROOT objects. > But I understand you have this preference, and since you are the class author we accept this. I will try to figure out how the streaming of STL containers is done, then I don't feel bad about using them, since they also have some advantages. > For SetNErrorDimensions I understand the use case to reduce the dimensionality before storing, but then it would not be better to have the capability to delete a full error dimension with a dedicated function ? I also think that might be an even better solution. I will look into it. > I think before merging this PR it would be nice to have also two additional things:. > . > * one tutorial showing the usage of the class. > . > * a test program testing the basic functionality. This could be written for example in gtest and included in the hist/hist/test directory where we have other tests of new histogram classes. I will also look into this. I will probaly need some time to implement and test all the requested changes, especially since I have also some work to do for my PhD, but I see no severe problems at the moment. Thanks and all the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:78,availability,state,state,78,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:48,deployability,updat,update,48,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:70,energy efficiency,current,current,70,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:78,integrability,state,state,78,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:48,safety,updat,update,48,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:48,security,updat,update,48,"OK, please ignore this commit. I just wanted to update my fork to the current state of the root project and did not knew github would create a commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:778,availability,error,errors,778,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1043,availability,error,errors,1043,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1073,availability,error,errors,1073,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:516,deployability,instal,installation,516,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:710,interoperability,exchang,exchanged,710,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:778,performance,error,errors,778,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:847,performance,memor,memory,847,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1043,performance,error,errors,1043,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1073,performance,error,errors,1073,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:778,safety,error,errors,778,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:940,safety,test,test,940,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:951,safety,test,testing,951,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1043,safety,error,errors,1043,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1073,safety,error,errors,1073,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:940,testability,test,test,940,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:951,testability,test,testing,951,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:432,usability,custom,custom,432,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:504,usability,custom,custom,504,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:701,usability,clear,clear,701,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:778,usability,error,errors,778,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:847,usability,memor,memory,847,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1043,usability,error,errors,1043,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1073,usability,error,errors,1073,"Well, actually it was less work than I thought. I implemented now all the additions, changes and suggestions from @lmoneta. I used now std::vector everywhere it's features are useful. For the rest I stayed with using arrays to stay similar to all other TGraph objects. I moved the functions GetPointX, GetPointY, SetPointX, SetPointY and GetObjectInfo to the TGraph class because they apply to any TGraph object and only were in my custom class cause I could not implement them in TGraph without using a custom Root installation. I replaced the funtion SetNErrorDimensions by the functions AddYError and DeleteYError as proposed by @lmoneta. Since I think the meaning of ""dimension"" might not be 100% clear, I exchanged it to a term claryfing that it corresponds to different y errors. Besides that I implemented some further features and fixed a memory leak in the function PaintGraphMultiErrors in the TGraphPainter class. I also added a test macro testing the most critical features like streaming the class, adding / deleting points and y errors and the summation of y errors for fitting with different methods. Furthermore, I added a small tutorial macro that shows how to use the basic functionalities of the class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:106,deployability,continu,continue,106,"OK, it seems that Travis CI sometimes request changes that break the functionality. Therefore, I will not continue to implement any changes requested by it. I anyhow think the most important problems are fixed now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:677,deployability,contain,contained,677,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:179,integrability,interfac,interface,179,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:179,interoperability,interfac,interface,179,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:179,modifiability,interfac,interface,179,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:85,safety,test,test,85,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:290,safety,compl,complained,290,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:820,safety,review,reviewing,820,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:290,security,compl,complained,290,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:85,testability,test,test,85,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:432,testability,simpl,simply,432,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:519,testability,simpl,simple,519,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:820,testability,review,reviewing,820,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:432,usability,simpl,simply,432,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:496,usability,prefer,preference,496,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:519,usability,simpl,simple,519,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:622,usability,prefer,prefer,622,"Hi, . Thank you for applying the changes in the code and to provide a tutorial and a test program. . I have one more comment:. I still don't like having to pass a double** in the interface (in this case in the constructor). As you see that makes the code not nice (you see that also Travis complained). Since there is no easy solution for this, I would use std::vector<std::vector>> which gives the advantage that you could make it simply directly from a 2D initializer list. Otherwise my second preference is to use a simple double or float pointer and one assumes a proper order of the data. (e.g. raw major). . I would prefer having std::vector<std::vector<double>> for the contained type instead of std::vector<TArrayD>. . Thank you again for your changes and I hope we can merge this PR soon. Sorry for my delay in reviewing it . Lorenzo. Thank you if you can apply the ch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:464,availability,error,errors,464,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:836,availability,error,errors,836,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:677,deployability,contain,containers,677,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:388,interoperability,compatib,compatible,388,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:931,modifiability,inherit,inherited,931,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:464,performance,error,errors,464,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:836,performance,error,errors,836,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:464,safety,error,errors,464,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:836,safety,error,errors,836,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:973,security,sign,signature,973,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:464,usability,error,errors,464,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:540,usability,prefer,prefered,540,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:630,usability,prefer,prefer,630,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:836,usability,error,errors,836,"Hi,. I think I have found a solution that fulfilles all requirements. First of all the good news: I got rid of all double pointers and two dimensional arrays. I overhauled all the constructors and since I was already at it, I also added constructors which take a name and a title, as it is implemented for histograms. The notations without name and title still persist so the class stays compatible with all other TGraph objects. For the constructors which take y errors, I implemented one which takes std::vector<std::vector<Double_t>> as prefered by you and one which takes std::vector\<TArrayD\> which ist the implementation I prefer, since I still think one should use STL containers only when there is no way to achieve the same result with ROOT objects. Another change I implemented is changing the arrays that store the summed y-errors to mutable because that allows me to implement the functions GetEYlow() and GetEYhigh() inherited from TGraph with the exact same signature which eliminated possible problems with graph objects declared as constant. I hope I could fulfill all your expectations with these changes. All the best,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:28,deployability,updat,update,28,"Hi. Thank you Simon for the update and this very nice and useful contribution! . The changes look fine to me. For my opinion this PR is ready to be merged! Best, . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:28,safety,updat,update,28,"Hi. Thank you Simon for the update and this very nice and useful contribution! . The changes look fine to me. For my opinion this PR is ready to be merged! Best, . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:28,security,updat,update,28,"Hi. Thank you Simon for the update and this very nice and useful contribution! . The changes look fine to me. For my opinion this PR is ready to be merged! Best, . Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:78,safety,review,review,78,"Ups, sorry, these were my fat fingers on the tablet screen, please ignore the review request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:78,testability,review,review,78,"Ups, sorry, these were my fat fingers on the tablet screen, please ignore the review request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:127,deployability,releas,release,127,"The PR is now merged! Thank you very much Simon for your contribution. If we will have some issues in the next days before the release, we will let you know. Cheers. Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:66,usability,close,closed,66,"Thank you very much! I'm glad I can finally consider this project closed :D. In case any problems occur, I will help fixing them.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:112,usability,help,help,112,"Thank you very much! I'm glad I can finally consider this project closed :D. In case any problems occur, I will help fixing them.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3455:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:112,deployability,depend,dependency,112,"I think we can go for the PR to Cppyy and see what is the opinion of Wim on this issue. The tricky point is the dependency we introduce between CPyCppyy and ROOT, although only if a macro is defined.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:112,integrability,depend,dependency,112,"I think we can go for the PR to Cppyy and see what is the opinion of Wim on this issue. The tricky point is the dependency we introduce between CPyCppyy and ROOT, although only if a macro is defined.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:112,modifiability,depend,dependency,112,"I think we can go for the PR to Cppyy and see what is the opinion of Wim on this issue. The tricky point is the dependency we introduce between CPyCppyy and ROOT, although only if a macro is defined.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:112,safety,depend,dependency,112,"I think we can go for the PR to Cppyy and see what is the opinion of Wim on this issue. The tricky point is the dependency we introduce between CPyCppyy and ROOT, although only if a macro is defined.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:112,testability,depend,dependency,112,"I think we can go for the PR to Cppyy and see what is the opinion of Wim on this issue. The tricky point is the dependency we introduce between CPyCppyy and ROOT, although only if a macro is defined.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:57,deployability,patch,patch,57,@etejedor I've removed the preproc variable and put in a patch file. Should we put it in like this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:35,modifiability,variab,variable,35,@etejedor I've removed the preproc variable and put in a patch file. Should we put it in like this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:57,safety,patch,patch,57,@etejedor I've removed the preproc variable and put in a patch file. Should we put it in like this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:57,security,patch,patch,57,@etejedor I've removed the preproc variable and put in a patch file. Should we put it in like this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:23,performance,time,time,23,Let's try to find some time to look at it together with @amadio,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:10,deployability,patch,patch,10,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:192,deployability,depend,dependency,192,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:192,integrability,depend,dependency,192,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:192,modifiability,depend,dependency,192,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:10,safety,patch,patch,10,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:192,safety,depend,dependency,192,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:10,security,patch,patch,10,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3455:192,testability,depend,dependency,192,"Why add a patch file? We can easily check what changes have been made to Cppyy with git. Removing the preprocessor macro will probably not please Wim, since that turns an optional into a hard dependency on ROOT. Other than that, the changes look OK.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3455
https://github.com/root-project/root/pull/3460:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3460
https://github.com/root-project/root/pull/3463:268,integrability,repositor,repository,268,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:333,integrability,repositor,repository,333,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:268,interoperability,repositor,repository,268,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:333,interoperability,repositor,repository,333,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:107,modifiability,Concern,Concerning,107,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:122,safety,test,test,122,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:230,safety,test,tests,230,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:107,testability,Concern,Concerning,107,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:122,testability,test,test,122,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:144,testability,understand,understand,144,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:230,testability,test,tests,230,"Hi,. You're right about the naming convention, I totally forgot this and will fix it with the next commit. Concerning the test, I first have to understand how they work because until now I just executed them. As far as I know the tests go to the root-project/roottest repository so this requires an independent pull request for this repository, right? Thanks,. Simon",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:28,deployability,contain,contained,28,"The test(s) (if small, self contained and leveraging googletest framework) can also go in tree/tree/test. If in roottest, yes, it needs a separate PR (use the same branch name).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:4,safety,test,test,4,"The test(s) (if small, self contained and leveraging googletest framework) can also go in tree/tree/test. If in roottest, yes, it needs a separate PR (use the same branch name).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:100,safety,test,test,100,"The test(s) (if small, self contained and leveraging googletest framework) can also go in tree/tree/test. If in roottest, yes, it needs a separate PR (use the same branch name).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:4,testability,test,test,4,"The test(s) (if small, self contained and leveraging googletest framework) can also go in tree/tree/test. If in roottest, yes, it needs a separate PR (use the same branch name).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:100,testability,test,test,100,"The test(s) (if small, self contained and leveraging googletest framework) can also go in tree/tree/test. If in roottest, yes, it needs a separate PR (use the same branch name).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:133,testability,understand,understand,133,"@pcanal I just changed the name of the data member. I don't really like fElement, cause it says nothing about its meaning, but OK, I understand why you think fStreamingElement could be confusing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:84,usability,clear,clearer,84,"> cause it says nothing about its meaning,. True. > fStreamingElement. It is indeed clearer. I am hesitant because we don't use this wording anywhere else (and have use fElement in TBranchProxy, albeit there it is clearer/more straightforward what the member is about). fStreamerElement could have work (if it was not just one character away from the type ...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:214,usability,clear,clearer,214,"> cause it says nothing about its meaning,. True. > fStreamingElement. It is indeed clearer. I am hesitant because we don't use this wording anywhere else (and have use fElement in TBranchProxy, albeit there it is clearer/more straightforward what the member is about). fStreamerElement could have work (if it was not just one character away from the type ...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:182,usability,document,documentation,182,> and have use fElement in TBranchProxy. I did not know that it is named fElement there. In this case I think it is really the best solution to use the same wording as there. In the documentation there will anyway be an explanation what the data member is for so I think it is not so problematic.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:70,deployability,Releas,ReleaseNotes,70,"One more thing (sorry), could you also announce this change in README/ReleaseNotes/v618/index.md. Thanks,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:72,deployability,Releas,ReleaseNotes,72,"> One more thing (sorry), could you also announce this change in README/ReleaseNotes/v618/index.md. Thanks,. You don't have to apologize. I just added a short entry to the release notes summarizing the new functionalities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:172,deployability,releas,release,172,"> One more thing (sorry), could you also announce this change in README/ReleaseNotes/v618/index.md. Thanks,. You don't have to apologize. I just added a short entry to the release notes summarizing the new functionalities.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:34,deployability,releas,release,34,Just added a short example to the release notes showing how to create branches of the new types with and without specifying a range or amount of bits.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:113,interoperability,specif,specifying,113,Just added a short example to the release notes showing how to create branches of the new types with and without specifying a range or amount of bits.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3466:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3466
https://github.com/root-project/root/pull/3466:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3466
https://github.com/root-project/root/pull/3468:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3468
https://github.com/root-project/root/pull/3468:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3468
https://github.com/root-project/root/pull/3470:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3470:23,availability,error,errors,23,Remaining warnings and errors coming from eve7 and will be fixed with next PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3470:23,performance,error,errors,23,Remaining warnings and errors coming from eve7 and will be fixed with next PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3470:23,safety,error,errors,23,Remaining warnings and errors coming from eve7 and will be fixed with next PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3470:23,usability,error,errors,23,Remaining warnings and errors coming from eve7 and will be fixed with next PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3473:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3473
https://github.com/root-project/root/pull/3474:86,availability,error,error,86,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:9,deployability,build,build,9,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:43,deployability,build,build,43,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:49,deployability,build,build,49,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:86,performance,error,error,86,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:86,safety,error,error,86,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:111,security,ident,identifier,111,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:86,usability,error,error,86,"> * /mnt/build/workspace/root-pullrequests-build/build/include/TRootBrowser.h:167:53: error: use of undeclared identifier 'gEnv'. Seems to be, TEnv.h include is missing. . I guess, it is better to put code in TRootBrowser.cxx file",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3474:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3474
https://github.com/root-project/root/pull/3475:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3475
https://github.com/root-project/root/pull/3477:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3477:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3477:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3477:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:39,deployability,fail,failed,39,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:197,integrability,configur,configuring,197,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:197,modifiability,configur,configuring,197,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:134,performance,perform,performance-,134,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:39,reliability,fail,failed,39,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:197,security,configur,configuring,197,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:134,usability,perform,performance-,134,"Bertrand. Now Jenkins too smart - once failed, it will not start new compiling jobs. . One need to add more commits and exclude `ROOT-performance-centos7-multicore/default`, which has problem with configuring cmake for LLVM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:161,integrability,sub,submitting,161,> * warning: format string is not a string literal (potentially insecure) [-Wformat-security]. I will fix warnings with next PR - they didn't appears when I was submitting my last PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:13,interoperability,format,format,13,> * warning: format string is not a string literal (potentially insecure) [-Wformat-security]. I will fix warnings with next PR - they didn't appears when I was submitting my last PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:84,security,secur,security,84,> * warning: format string is not a string literal (potentially insecure) [-Wformat-security]. I will fix warnings with next PR - they didn't appears when I was submitting my last PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,@phsft-bot build just on fedora27/noimt fedora29/python3 ubuntu16/rtcxxmod mac1014/cxx17 windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,@phsft-bot build just on ROOT-fedora27/noimt ROOT-fedora29/python3 ROOT-ubuntu16/rtcxxmod windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:103,reliability,doe,does,103,@bellenot Jenkins is going crazy. I use last command with other PR #3477 and it works properly. Now it does not :-(,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:45,usability,command,command,45,@bellenot Jenkins is going crazy. I use last command with other PR #3477 and it works properly. Now it does not :-(,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:28,deployability,infrastructur,infrastructure,28,I'm fed-up with this crappy infrastructure :angry:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3480:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3480
https://github.com/root-project/root/pull/3482:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3482
https://github.com/root-project/root/pull/3482:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3482
https://github.com/root-project/root/pull/3482:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3482
https://github.com/root-project/root/pull/3486:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3486
https://github.com/root-project/root/pull/3487:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3487
https://github.com/root-project/root/pull/3487:11,deployability,build,build,11,"@phsft-bot build just on ROOT-fedora27/noimt, ROOT-fedora29/python3, ROOT-ubuntu16/rtcxxmod, mac1014/cxx17, windows10/default with flags -Droot7=ON -DCMAKE_CXX_STANDARD=14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3487
https://github.com/root-project/root/pull/3488:49,deployability,automat,automatic,49,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:118,deployability,automat,automatically,118,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:6,energy efficiency,cool,cool,6,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:59,integrability,wrap,wrapping,59,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:49,testability,automat,automatic,49,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:118,testability,automat,automatically,118,Super cool! The real amazing feature here is the automatic wrapping of python functions as C++ functions...and PyROOT automatically lets you go back!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:69,integrability,wrap,wrapper,69,"I've added a commit which acquires the `ROOT::gCoreMutex` in the C++ wrapper code. However, the runtime of following code goes up by a factor of 10 :/ But no segfaults (which you get without the lock!) ;). ```python. import ROOT. ROOT.ROOT.EnableImplicitMT(). @ROOT.DeclareCppCallable([""float""], ""float""). def f(x):. return 2.0 * x. print(f.__cpp_wrapper__). df = ROOT.ROOT.RDataFrame(10000000).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::f(x)""). print(df.Mean(""y"").GetValue()). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:69,interoperability,wrapper,wrapper,69,"I've added a commit which acquires the `ROOT::gCoreMutex` in the C++ wrapper code. However, the runtime of following code goes up by a factor of 10 :/ But no segfaults (which you get without the lock!) ;). ```python. import ROOT. ROOT.ROOT.EnableImplicitMT(). @ROOT.DeclareCppCallable([""float""], ""float""). def f(x):. return 2.0 * x. print(f.__cpp_wrapper__). df = ROOT.ROOT.RDataFrame(10000000).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::f(x)""). print(df.Mean(""y"").GetValue()). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:195,performance,lock,lock,195,"I've added a commit which acquires the `ROOT::gCoreMutex` in the C++ wrapper code. However, the runtime of following code goes up by a factor of 10 :/ But no segfaults (which you get without the lock!) ;). ```python. import ROOT. ROOT.ROOT.EnableImplicitMT(). @ROOT.DeclareCppCallable([""float""], ""float""). def f(x):. return 2.0 * x. print(f.__cpp_wrapper__). df = ROOT.ROOT.RDataFrame(10000000).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::f(x)""). print(df.Mean(""y"").GetValue()). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:195,security,lock,lock,195,"I've added a commit which acquires the `ROOT::gCoreMutex` in the C++ wrapper code. However, the runtime of following code goes up by a factor of 10 :/ But no segfaults (which you get without the lock!) ;). ```python. import ROOT. ROOT.ROOT.EnableImplicitMT(). @ROOT.DeclareCppCallable([""float""], ""float""). def f(x):. return 2.0 * x. print(f.__cpp_wrapper__). df = ROOT.ROOT.RDataFrame(10000000).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::f(x)""). print(df.Mean(""y"").GetValue()). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:50,testability,simpl,simplified,50,@bluehood pointed out that the internals could be simplified with `TPython.h` features (without changing the user facing workflow). Let's have a look!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:50,usability,simpl,simplified,50,@bluehood pointed out that the internals could be simplified with `TPython.h` features (without changing the user facing workflow). Let's have a look!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:109,usability,user,user,109,@bluehood pointed out that the internals could be simplified with `TPython.h` features (without changing the user facing workflow). Let's have a look!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:121,usability,workflow,workflow,121,@bluehood pointed out that the internals could be simplified with `TPython.h` features (without changing the user facing workflow). Let's have a look!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:36,safety,reme,remember,36,"I agree with @dpiparo 's comment, I remember that for the namespace Jim suggested `ROOT::Python` which I find nice.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:323,availability,down,down,323,"@stwunsch @etejedor @dpiparo I think it's highly desirable to have a (silenceable) warning if `DeclareCppCallable` needs to skip numba and fallback to the ""Generic"" backend. The rationale is that, otherwise, I'm 100% sure that PyROOT+RDF users will love this feature and start using it _all the time_, shooting performance down with a bazooka without even realizing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:311,performance,perform,performance,311,"@stwunsch @etejedor @dpiparo I think it's highly desirable to have a (silenceable) warning if `DeclareCppCallable` needs to skip numba and fallback to the ""Generic"" backend. The rationale is that, otherwise, I'm 100% sure that PyROOT+RDF users will love this feature and start using it _all the time_, shooting performance down with a bazooka without even realizing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:238,usability,user,users,238,"@stwunsch @etejedor @dpiparo I think it's highly desirable to have a (silenceable) warning if `DeclareCppCallable` needs to skip numba and fallback to the ""Generic"" backend. The rationale is that, otherwise, I'm 100% sure that PyROOT+RDF users will love this feature and start using it _all the time_, shooting performance down with a bazooka without even realizing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:311,usability,perform,performance,311,"@stwunsch @etejedor @dpiparo I think it's highly desirable to have a (silenceable) warning if `DeclareCppCallable` needs to skip numba and fallback to the ""Generic"" backend. The rationale is that, otherwise, I'm 100% sure that PyROOT+RDF users will love this feature and start using it _all the time_, shooting performance down with a bazooka without even realizing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:193,availability,down,down,193,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:105,deployability,log,logging,105,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:206,modifiability,scenario,scenario,206,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:105,safety,log,logging,105,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:105,security,log,logging,105,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:105,testability,log,logging,105,"On the one hand I agree with @bluehood, on the other hand I hate writing to stdout or stderr without any logging mechanism ... But I agree that it could fall back to the generic impl and shoot down your MT scenario silently.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:113,safety,compl,completely,113,"Probably I could add a verbose flag, default on 1 (printing whether it switched to generic), with the options 0 (completely silent besides crashes of the generic impl) and 2 (puts the exception of numba on stdout but goes to the generic impl).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:184,safety,except,exception,184,"Probably I could add a verbose flag, default on 1 (printing whether it switched to generic), with the options 0 (completely silent besides crashes of the generic impl) and 2 (puts the exception of numba on stdout but goes to the generic impl).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:113,security,compl,completely,113,"Probably I could add a verbose flag, default on 1 (printing whether it switched to generic), with the options 0 (completely silent besides crashes of the generic impl) and 2 (puts the exception of numba on stdout but goes to the generic impl).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:74,deployability,log,logging,74,"You can use ROOT's facilities (e.g. `ROOT.Warning`). The lack of a proper logging system is a ROOT issue, which should be solved in ROOT7 at some point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:74,safety,log,logging,74,"You can use ROOT's facilities (e.g. `ROOT.Warning`). The lack of a proper logging system is a ROOT issue, which should be solved in ROOT7 at some point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:74,security,log,logging,74,"You can use ROOT's facilities (e.g. `ROOT.Warning`). The lack of a proper logging system is a ROOT issue, which should be solved in ROOT7 at some point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:74,testability,log,logging,74,"You can use ROOT's facilities (e.g. `ROOT.Warning`). The lack of a proper logging system is a ROOT issue, which should be solved in ROOT7 at some point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:183,availability,slo,slower,183,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:228,availability,toler,tolerate,228,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:243,availability,slo,slower,243,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,deployability,fail,fail,21,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:100,performance,time,time,100,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,reliability,fail,fail,21,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:183,reliability,slo,slower,183,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:243,reliability,slo,slower,243,"How often will numba fail to run? If it is often, seeing the warning of the fallback solution every time might be annoying. So the choice is: we annoy people that are ok with running slower vs we don't inform people that cannot tolerate going slower.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,deployability,log,logger,21,"FairRoot has a nice [logger](https://github.com/FairRootGroup/FairLogger) that might serve as an inspiration (or could maybe be used?). Note: would require some pythonisation, as it does not work well with PyROOT out of the box...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:182,reliability,doe,does,182,"FairRoot has a nice [logger](https://github.com/FairRootGroup/FairLogger) that might serve as an inspiration (or could maybe be used?). Note: would require some pythonisation, as it does not work well with PyROOT out of the box...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,safety,log,logger,21,"FairRoot has a nice [logger](https://github.com/FairRootGroup/FairLogger) that might serve as an inspiration (or could maybe be used?). Note: would require some pythonisation, as it does not work well with PyROOT out of the box...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,security,log,logger,21,"FairRoot has a nice [logger](https://github.com/FairRootGroup/FairLogger) that might serve as an inspiration (or could maybe be used?). Note: would require some pythonisation, as it does not work well with PyROOT out of the box...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:21,testability,log,logger,21,"FairRoot has a nice [logger](https://github.com/FairRootGroup/FairLogger) that might serve as an inspiration (or could maybe be used?). Note: would require some pythonisation, as it does not work well with PyROOT out of the box...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:42,safety,compl,completely,42,Yes the option to switch off the warnings completely might be useful!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:42,security,compl,completely,42,Yes the option to switch off the warnings completely might be useful!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3492:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3492
https://github.com/root-project/root/pull/3493:0,availability,Ping,Ping,0,Ping @lmoneta. Any reason not to merge this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3493
https://github.com/root-project/root/pull/3495:4,availability,failur,failures,4,The failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3495
https://github.com/root-project/root/pull/3495:4,deployability,fail,failures,4,The failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3495
https://github.com/root-project/root/pull/3495:4,performance,failur,failures,4,The failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3495
https://github.com/root-project/root/pull/3495:4,reliability,fail,failures,4,The failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3495
https://github.com/root-project/root/pull/3496:4,availability,failur,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3496
https://github.com/root-project/root/pull/3496:4,deployability,fail,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3496
https://github.com/root-project/root/pull/3496:17,deployability,infrastructur,infrastructure,17,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3496
https://github.com/root-project/root/pull/3496:4,performance,failur,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3496
https://github.com/root-project/root/pull/3496:4,reliability,fail,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3496
https://github.com/root-project/root/pull/3499:74,performance,time,timeout,74,"@osschar please fork also roottest in your github repo, that will fix the timeout issue on Windows...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3499
https://github.com/root-project/root/pull/3499:74,safety,timeout,timeout,74,"@osschar please fork also roottest in your github repo, that will fix the timeout issue on Windows...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3499
https://github.com/root-project/root/pull/3501:264,security,sign,signature,264,"Client code can use `auto*` to make it explicit that a pointer is returned. However `TFile::Get` is so common in ROOT, and so idiomatic, that I don't think the ambiguity will be a disturbance. Also, the doxygen doc will clearly show that a `T*` is returned in the signature.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3501
https://github.com/root-project/root/pull/3501:220,usability,clear,clearly,220,"Client code can use `auto*` to make it explicit that a pointer is returned. However `TFile::Get` is so common in ROOT, and so idiomatic, that I don't think the ambiguity will be a disturbance. Also, the doxygen doc will clearly show that a `T*` is returned in the signature.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3501
https://github.com/root-project/root/pull/3503:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3503
https://github.com/root-project/root/pull/3505:38,integrability,coupl,couple,38,Perfect @JavierCVilla . Can you add a couple of tests with different types?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3505
https://github.com/root-project/root/pull/3505:38,modifiability,coupl,couple,38,Perfect @JavierCVilla . Can you add a couple of tests with different types?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3505
https://github.com/root-project/root/pull/3505:48,safety,test,tests,48,Perfect @JavierCVilla . Can you add a couple of tests with different types?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3505
https://github.com/root-project/root/pull/3505:38,testability,coupl,couple,38,Perfect @JavierCVilla . Can you add a couple of tests with different types?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3505
https://github.com/root-project/root/pull/3505:48,testability,test,tests,48,Perfect @JavierCVilla . Can you add a couple of tests with different types?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3505
https://github.com/root-project/root/pull/3509:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:9,availability,failur,failures,9,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:9,deployability,fail,failures,9,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:9,performance,failur,failures,9,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:9,reliability,fail,failures,9,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:4,safety,test,test,4,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3509:4,testability,test,test,4,All test failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3513:83,deployability,fail,failed,83,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:153,deployability,Fail,Failed,153,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:218,deployability,Fail,Failed,218,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:281,deployability,Fail,Failed,281,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:343,deployability,Fail,Failed,343,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:6,interoperability,format,format,6,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:83,reliability,fail,failed,83,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:153,reliability,Fail,Failed,153,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:218,reliability,Fail,Failed,218,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:281,reliability,Fail,Failed,281,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:343,reliability,Fail,Failed,343,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:55,safety,Test,Tests,55,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:65,safety,test,tests,65,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:55,testability,Test,Tests,55,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:65,testability,test,tests,65,"clang-format:. Has been run on all edited/added files. Tests:. 4 tests out of 1769 failed, namely the following. 215 - tutorial-dataframe-df024_Display (Failed). 978 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 979 - roottest-python-JupyROOT-thread_local_notebook (Failed). 980 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:45,modifiability,pac,packages,45,This PR needs to be tested also with the VMC packages masters; please wait with merge when this is verified. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:20,safety,test,tested,20,This PR needs to be tested also with the VMC packages masters; please wait with merge when this is verified. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:20,testability,test,tested,20,This PR needs to be tested also with the VMC packages masters; please wait with merge when this is verified. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:99,testability,verif,verified,99,This PR needs to be tested also with the VMC packages masters; please wait with merge when this is verified. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:21,deployability,fail,fails,21,"I see that one check fails due to the usage of TError::Fatal in the constructor of TVirtualMC and TVirtualMCApplication. Is the CI assuming that this would be a virtual method of TVirtualMC and TVirtualMCApplication, respectively, even though it's not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:21,reliability,fail,fails,21,"I see that one check fails due to the usage of TError::Fatal in the constructor of TVirtualMC and TVirtualMCApplication. Is the CI assuming that this would be a virtual method of TVirtualMC and TVirtualMCApplication, respectively, even though it's not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:1,availability,Error,Error,1,"`Error()` uses `IsA()` which is a virtual function. Calling virtual functions before the object is fully constructed can give unexpected (""I am the base!"") results.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:1,performance,Error,Error,1,"`Error()` uses `IsA()` which is a virtual function. Calling virtual functions before the object is fully constructed can give unexpected (""I am the base!"") results.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:1,safety,Error,Error,1,"`Error()` uses `IsA()` which is a virtual function. Calling virtual functions before the object is fully constructed can give unexpected (""I am the base!"") results.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:1,usability,Error,Error,1,"`Error()` uses `IsA()` which is a virtual function. Calling virtual functions before the object is fully constructed can give unexpected (""I am the base!"") results.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:83,performance,time,time,83,The Fatal() is in the TVirtualMC and TVirtualMCApplication constructors since long time; what should be used at this place instead? Is there some out-of-class equivalent? Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:114,security,modif,modify,114,"Thanks, so I will change to. `::Fatal(""TVirtualMC::TVirtualMC"", ""No user MC application is defined."");`. and will modify other places accordingly",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:68,usability,user,user,68,"Thanks, so I will change to. `::Fatal(""TVirtualMC::TVirtualMC"", ""No user MC application is defined."");`. and will modify other places accordingly",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:148,availability,error,error,148,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:37,deployability,build,build,37,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:142,deployability,build,build,142,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:148,performance,error,error,148,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:148,safety,error,error,148,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:148,usability,error,error,148,"@Axel-Naumann Can/should I steer the build? Or will you do it at some point? If something else needs to be done before, just let me know. The build error with windows10/default should be related to the fact that a `struct` was forward-declared in some cases as a `class`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:34,deployability,updat,update,34,I ran the VMC tests with the last update and they work ok.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:14,safety,test,tests,14,I ran the VMC tests with the last update and they work ok.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:34,safety,updat,update,34,I ran the VMC tests with the last update and they work ok.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:34,security,updat,update,34,I ran the VMC tests with the last update and they work ok.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:14,testability,test,tests,14,I ran the VMC tests with the last update and they work ok.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:626,availability,operat,operator,626,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:50,deployability,Build,Building,50,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:136,deployability,build,build,136,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:170,deployability,build,build,170,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:297,deployability,build,build,297,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:331,deployability,build,build,331,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:445,security,sign,signedness,445,@benedikt-voelkel could you fix. ```. [8377/9534] Building CXX object montecarlo/vmc/CMakeFiles/VMC.dir/src/TMCManagerStack.cxx.o. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx: In member function ‘Bool_t TMCManagerStack::HasTrackId(Int_t) const’:. /mnt/build/workspace/root-pullrequests-build/root/montecarlo/vmc/src/TMCManagerStack.cxx:262:32: warning: comparison of integer expressions of different signedness: ‘Int_t’ {aka ‘int’} and ‘std::vector<TParticle*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]. if (trackId >= 0 && trackId < fParticles->size() && fParticles->operator[](trackId)) {. ~~~~~~~~^~~~~~~~~~~~~~~~~~~~. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:28,security,team,team,28,Sorry - virtually the whole team was on travel during the past weeks...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:287,deployability,upgrad,upgrading,287,"Just a quick head up! Adding a virtual method break some of our use code. The virtual method was not implemented in one of our class, what use to be a normal class is now a virtual class and that cannot be instantiated anymore. The first compilation problem seems to be solved simply by upgrading to the last release of GEANT3, it should not be a big issue, but I just wanted to point out this ""problem"". Cheers,. Simone",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:309,deployability,releas,release,309,"Just a quick head up! Adding a virtual method break some of our use code. The virtual method was not implemented in one of our class, what use to be a normal class is now a virtual class and that cannot be instantiated anymore. The first compilation problem seems to be solved simply by upgrading to the last release of GEANT3, it should not be a big issue, but I just wanted to point out this ""problem"". Cheers,. Simone",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:287,modifiability,upgrad,upgrading,287,"Just a quick head up! Adding a virtual method break some of our use code. The virtual method was not implemented in one of our class, what use to be a normal class is now a virtual class and that cannot be instantiated anymore. The first compilation problem seems to be solved simply by upgrading to the last release of GEANT3, it should not be a big issue, but I just wanted to point out this ""problem"". Cheers,. Simone",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:277,testability,simpl,simply,277,"Just a quick head up! Adding a virtual method break some of our use code. The virtual method was not implemented in one of our class, what use to be a normal class is now a virtual class and that cannot be instantiated anymore. The first compilation problem seems to be solved simply by upgrading to the last release of GEANT3, it should not be a big issue, but I just wanted to point out this ""problem"". Cheers,. Simone",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:277,usability,simpl,simply,277,"Just a quick head up! Adding a virtual method break some of our use code. The virtual method was not implemented in one of our class, what use to be a normal class is now a virtual class and that cannot be instantiated anymore. The first compilation problem seems to be solved simply by upgrading to the last release of GEANT3, it should not be a big issue, but I just wanted to point out this ""problem"". Cheers,. Simone",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:217,deployability,build,build,217,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:248,deployability,version,versions,248,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:338,deployability,version,versions,338,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:74,integrability,interfac,interfaces,74,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:248,integrability,version,versions,248,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:338,integrability,version,versions,338,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:74,interoperability,interfac,interfaces,74,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:113,interoperability,compatib,compatibility,113,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:56,modifiability,exten,extending,56,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:74,modifiability,interfac,interfaces,74,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:248,modifiability,version,versions,248,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:273,modifiability,pac,packagages,273,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:338,modifiability,version,versions,338,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:190,usability,user,user,190,"Hi @siscia ,. Could you, please, be more explicit? When extending the VMC interfaces we take care about backward compatibility. Which was the virtual method which caused the problem in your user code? And also do you build your code against tagged versions of Root and VMC packagages (what is the recommended way), or against development versions (master branches)? Thank you,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:101,deployability,build,build,101,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:380,deployability,version,version,380,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:484,deployability,version,version,484,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:545,deployability,build,build,545,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:380,integrability,version,version,380,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:484,integrability,version,version,484,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:515,interoperability,standard,standard,515,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:380,modifiability,version,version,380,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:484,modifiability,version,version,484,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:373,usability,custom,custom,373,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:477,usability,custom,custom,477,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:633,usability,clear,clear,633,"Hi @ihrivnac,. I investigate the issue more deeply. It turns out to be a mix of problems between our build system and the v2-4 and v2-7 of vmc/GEANT3. In v2-4 TrackPosition is not defined for Float: https://github.com/vmc-project/geant3/blob/v2-4/TGeant3/TGeant3.h#L677. While it is in v2-7: https://github.com/vmc-project/geant3/blob/v2-7/TGeant3/TGeant3.h#L682. We had a custom version of geant3 that was hiding the problem with ROOT v6-14, when I moved to v6-18 I lost this custom version, going back to use the standard v2-4, that broke the build because it needed TrackPosition(float) to be defined. . I am not sure I have been clear enough! But I believe you guys were correct in your code :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3515:11,deployability,build,build,11,@phsft-bot build with `-Dpyroot_experimental=ON`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3515
https://github.com/root-project/root/pull/3515:44,reliability,doe,does,44,"Ah wait, we need to fix this either way. It does not seem to work in all cases as Wim pointed out.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3515
https://github.com/root-project/root/pull/3518:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3518:4,availability,failur,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3518:4,deployability,fail,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3518:17,deployability,infrastructur,infrastructure,17,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3518:4,performance,failur,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3518:4,reliability,fail,failures,4,The failures are infrastructure related.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3518
https://github.com/root-project/root/pull/3521:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3521
https://github.com/root-project/root/pull/3521:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3521
https://github.com/root-project/root/pull/3521:0,deployability,Continu,Continued,0,Continued in https://github.com/root-project/root/pull/3529,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3521
https://github.com/root-project/root/pull/3522:11,deployability,build,build,11,"@phsft-bot build, please - now that I fixed roottest",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3522
https://github.com/root-project/root/pull/3522:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3522
https://github.com/root-project/root/pull/3523:0,availability,failur,failure,0,failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3523
https://github.com/root-project/root/pull/3523:0,deployability,fail,failure,0,failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3523
https://github.com/root-project/root/pull/3523:0,performance,failur,failure,0,failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3523
https://github.com/root-project/root/pull/3523:0,reliability,fail,failure,0,failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3523
https://github.com/root-project/root/pull/3524:0,availability,Failur,Failure,0,Failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3524
https://github.com/root-project/root/pull/3524:0,deployability,Fail,Failure,0,Failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3524
https://github.com/root-project/root/pull/3524:0,performance,Failur,Failure,0,Failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3524
https://github.com/root-project/root/pull/3524:0,reliability,Fail,Failure,0,Failure are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3524
https://github.com/root-project/root/pull/3528:117,interoperability,bind,bindings,117,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:117,modifiability,bind,bindings,117,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:82,safety,test,tests,82,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:153,safety,test,test,153,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:195,safety,test,test,195,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:82,testability,test,tests,82,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:153,testability,test,test,153,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:195,testability,test,test,195,"Uh, thank you alot for your contribution! This corner-case should be added to the tests as well. This would go into `bindings/pyroot_experimental/PyROOT/test/array_interface.py`. Could you add a test there?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:349,availability,consist,consistent,349,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:88,integrability,interfac,interface,88,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:88,interoperability,interfac,interface,88,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:88,modifiability,interfac,interface,88,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:376,reliability,doe,does,376,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:137,usability,minim,minimal,137,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:349,usability,consist,consistent,349,"Wait, I was too quick. This fix should go into the adoption mechanism through the array interface and not into `RDataFrame.AsNumpy`. The minimal reproducer is the following:. ```python. import ROOT. import numpy. x = ROOT.std.vector(""float"")(). npy = numpy.asnumpy(x). ```. And then, I'm not sure what value the `data` field should take and what is consistent with what numpy does for empty arrays (which do not have any data?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:153,deployability,version,version,153,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:153,integrability,version,version,153,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:153,modifiability,version,version,153,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:223,reliability,doe,does,223,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:278,reliability,doe,does,278,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:121,security,stride,strides,121,"Hm, it looks like this:. ```python. import numpy. x = numpy.empty(0). x.__array_interface__. # {'descr': [('', '<f8')], 'strides': None, 'shape': (0,), 'version': 3, 'typestr': '<f8', 'data': (25479120, False)}. ```. So it does set a data pointer for an empty array. Now, where does it point? And the correct shape for empty arrays is `(0,)`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:50,integrability,interfac,interface,50,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:81,integrability,interfac,interface,81,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:50,interoperability,interfac,interface,50,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:81,interoperability,interfac,interface,81,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:50,modifiability,interfac,interface,50,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:81,modifiability,interfac,interface,81,"I don't know, if I am able to fix it in the array interface. Where is this array interface actually defined and where is the adoption mechanism implemented?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:960,deployability,fail,fails,960,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:1139,deployability,version,version,1139,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:156,integrability,interfac,interface,156,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:742,integrability,interfac,interface,742,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:1139,integrability,version,version,1139,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:156,interoperability,interfac,interface,156,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:302,interoperability,bind,bindings,302,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:742,interoperability,interfac,interface,742,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:156,modifiability,interfac,interface,156,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:302,modifiability,bind,bindings,302,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:742,modifiability,interfac,interface,742,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:1139,modifiability,version,version,1139,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:673,performance,memor,memory,673,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:960,reliability,fail,fails,960,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:58,usability,guid,guide,58,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:673,usability,memor,memory,673,"If you like to have a look into this, I would be happy to guide you. But feel free to tell me if you have to do other stuff, then I'll take over. The array interface is added in `ROOT.py:243`, however no need to change something there. Following the code path, you can look for `AddArrayInterface` in `bindings/pyroot/src/Pythonize.cxx`. Still no need to fix something there ;) Finally, you end up in `STLVectorArrayInterface` and `RVecArrayInterface` in as well in `Pythonize.cxx`. There, the C++ object (a `std::vector` in your case) is read out and the `__array_interface__` dict is added to the Python object, which carries all information needed by numpy to adopt the memory (see [here](https://docs.scipy.org/doc/numpy/reference/arrays.interface.html)). In short: You would need to cover the case of `vector.size() == 0` in `STLVectorArrayInterface` properly. Following code tells me, that the size field is already set properly, but it seems that numpy fails with the `""data"": (0, False)` set in the `__array_interface__`. ```python. >>> import ROOT. >>> x = ROOT.std.vector(""float"")(). >>> x.__array_interface__. {'shape': (0L,), 'version': 3, 'data': (0, False), 'typestr': '<f4'}. ```. So what is the correct thing to do there that `numpy.asarray` returns an empty numpy array?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:419,deployability,version,version,419,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:165,integrability,buffer,buffer,165,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:172,integrability,interfac,interface,172,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:290,integrability,buffer,buffer,290,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:297,integrability,interfac,interface,297,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:419,integrability,version,version,419,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:172,interoperability,interfac,interface,172,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:297,interoperability,interfac,interface,297,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:172,modifiability,interfac,interface,172,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:297,modifiability,interfac,interface,297,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:419,modifiability,version,version,419,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:250,performance,memor,memory,250,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:250,usability,memor,memory,250,"Ok the issue seems to be the `0` in the `'data'` entry of the dict. . probably this is interpreted as None if it is zero and numpy tries to read the data trough the buffer interface of the object. > If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. ```python. import numpy. class empty_test:. 	__array_interface__ = \. {'shape': (0L,), . 'version': 3, . 'data': (1, False), . 'typestr': '<f4'}. print(numpy.asarray(empty_test())). ```. so something like. ```c++. if(cobj->empty()){. PyDict_SetItemString(dict, ""data"",. PyTuple_Pack(2, PyLong_FromLong(reinterpret_cast<long>(-1)), Py_False));. }. ```. in the Pythonization.cxx. should fix this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:61,testability,understand,understand,61,I can confirm that this fixes the issue. Even though I don't understand from the numpy side why `-1` is a better pointer than `0` :P,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:6,usability,confirm,confirm,6,I can confirm that this fixes the issue. Even though I don't understand from the numpy side why `-1` is a better pointer than `0` :P,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:270,performance,time,time,270,"Ok, I've just spotted some other issues which did not yet show up as a bug but could lead to similar behaviours (for example, the type of the casted address is only long but should by unsigned long long to cover the full 64 bit address space). I'm very grateful for the time you put into this and finding out what is actually going wrong. I'm gonna spend this afternoon in revamping and hardening the adoption mechanism. As soon as I've put all fixes in, I'll report back!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:387,security,harden,hardening,387,"Ok, I've just spotted some other issues which did not yet show up as a bug but could lead to similar behaviours (for example, the type of the casted address is only long but should by unsigned long long to cover the full 64 bit address space). I'm very grateful for the time you put into this and finding out what is actually going wrong. I'm gonna spend this afternoon in revamping and hardening the adoption mechanism. As soon as I've put all fixes in, I'll report back!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3528:101,usability,behavi,behaviours,101,"Ok, I've just spotted some other issues which did not yet show up as a bug but could lead to similar behaviours (for example, the type of the casted address is only long but should by unsigned long long to cover the full 64 bit address space). I'm very grateful for the time you put into this and finding out what is actually going wrong. I'm gonna spend this afternoon in revamping and hardening the adoption mechanism. As soon as I've put all fixes in, I'll report back!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3528
https://github.com/root-project/root/pull/3529:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:79,deployability,updat,update,79,"You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:79,safety,updat,update,79,"You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:79,security,updat,update,79,"You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:353,availability,error,error,353,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:81,deployability,updat,update,81,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:353,performance,error,error,353,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:81,safety,updat,update,81,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:353,safety,error,error,353,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:81,security,updat,update,81,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3529:353,usability,error,error,353,"> You know you can do a force push with `git push -f` to your original branch to update a PR without having to create a new one, right? :-). Of course, you can see how I force pushed in https://github.com/root-project/root/pull/3521 but for some reason at that moment github was keeping the three original commits instead of the final two and giving an error. So I just went for another PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3529
https://github.com/root-project/root/pull/3531:69,safety,review,review,69,"Hey, I have removed the full path to STL headers. . Could you please review it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:69,testability,review,review,69,"Hey, I have removed the full path to STL headers. . Could you please review it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:55,deployability,Modul,Modules,55,"Hi Axel,. We're going thought exercises for the Global Modules Index project, thanks for reviewing!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:55,modifiability,Modul,Modules,55,"Hi Axel,. We're going thought exercises for the Global Modules Index project, thanks for reviewing!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:55,safety,Modul,Modules,55,"Hi Axel,. We're going thought exercises for the Global Modules Index project, thanks for reviewing!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:89,safety,review,reviewing,89,"Hi Axel,. We're going thought exercises for the Global Modules Index project, thanks for reviewing!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:89,testability,review,reviewing,89,"Hi Axel,. We're going thought exercises for the Global Modules Index project, thanks for reviewing!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:172,availability,consist,consistent,172,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:121,deployability,modul,modulemap,121,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:197,deployability,modul,modulemap,197,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:121,modifiability,modul,modulemap,121,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:197,modifiability,modul,modulemap,197,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:97,safety,except,except,97,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:121,safety,modul,modulemap,121,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:197,safety,modul,modulemap,197,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:172,usability,consist,consistent,172,"@oshadura, I have squashed the commits. . All the headers used for generation of PCH are present except cassert. The stl.modulemap file says that it is not present to stay consistent with the OS X modulemap, so I did not add it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu16/rtcxxmod with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:31,availability,failur,failure,31,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:64,availability,avail,available,64,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:31,deployability,fail,failure,31,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:31,performance,failur,failure,31,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:31,reliability,fail,failure,31,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:64,reliability,availab,available,64,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:64,safety,avail,available,64,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:64,security,availab,available,64,"@arpi-r can you check please a failure, looks like <any> is not available as a part of std still on Ubuntu 16 and 18.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:124,deployability,modul,modulemap,124,@oshadura I have included more headers than in the list of STL headers that are used for generation of PCH. Do I change stl.modulemap to contain headers only from that list? (This compiled in my system),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:137,deployability,contain,contain,137,@oshadura I have included more headers than in the list of STL headers that are used for generation of PCH. Do I change stl.modulemap to contain headers only from that list? (This compiled in my system),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:124,modifiability,modul,modulemap,124,@oshadura I have included more headers than in the list of STL headers that are used for generation of PCH. Do I change stl.modulemap to contain headers only from that list? (This compiled in my system),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:124,safety,modul,modulemap,124,@oshadura I have included more headers than in the list of STL headers that are used for generation of PCH. Do I change stl.modulemap to contain headers only from that list? (This compiled in my system),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:38,availability,failur,failure,38,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:130,availability,error,error,130,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:38,deployability,fail,failure,38,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:38,performance,failur,failure,38,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:130,performance,error,error,130,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:38,reliability,fail,failure,38,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:130,safety,error,error,130,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:130,usability,error,error,130,"@arpi-r, what I am asking is to fix a failure on our CI node ROOT-ubuntu16/rtcxxmod, where it was not able to find <any> header: `error: header 'any' not found`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:62,deployability,modul,modulemap,62,"@oshadura, I have made the changes and removed 'any' from stl.modulemap. Please check if it works now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:62,modifiability,modul,modulemap,62,"@oshadura, I have made the changes and removed 'any' from stl.modulemap. Please check if it works now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3531:62,safety,modul,modulemap,62,"@oshadura, I have made the changes and removed 'any' from stl.modulemap. Please check if it works now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3531
https://github.com/root-project/root/pull/3533:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3533:11,deployability,build,build,11,@phsft-bot build on ROOT-performance-centos7-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3533:25,performance,perform,performance-,25,@phsft-bot build on ROOT-performance-centos7-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3533:25,usability,perform,performance-,25,@phsft-bot build on ROOT-performance-centos7-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3537:22,safety,review,review,22,Relying on post-merge review with Guilherme gone.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3537
https://github.com/root-project/root/pull/3537:22,testability,review,review,22,Relying on post-merge review with Guilherme gone.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3537
https://github.com/root-project/root/pull/3541:15,usability,help,help,15,Thanks for the help!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3541
https://github.com/root-project/root/pull/3542:24,safety,test,test,24,I meant *I* would add a test :) thanks a lot!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3542
https://github.com/root-project/root/pull/3542:24,testability,test,test,24,I meant *I* would add a test :) thanks a lot!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3542
https://github.com/root-project/root/pull/3543:488,safety,review,review,488,"Hi Martin - well, that's inconsistent :-) This file collects the git identities you used for commits to this repo. It's a view of data that's in the repo anyway; github shows it, git clone has it. (Re GDPR: that's data that you willingly provided through your commits, without us asking - I'm happy with contributors using aliases, so I'm not sure how this relates.). That said we can of course remove you from the mail map. As @amadio set this up I'd appreciate if we could wait for his review. But he is on a long multi-week trip. Please let me know whether we can wait.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:69,security,ident,identities,69,"Hi Martin - well, that's inconsistent :-) This file collects the git identities you used for commits to this repo. It's a view of data that's in the repo anyway; github shows it, git clone has it. (Re GDPR: that's data that you willingly provided through your commits, without us asking - I'm happy with contributors using aliases, so I'm not sure how this relates.). That said we can of course remove you from the mail map. As @amadio set this up I'd appreciate if we could wait for his review. But he is on a long multi-week trip. Please let me know whether we can wait.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:201,security,GDPR,GDPR,201,"Hi Martin - well, that's inconsistent :-) This file collects the git identities you used for commits to this repo. It's a view of data that's in the repo anyway; github shows it, git clone has it. (Re GDPR: that's data that you willingly provided through your commits, without us asking - I'm happy with contributors using aliases, so I'm not sure how this relates.). That said we can of course remove you from the mail map. As @amadio set this up I'd appreciate if we could wait for his review. But he is on a long multi-week trip. Please let me know whether we can wait.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:488,testability,review,review,488,"Hi Martin - well, that's inconsistent :-) This file collects the git identities you used for commits to this repo. It's a view of data that's in the repo anyway; github shows it, git clone has it. (Re GDPR: that's data that you willingly provided through your commits, without us asking - I'm happy with contributors using aliases, so I'm not sure how this relates.). That said we can of course remove you from the mail map. As @amadio set this up I'd appreciate if we could wait for his review. But he is on a long multi-week trip. Please let me know whether we can wait.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:336,interoperability,distribut,distributed,336,"@Axel-Naumann The file has been out for a few months, so I'm sure it won't hurt being there a few more weeks till @amadio returns. I'm aware that git already has this information, the problem is that this is now a file in the repo itself and not just part of the git ""metadata"", leading to that my name + aliases + email addresses gets distributed in other channels than just source control.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:383,security,control,control,383,"@Axel-Naumann The file has been out for a few months, so I'm sure it won't hurt being there a few more weeks till @amadio returns. I'm aware that git already has this information, the problem is that this is now a file in the repo itself and not just part of the git ""metadata"", leading to that my name + aliases + email addresses gets distributed in other channels than just source control.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:383,testability,control,control,383,"@Axel-Naumann The file has been out for a few months, so I'm sure it won't hurt being there a few more weeks till @amadio returns. I'm aware that git already has this information, the problem is that this is now a file in the repo itself and not just part of the git ""metadata"", leading to that my name + aliases + email addresses gets distributed in other channels than just source control.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:144,deployability,log,log,144,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:276,deployability,log,log,276,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:144,safety,log,log,144,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:276,safety,log,log,276,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:144,security,log,log,144,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:276,security,log,log,276,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:144,testability,log,log,144,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:276,testability,log,log,276,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:379,usability,prefer,prefer,379,"Hi Martin! How are you doing? We can certainly remove the information from the mailmap file, but that file only repeats info already in the git log (i.e. the file only maps contributions with different emails to your CERN email). We cannot remove the information from the git log, so I don't see much gain from removing it from the mailmap file either. In any case, if you still prefer to remove, just let us know and either me or someone else will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:221,energy efficiency,Current,Currently,221,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:486,integrability,discover,discovered,486,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:180,interoperability,distribut,distributed,180,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:338,interoperability,distribut,distributed,338,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:486,interoperability,discover,discovered,486,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3543:486,usability,discov,discovered,486,"@amadio I'm doing pretty fine thanks, life out in the industry is quite different from CERN :) Like I said in my previous comment, the problem I have is that this information gets distributed with other channels as well. Currently it is part of git (which I am perfectly fine with), but by placing this information in a file makes it get distributed in the channels where the git history is not, such as a tar of the source code. Another example is search engines where Google is how I discovered my mail address was there. So yes, you can go ahead and merge this. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3543
https://github.com/root-project/root/pull/3546:11,deployability,build,build,11,@phsft-bot build with flags -Dpyroot_experimental=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3546
https://github.com/root-project/root/pull/3547:0,availability,error,errors,0,errors are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3547
https://github.com/root-project/root/pull/3547:0,performance,error,errors,0,errors are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3547
https://github.com/root-project/root/pull/3547:0,safety,error,errors,0,errors are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3547
https://github.com/root-project/root/pull/3547:0,usability,error,errors,0,errors are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3547
https://github.com/root-project/root/pull/3549:62,safety,test,test,62,Do you have a small reproducer of this problem ? (in order to test your fix),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:62,testability,test,test,62,Do you have a small reproducer of this problem ? (in order to test your fix),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:374,deployability,updat,update,374,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:471,deployability,updat,updated,471,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:754,deployability,updat,updated,754,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:374,safety,updat,update,374,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:471,safety,updat,updated,471,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:754,safety,updat,updated,754,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:374,security,updat,update,374,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:471,security,updat,updated,471,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:754,security,updat,updated,754,"I have a reproducer, but it is far from small. In our collaboration we have implemented our QA plots with TRootEmbeddedCanvas which are used to display several tabs. An additional thread is refreshing them. Every 15 Minutes our QA plots are being backed up in a pdf. We noticed that after the plots were saved to the file the windows were not refreshed anymore although the update thread was running and working. Furthermore in the written pdf files the plots were still updated, but not on the screen. Doing some debugging I found out that after the printing to the pdf the affected Canvases returned true for TCanvas::IsBatch(), so I added TCanvas::SetBatch(kFALSE); directly after the Print function which fixed the problem that the Canvases were not updated anymore on the screen. I could try to write a small reproducer, but that will take quite some effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:163,availability,state,statement,163,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:46,deployability,log,logical,46,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:163,integrability,state,statement,163,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:46,safety,log,logical,46,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:46,security,log,logical,46,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:46,testability,log,logical,46,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3549:13,usability,close,closely,13,"Looking more closely at your fix it is indeed logical regarding the code structure. The line you propose to add is indeed missing in the ""else"" branch of the ""if"" statement starting at line 5068. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3549
https://github.com/root-project/root/pull/3550:9,availability,failur,failure,9,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3550:9,deployability,fail,failure,9,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3550:9,performance,failur,failure,9,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3550:9,reliability,fail,failure,9,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3550:4,safety,test,test,4,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3550:4,testability,test,test,4,The test failure seems unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3550
https://github.com/root-project/root/pull/3552:236,safety,valid,valid,236,"Hi Otto,. I see you have modified only the file TPaletteAxis.cxx. But I guess this option will pass trough THistPainter::MakeChopt also... Is there any danger that it my trigger some other option in THistPainter ? For instance ""C"" is a valid option.. Just wondering... Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:25,security,modif,modified,25,"Hi Otto,. I see you have modified only the file TPaletteAxis.cxx. But I guess this option will pass trough THistPainter::MakeChopt also... Is there any danger that it my trigger some other option in THistPainter ? For instance ""C"" is a valid option.. Just wondering... Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:44,integrability,messag,message,44,"Hi Otto,. Have you some comments on my last message ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:44,interoperability,messag,message,44,"Hi Otto,. Have you some comments on my last message ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:439,deployability,version,version,439,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:259,energy efficiency,current,current,259,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:439,integrability,version,version,439,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:504,integrability,pub,published,504,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:439,modifiability,version,version,439,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:374,usability,clear,clear,374,"Hi Olivier. I propose for the docu:. In THistPainter in table for 2dim options: add a row for ""Z CJUST"" . with short description and a reference to TPaletteAxis. In TPaletteAxis: description + example macro. In general:. Make a new Pull Request starting from current head (6.19.01??). including code + docu since original PR was based on 6.16. (ignore original PR). Its not clear to me how in the docu handle the since, e.g. \since **ROOT version 6.09/01**. because I dont know yet when this really gets published. Cheers . Otto.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:32,security,modif,modified,32,"Hi Otto,. Yes the doc should be modified in THistPainter also. May be put the example there or in TPaletteAxis ? ... You do not need to make a new PR. Just push you mods in that one . Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:27,security,modif,modified,27,"Hi Otto,. I think you have modified Doxyfile by mistake. Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:107,deployability,fail,failed,107,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:324,deployability,version,version,324,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:136,energy efficiency,reduc,reduced,136,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:324,integrability,version,version,324,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:324,modifiability,version,version,324,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:107,reliability,fail,failed,107,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:149,safety,Input,Input,149,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:115,testability,trace,traceback,115,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:149,usability,Input,Input,149,"Hi Olivier,. oh sorry, mea culpa. I tried to generate the full docu in in doxygen directory,. this somehow failed (traceback ) . Then I reduced the ""Input section"" to THistPainter + PaletteAxisin in Doxyfile. this worked. Yesterday I added this by mistake to the commits. How can I fix that: Replace Doxyfile by the 6.18.00 version and commit again?? Cheers. Otto",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:110,availability,restor,restore,110,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:127,deployability,version,version,127,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:205,deployability,version,version,205,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:49,energy efficiency,reduc,reducing,49,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:127,integrability,version,version,127,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:205,integrability,version,version,205,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:127,modifiability,version,version,127,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:205,modifiability,version,version,205,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:31,performance,time,time,31,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:39,performance,time,time,39,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:110,reliability,restor,restore,110,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:72,safety,input,input,72,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:159,testability,simpl,simply,159,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:72,usability,input,input,72,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:159,usability,simpl,simply,159,Yes I do this mistake too from time to time :-) (reducing the number of input files in Doxyfile and forget to restore te right version before committing). You simply need to change Doxyfile to the correct version and push it again to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:23,availability,restor,restores,23,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:36,modifiability,variab,variable,36,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:23,reliability,restor,restores,23,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:45,safety,INPUT,INPUT,45,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:61,security,modif,modified,61,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:45,usability,INPUT,INPUT,45,"Hi Otto, Your new puss restores the variable INPUT, but also modified EXCLUDE_SYMBOLS and EXCLUDE_PATTERNS... do you really want to do that ? Cheers,. Olivier",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:167,availability,backup,backup,167,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:43,deployability,version,version,43,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:43,integrability,version,version,43,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:43,modifiability,version,version,43,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:167,reliability,backup,backup,167,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:150,safety,INPUT,INPUT,150,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:167,safety,backup,backup,167,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:140,security,modif,modifying,140,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:150,usability,INPUT,INPUT,150,"no, not really,. I took the file from root version 6.18.00, obviosly wrong one. I dont know how to get exactly the one I started with when. modifying INPUT,. I have a backup from 2019-09-10:. [Doxyfile.2019-09-10-000000.txt](https://github.com/root-project/root/files/3620872/Doxyfile.2019-09-10-000000.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:21,availability,state,state,21,PR is in a not clean state since Doxyfile was modified by mistake . will restart from current master,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:86,energy efficiency,current,current,86,PR is in a not clean state since Doxyfile was modified by mistake . will restart from current master,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:21,integrability,state,state,21,PR is in a not clean state since Doxyfile was modified by mistake . will restart from current master,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3552:46,security,modif,modified,46,PR is in a not clean state since Doxyfile was modified by mistake . will restart from current master,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3552
https://github.com/root-project/root/pull/3555:4,deployability,releas,releases,4,"New releases for the three Cppyy packages are out, merging this since the update of Cppyy in experimental PyROOT is imminent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:74,deployability,updat,update,74,"New releases for the three Cppyy packages are out, merging this since the update of Cppyy in experimental PyROOT is imminent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:33,modifiability,pac,packages,33,"New releases for the three Cppyy packages are out, merging this since the update of Cppyy in experimental PyROOT is imminent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:74,safety,updat,update,74,"New releases for the three Cppyy packages are out, merging this since the update of Cppyy in experimental PyROOT is imminent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:74,security,updat,update,74,"New releases for the three Cppyy packages are out, merging this since the update of Cppyy in experimental PyROOT is imminent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3556:95,deployability,fail,failing,95,"Let's rebuild and check what the problem is. @etejedor Do you remember the problems above with failing string proxies? `PyROOT::CreateScopeProxy(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, _object*)` leads to a segfault. Probably it's the cxx11 ABI?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:207,energy efficiency,alloc,allocator,207,"Let's rebuild and check what the problem is. @etejedor Do you remember the problems above with failing string proxies? `PyROOT::CreateScopeProxy(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, _object*)` leads to a segfault. Probably it's the cxx11 ABI?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:110,interoperability,prox,proxies,110,"Let's rebuild and check what the problem is. @etejedor Do you remember the problems above with failing string proxies? `PyROOT::CreateScopeProxy(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, _object*)` leads to a segfault. Probably it's the cxx11 ABI?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:95,reliability,fail,failing,95,"Let's rebuild and check what the problem is. @etejedor Do you remember the problems above with failing string proxies? `PyROOT::CreateScopeProxy(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, _object*)` leads to a segfault. Probably it's the cxx11 ABI?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:62,safety,reme,remember,62,"Let's rebuild and check what the problem is. @etejedor Do you remember the problems above with failing string proxies? `PyROOT::CreateScopeProxy(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, _object*)` leads to a segfault. Probably it's the cxx11 ABI?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:126,interoperability,prox,proxy,126,"@stwunsch no I do not remember this, the issue is with `CreateScopeProxy` in general or it is crashing when trying to get the proxy of a particular class? This shoud be easily reproducible since `CreateScopeProxy` can be even called from Python.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3556:22,safety,reme,remember,22,"@stwunsch no I do not remember this, the issue is with `CreateScopeProxy` in general or it is crashing when trying to get the proxy of a particular class? This shoud be easily reproducible since `CreateScopeProxy` can be even called from Python.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3556
https://github.com/root-project/root/pull/3557:11,deployability,build,build,11,@phsft-bot build with flags -Droot7=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3557
https://github.com/root-project/root/pull/3557:122,availability,state,statement,122,"cmake works now as expected, but implementation may be not the most optimal. . Especially `if(""${webui}"" STREQUAL ""OFF"")` statement for `webui` option.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3557
https://github.com/root-project/root/pull/3557:68,energy efficiency,optim,optimal,68,"cmake works now as expected, but implementation may be not the most optimal. . Especially `if(""${webui}"" STREQUAL ""OFF"")` statement for `webui` option.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3557
https://github.com/root-project/root/pull/3557:122,integrability,state,statement,122,"cmake works now as expected, but implementation may be not the most optimal. . Especially `if(""${webui}"" STREQUAL ""OFF"")` statement for `webui` option.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3557
https://github.com/root-project/root/pull/3557:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3557
https://github.com/root-project/root/pull/3558:152,energy efficiency,core,core,152,"Hi @anerokhi , thanks for the PR. Could you add a test for this feature? It could be located in a file https://github.com/root-project/root/tree/master/core/base/test here called ""ExecutorsTests.cxx"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:50,safety,test,test,50,"Hi @anerokhi , thanks for the PR. Could you add a test for this feature? It could be located in a file https://github.com/root-project/root/tree/master/core/base/test here called ""ExecutorsTests.cxx"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:162,safety,test,test,162,"Hi @anerokhi , thanks for the PR. Could you add a test for this feature? It could be located in a file https://github.com/root-project/root/tree/master/core/base/test here called ""ExecutorsTests.cxx"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:50,testability,test,test,50,"Hi @anerokhi , thanks for the PR. Could you add a test for this feature? It could be located in a file https://github.com/root-project/root/tree/master/core/base/test here called ""ExecutorsTests.cxx"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:162,testability,test,test,162,"Hi @anerokhi , thanks for the PR. Could you add a test for this feature? It could be located in a file https://github.com/root-project/root/tree/master/core/base/test here called ""ExecutorsTests.cxx"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:20,energy efficiency,current,currently,20,"TExecutor tests are currently in here https://github.com/root-project/roottest/blob/master/root/multicore/, but I agree that it would be much nicer to move them to gtest and have them in root :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:10,safety,test,tests,10,"TExecutor tests are currently in here https://github.com/root-project/roottest/blob/master/root/multicore/, but I agree that it would be much nicer to move them to gtest and have them in root :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:10,testability,test,tests,10,"TExecutor tests are currently in here https://github.com/root-project/roottest/blob/master/root/multicore/, but I agree that it would be much nicer to move them to gtest and have them in root :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:26,safety,test,test,26,"So where should I add the test? BTW, it is more than primitive. ```c++. ROOT::TThreadExecutor{}.Map([](int) { return make_unique<TList>(); }, { 1, 2, 3 });. ```. shall compile (not try to invoke the `delete`d `unique_ptr` copy constructor).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:26,testability,test,test,26,"So where should I add the test? BTW, it is more than primitive. ```c++. ROOT::TThreadExecutor{}.Map([](int) { return make_unique<TList>(); }, { 1, 2, 3 });. ```. shall compile (not try to invoke the `delete`d `unique_ptr` copy constructor).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:24,deployability,build,build,24,The `windows10/default` build fails because of roottest not being found in your GitHub (i.e. you didn't fork roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:30,deployability,fail,fails,30,The `windows10/default` build fails because of roottest not being found in your GitHub (i.e. you didn't fork roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:30,reliability,fail,fails,30,The `windows10/default` build fails because of roottest not being found in your GitHub (i.e. you didn't fork roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3558:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3558
https://github.com/root-project/root/pull/3566:23,safety,except,exception,23,@dpiparo why should an exception be thrown in this case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3566
https://github.com/root-project/root/pull/3567:130,availability,error,error,130,"Correct. Aliases are still global, there is a single map for those, but with this change it will not be possible to incurr in the error. I agree that Aliases should be made branch specific.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3567
https://github.com/root-project/root/pull/3567:180,interoperability,specif,specific,180,"Correct. Aliases are still global, there is a single map for those, but with this change it will not be possible to incurr in the error. I agree that Aliases should be made branch specific.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3567
https://github.com/root-project/root/pull/3567:130,performance,error,error,130,"Correct. Aliases are still global, there is a single map for those, but with this change it will not be possible to incurr in the error. I agree that Aliases should be made branch specific.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3567
https://github.com/root-project/root/pull/3567:130,safety,error,error,130,"Correct. Aliases are still global, there is a single map for those, but with this change it will not be possible to incurr in the error. I agree that Aliases should be made branch specific.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3567
https://github.com/root-project/root/pull/3567:130,usability,error,error,130,"Correct. Aliases are still global, there is a single map for those, but with this change it will not be possible to incurr in the error. I agree that Aliases should be made branch specific.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3567
https://github.com/root-project/root/pull/3568:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3568
https://github.com/root-project/root/pull/3571:18,deployability,build,builds,18,"As soon as the PR builds and passes all tests, it can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3571
https://github.com/root-project/root/pull/3571:40,safety,test,tests,40,"As soon as the PR builds and passes all tests, it can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3571
https://github.com/root-project/root/pull/3571:40,testability,test,tests,40,"As soon as the PR builds and passes all tests, it can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3571
https://github.com/root-project/root/pull/3571:11,deployability,build,build,11,@phsft-bot build on `windows10/default`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3571
https://github.com/root-project/root/pull/3573:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3573
https://github.com/root-project/root/pull/3574:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:85,deployability,build,build,85,"@gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:91,deployability,fail,failed,91,"@gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:91,reliability,fail,failed,91,"@gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:87,deployability,build,build,87,"> @gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks! Done right now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:93,deployability,fail,failed,93,"> @gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks! Done right now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:93,reliability,fail,failed,93,"> @gargvaibhav64 can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks! Done right now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3574:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3574
https://github.com/root-project/root/pull/3577:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3579:70,availability,state,statement-within-a-namespace-does,70,Background is here:. https://bitbucket.org/wlav/cppyy/issues/61/using-statement-within-a-namespace-does,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:70,integrability,state,statement-within-a-namespace-does,70,Background is here:. https://bitbucket.org/wlav/cppyy/issues/61/using-statement-within-a-namespace-does,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:99,reliability,doe,does,99,Background is here:. https://bitbucket.org/wlav/cppyy/issues/61/using-statement-within-a-namespace-does,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:615,availability,slo,slowness,615,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:197,deployability,updat,update,197,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:228,interoperability,standard,standards,228,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:366,interoperability,bind,bindings,366,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:431,interoperability,platform,platforms,431,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:539,interoperability,bind,bindings,539,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:324,modifiability,evolv,evolved,324,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:366,modifiability,bind,bindings,366,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:400,modifiability,portab,portable,400,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:539,modifiability,bind,bindings,539,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:259,reliability,doe,does,259,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:615,reliability,slo,slowness,615,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:926,reliability,doe,doesn,926,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:74,safety,compl,complex,74,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:155,safety,compl,complex,155,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:197,safety,updat,update,197,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:241,safety,Except,Except,241,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:74,security,compl,complex,74,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:155,security,compl,complex,155,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:197,security,updat,update,197,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:678,testability,simpl,simple,678,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:678,usability,simpl,simple,678,"@Axel-Naumann ,. ""This isn't going to ever work - C++ lookup is waaay too complex. And even if it were to work, we would be duplicating a large amount of (complex) functionality, and would have to update it with future language standards."". Except that a) it does work today (I think you're truly missing how much cppyy has evolved in functionality from the limited bindings that PyROOT offers, with portable binaries on all major platforms to boot), and b) most of the new language features are resolved in a way that is invisible to the bindings. A case like this PR is very rare. Neither this decl stuff nor the slowness of TClass and friends are material at this point (and simple to replace). What hurts cppyy much more, and what is taking up much more workaround code, is where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:220,availability,operat,operators,220,"> I think you're truly missing how much cppyy has evolved. Totally. That said you either re-implement lookup rules or they don't work properly, there's not a lot of middle ground... Templated constructors? ADL? Friended operators? What about spaceship? So much fun! > where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules. How are we then not talking about the same issue? Is it because you believe that I blame cppyy, while I merely describe the behavior? I.e. yes exactly, and as I really don't feel like messing with ROOT's type names our best way out is lookup: pass the original name to clang, no name normalization, and see what it says. How's that not addressing these issues?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:50,modifiability,evolv,evolved,50,"> I think you're truly missing how much cppyy has evolved. Totally. That said you either re-implement lookup rules or they don't work properly, there's not a lot of middle ground... Templated constructors? ADL? Friended operators? What about spaceship? So much fun! > where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules. How are we then not talking about the same issue? Is it because you believe that I blame cppyy, while I merely describe the behavior? I.e. yes exactly, and as I really don't feel like messing with ROOT's type names our best way out is lookup: pass the original name to clang, no name normalization, and see what it says. How's that not addressing these issues?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:416,reliability,doe,doesn,416,"> I think you're truly missing how much cppyy has evolved. Totally. That said you either re-implement lookup rules or they don't work properly, there's not a lot of middle ground... Templated constructors? ADL? Friended operators? What about spaceship? So much fun! > where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules. How are we then not talking about the same issue? Is it because you believe that I blame cppyy, while I merely describe the behavior? I.e. yes exactly, and as I really don't feel like messing with ROOT's type names our best way out is lookup: pass the original name to clang, no name normalization, and see what it says. How's that not addressing these issues?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:573,usability,behavi,behavior,573,"> I think you're truly missing how much cppyy has evolved. Totally. That said you either re-implement lookup rules or they don't work properly, there's not a lot of middle ground... Templated constructors? ADL? Friended operators? What about spaceship? So much fun! > where ROOT/meta breaks things, like removing std::, or tries too hard to be smart, like with template instantiations or overload matching, where it doesn't even follow C++'s rules. How are we then not talking about the same issue? Is it because you believe that I blame cppyy, while I merely describe the behavior? I.e. yes exactly, and as I really don't feel like messing with ROOT's type names our best way out is lookup: pass the original name to clang, no name normalization, and see what it says. How's that not addressing these issues?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:632,availability,operat,operator,632,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:712,availability,down,down,712,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:840,availability,operat,operator,840,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:192,deployability,releas,released,192,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:239,deployability,automat,automatic,239,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:661,interoperability,semant,semantics,661,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:1870,modifiability,maintain,maintain,1870,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:1885,performance,time,times,1885,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:54,safety,except,except,54,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:1645,safety,except,except,1645,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:1870,safety,maintain,maintain,1870,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:2443,safety,compl,completion,2443,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:157,security,hack,hack,157,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:1482,security,expos,expose,1482,"ork, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:2443,security,compl,completion,2443,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:239,testability,automat,automatic,239,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:695,testability,simpl,simply,695,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:339,usability,user,user,339,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:490,usability,user,user-provided,490,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:695,usability,simpl,simply,695,"Templated constructors actually work since last week (except not yet on Mac due to a bug in TClingCallFunc; I needed them for shared_ptr), and yes they're a hack. Code is in repo, but not yet released. ADL will never work properly in full automatic mode, but is already covered most of the way. I'm having that discussion right now with a user who wants to turn Python tuples into std::tuples: the problem is underspecified on the Python side. So although it can be made to generally work, user-provided types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:2459,usability,help,help,2459,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:2485,usability,interact,interactive,2485,"ed types are necessary to cover corner cases, e.g. by handing template arguments to std::make_tuple. Python's three-way comparison operator is only syntax, not semantics, so the spaceship would simply be broken down in Python's richcompare and the only real issue again is ROOT/meta giving wrong overloads. That said, I'm moving away from operator lookups: not only are the overloads often wrong, so I'm doing my own ADL, but also TClingCallFunc generates broken code on Mac and Windows. Rather, I want to use a generic comparison template and let SFINAE deal with it. The difference between removing std::, giving wrong overloads, etc. and string <-> decl is that the former is a problem b/c ROOT/meta gives the _wrong_ results. Strings are sometimes clunky, but perfectly fine if they are correct. Yes, letting clang parse names (as done for function template lookups already) is exactly what should happen. But the next step is to funnel the results to the Python mappings, not expose cppyy to decls or their intricate details. E.g. the converters and executor lookups should be a combination of strings and categories, just like it is now (except that the categories are derived from string parsing, like looking for ends_in('*')). Doing that selection based on decls as suggested here and in the e-mail thread with Gerhard makes no sense whatsoever: you'd have to maintain three times the same functionality. I would want something like this:. ```. opaque_handle h = what_is(parent, name). type_category t = what_type(h). qual_category q = what_qualifiers(h). true_name = unqualified_true(h). opaque_handle p = true_parent(h). etc. ```. with opaque_handle possibly the decl, and with t and q some enums or flags, and that would get rid of the name parsing in converters/executors, but NOT the string-based name lookups there. I do not need listings per se, not even for classes, but see GetAllCppNames(): something to feed to dir(), tab-completion, and help() remains needed for interactive use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:0,availability,Failur,Failure,0,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:0,deployability,Fail,Failure,0,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:104,deployability,updat,update,104,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:135,deployability,build,build,135,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:0,performance,Failur,Failure,0,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:43,performance,time,time,43,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:0,reliability,Fail,Failure,0,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:104,safety,updat,update,104,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:104,security,updat,update,104,Failure in filemerger is likely due to the time delay between the PR being merged and the corresponding update in roottest. @phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3580:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:78,deployability,build,build,78,"@arpi-r can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:84,deployability,fail,failed,84,"@arpi-r can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:84,reliability,fail,failed,84,"@arpi-r can you please fork https://github.com/root-project/roottest, windows build failed because it was not able to find your fork of roottest.git. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:13,availability,failur,failure,13,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:13,deployability,fail,failure,13,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:31,deployability,Build,Build,31,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:37,deployability,fail,failed,37,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:67,interoperability,plug,plugins,67,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:13,performance,failur,failure,13,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:13,reliability,fail,failure,13,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:37,reliability,fail,failed,37,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:75,usability,workflow,workflow,75,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3580:88,usability,Workflow,WorkflowRun,88,Unrelated CI failure `10:43:05 Build failed because: org.jenkinsci.plugins.workflow.job.WorkflowRun`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3580
https://github.com/root-project/root/pull/3583:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu16 with flags -Dcxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu16/default with flags -Dcxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:23,deployability,build,build,23,"@vgvassilev cxxmodules build will be broken, since clang HEAD was not build last few days (I am working on it)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:70,deployability,build,build,70,"@vgvassilev cxxmodules build will be broken, since clang HEAD was not build last few days (I am working on it)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu16/default with flags -Dcxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu1804-clangHEAD/default with flags -Dcxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:18,deployability,build,build,18,"Merging since the build is actually green, but there is no way to check cxxmodules builds in Jenkins [no node with clang compiler setup].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:83,deployability,build,builds,83,"Merging since the build is actually green, but there is no way to check cxxmodules builds in Jenkins [no node with clang compiler setup].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3583:36,energy efficiency,green,green,36,"Merging since the build is actually green, but there is no way to check cxxmodules builds in Jenkins [no node with clang compiler setup].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3583
https://github.com/root-project/root/pull/3584:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:10,deployability,Build,Building,10,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:31,deployability,build,build,31,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:65,deployability,build,build,65,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:71,deployability,build,build,71,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:133,deployability,FAIL,FAILED,133,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:358,deployability,build,build,358,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:392,deployability,build,build,392,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:77,energy efficiency,core,core,77,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:133,reliability,FAIL,FAILED,133,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:154,usability,Custom,CustomBuild,154,"`448>Done Building Project ""C:\build\workspace\root-pullrequests-build\build\core\clingutils\dequeDict.vcxproj"" (default targets) -- FAILED. 16:05:34 483>CustomBuild:. 16:05:34 <SeparateClass Prefixes:[""--""] Name:""metastr"">. 16:05:34 <JoinedClass Prefixes:[""-""] Name:""includedir_loc="">. 16:05:34 Options are not in order! 16:05:34 UNREACHABLE executed at C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Option\OptTable.cpp:134! 16:05:34 Exit code 0xc0000409`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:60,deployability,build,builds,60,"Hi @oshadura ,. Is there something that I can do to get the builds successful and get this PR merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:21,deployability,build,build,21,"@gargvaibhav64, yes, build was broken for the windows, now it also has conflicts, so you need to rebase on master and check how to fix windows build :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:143,deployability,build,build,143,"@gargvaibhav64, yes, build was broken for the windows, now it also has conflicts, so you need to rebase on master and check how to fix windows build :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:71,interoperability,conflict,conflicts,71,"@gargvaibhav64, yes, build was broken for the windows, now it also has conflicts, so you need to rebase on master and check how to fix windows build :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:32,deployability,fail,failing,32,@gargvaibhav64 Please check the failing tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:32,reliability,fail,failing,32,@gargvaibhav64 Please check the failing tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:40,safety,test,tests,40,@gargvaibhav64 Please check the failing tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:40,testability,test,tests,40,@gargvaibhav64 Please check the failing tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:13,availability,failur,failure,13,"Travis build failure is not connected with changes, I will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:7,deployability,build,build,7,"Travis build failure is not connected with changes, I will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:13,deployability,fail,failure,13,"Travis build failure is not connected with changes, I will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:13,performance,failur,failure,13,"Travis build failure is not connected with changes, I will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3584:13,reliability,fail,failure,13,"Travis build failure is not connected with changes, I will merge this PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3584
https://github.com/root-project/root/pull/3585:648,deployability,updat,updated,648,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:715,integrability,interfac,interface,715,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:715,interoperability,interfac,interface,715,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:715,modifiability,interfac,interface,715,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:648,safety,updat,updated,648,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:648,security,updat,updated,648,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:685,security,control,controlled,685,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:685,testability,control,controlled,685,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:453,usability,user,user,453,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:596,usability,document,documentation,596,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:659,usability,indicat,indicate,659,"It seems to me one can now do:. ```. root [0] ROOT::IsImplicitMTEnabled(). (bool) false. root [1] TMVA::gConfig().EnableMT(4). root [2] ROOT::IsImplicitMTEnabled(). (bool) false. root [3] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 4. ```. It could be expected that TMVA IMT implies ROOT IMT. And. ```. root [0] ROOT::EnableImplicitMT(4). root [1] TMVA::gConfig().GetThreadExecutor().GetPoolSize(). (unsigned int) 1. ```. Here the user may expect that TMVA uses IMT, however an extra `TMVA::gConfig().EnableMT()` is required. Are these two situations desirable? If not, the documentation of `ROOT::EnableImplicitMT` should be updated to indicate that TMVA IMT is controlled through a separate interface (`TMVA::gConfig()`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3588:115,availability,operat,operations,115,"I don't think 62b55ed9 is equivalent: what about e.g. the prompt showing `cling$` (that's not a wrapper), or async operations spawned by the wrapper? I don't see that this code needs fixing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3588
https://github.com/root-project/root/pull/3588:96,integrability,wrap,wrapper,96,"I don't think 62b55ed9 is equivalent: what about e.g. the prompt showing `cling$` (that's not a wrapper), or async operations spawned by the wrapper? I don't see that this code needs fixing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3588
https://github.com/root-project/root/pull/3588:141,integrability,wrap,wrapper,141,"I don't think 62b55ed9 is equivalent: what about e.g. the prompt showing `cling$` (that's not a wrapper), or async operations spawned by the wrapper? I don't see that this code needs fixing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3588
https://github.com/root-project/root/pull/3588:96,interoperability,wrapper,wrapper,96,"I don't think 62b55ed9 is equivalent: what about e.g. the prompt showing `cling$` (that's not a wrapper), or async operations spawned by the wrapper? I don't see that this code needs fixing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3588
https://github.com/root-project/root/pull/3588:141,interoperability,wrapper,wrapper,141,"I don't think 62b55ed9 is equivalent: what about e.g. the prompt showing `cling$` (that's not a wrapper), or async operations spawned by the wrapper? I don't see that this code needs fixing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3588
https://github.com/root-project/root/pull/3589:0,availability,Failur,Failures,0,"Failures are not connected with changes, this commit is just a revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:0,deployability,Fail,Failures,0,"Failures are not connected with changes, this commit is just a revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:0,performance,Failur,Failures,0,"Failures are not connected with changes, this commit is just a revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:0,reliability,Fail,Failures,0,"Failures are not connected with changes, this commit is just a revert.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3590:78,testability,simpl,simpler,78,"@vgvassilev . > Why didn’t you move this check in maybeMangleName? Well, it's simpler here (and only needed for globals anyway)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3590
https://github.com/root-project/root/pull/3590:78,usability,simpl,simpler,78,"@vgvassilev . > Why didn’t you move this check in maybeMangleName? Well, it's simpler here (and only needed for globals anyway)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3590
https://github.com/root-project/root/pull/3590:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3590
https://github.com/root-project/root/pull/3591:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:134,availability,failur,failure,134,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:51,deployability,depend,dependency,51,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:94,deployability,depend,depends,94,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:134,deployability,fail,failure,134,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:51,integrability,depend,dependency,51,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:94,integrability,depend,depends,94,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:114,integrability,event,event,114,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:51,modifiability,depend,dependency,51,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:94,modifiability,depend,depends,94,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:134,performance,failur,failure,134,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:134,reliability,fail,failure,134,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:51,safety,depend,dependency,51,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:94,safety,depend,depends,94,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:51,testability,depend,dependency,51,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:94,testability,depend,depends,94,The friend.make problem is likely due to a missing dependency in ctest (root-tree-friend-make depends and root-io-event). The windows failure is due to missing M_PI declaration.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3595:62,deployability,modul,modules,62,Hi @guitargeek under what circumstances is `ROOT` not in `sys.modules` at cleanup time?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:62,modifiability,modul,modules,62,Hi @guitargeek under what circumstances is `ROOT` not in `sys.modules` at cleanup time?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:82,performance,time,time,82,Hi @guitargeek under what circumstances is `ROOT` not in `sys.modules` at cleanup time?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:62,safety,modul,modules,62,Hi @guitargeek under what circumstances is `ROOT` not in `sys.modules` at cleanup time?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:129,availability,error,error,129,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:129,performance,error,error,129,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:295,performance,time,time,295,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:88,safety,isol,isolate,88,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:129,safety,error,error,129,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:192,safety,test,testing,192,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:88,security,iso,isolate,88,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:88,testability,isol,isolate,88,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:187,testability,unit,unit,187,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:192,testability,test,testing,192,"Hi @etejedor, thank's for taking care of this! I lack the technical knowledge to really isolate which circumstances lead to this error, that's why I described my use case with the python unit testing. Do you need some more details on what is exactly happening? Unfortunately I don't really have time do do some research on this this week thought...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
