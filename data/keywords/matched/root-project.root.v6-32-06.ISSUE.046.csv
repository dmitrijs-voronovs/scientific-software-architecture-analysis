id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/8221:517,security,patch,patches,517,"Fix problem building with gcc11.; gcc11 uses the `no_unique_address` attribute in its implementation of `std::tuple`. (which is then used by `std::unique_ptr`). However, it spells it. `__no_unique_address__`, which cling doesn't recognize. This can result. in having differing memory layouts for structures in compiled code versus. cling, which will cause mysterious failures. Patch cling to recognize `__no_unique_address__` as a synonym. for no_unique_address. See issue #8071. This should probably also go to 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8221
https://github.com/root-project/root/pull/8221:277,usability,memor,memory,277,"Fix problem building with gcc11.; gcc11 uses the `no_unique_address` attribute in its implementation of `std::tuple`. (which is then used by `std::unique_ptr`). However, it spells it. `__no_unique_address__`, which cling doesn't recognize. This can result. in having differing memory layouts for structures in compiled code versus. cling, which will cause mysterious failures. Patch cling to recognize `__no_unique_address__` as a synonym. for no_unique_address. See issue #8071. This should probably also go to 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8221
https://github.com/root-project/root/pull/8222:20,availability,failur,failure,20,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:20,deployability,fail,failure,20,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:478,deployability,patch,patches,478,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:370,energy efficiency,current,currently,370,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:114,integrability,schema,schema,114,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:9,interoperability,convers,conversion,9,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:166,interoperability,convers,conversion,166,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:20,performance,failur,failure,20,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:20,reliability,fail,failure,20,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:87,reliability,doe,does,87,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:478,safety,patch,patches,478,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:478,security,patch,patches,478,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8222:106,usability,support,support,106,"Fix type conversion failure in TBufferFile::ReadObjectAny.; TBufferFile::ReadObjectAny does not correctly support schema evolution,. because the fact that there is a conversion never gets passed to the. streamer. This was originally reported in ROOT-8367. See there for a reproducer. This implements the fix proposed in that report. ATLAS trigger code relies on this. I currently have a workaround in ATLAS,. but i'd like to be able to remove that. Should probably go into 6.24-patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8222
https://github.com/root-project/root/pull/8224:272,usability,guid,guide,272,"Try to hide fwd include in doxygen; Try to better fix https://github.com/root-project/root/issues/8051. In the files `Vector2-4-3D.h` the definitions in the fwd files are now duplicated, . in order typedef like `PtEtaPhiMVector` appears defined in `Vector4D.h` in the ref guide. as it is the file users should include.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8224
https://github.com/root-project/root/pull/8224:297,usability,user,users,297,"Try to hide fwd include in doxygen; Try to better fix https://github.com/root-project/root/issues/8051. In the files `Vector2-4-3D.h` the definitions in the fwd files are now duplicated, . in order typedef like `PtEtaPhiMVector` appears defined in `Vector4D.h` in the ref guide. as it is the file users should include.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8224
https://github.com/root-project/root/pull/8225:152,safety,prevent,prevent,152,"TF1/TString possible overflow fix + Warning in TString; I have tried to fix [this](https://github.com/root-project/root/issues/8136) issue. This should prevent a possible overflow in TF1, as now the min of the length of strlen(formula) and 5 is taken, therefore preventing a possible overflow. . Also in TString if the first n characters of cs conatin \0 it warns you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8225
https://github.com/root-project/root/pull/8225:262,safety,prevent,preventing,262,"TF1/TString possible overflow fix + Warning in TString; I have tried to fix [this](https://github.com/root-project/root/issues/8136) issue. This should prevent a possible overflow in TF1, as now the min of the length of strlen(formula) and 5 is taken, therefore preventing a possible overflow. . Also in TString if the first n characters of cs conatin \0 it warns you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8225
https://github.com/root-project/root/pull/8225:152,security,preven,prevent,152,"TF1/TString possible overflow fix + Warning in TString; I have tried to fix [this](https://github.com/root-project/root/issues/8136) issue. This should prevent a possible overflow in TF1, as now the min of the length of strlen(formula) and 5 is taken, therefore preventing a possible overflow. . Also in TString if the first n characters of cs conatin \0 it warns you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8225
https://github.com/root-project/root/pull/8225:262,security,preven,preventing,262,"TF1/TString possible overflow fix + Warning in TString; I have tried to fix [this](https://github.com/root-project/root/issues/8136) issue. This should prevent a possible overflow in TF1, as now the min of the length of strlen(formula) and 5 is taken, therefore preventing a possible overflow. . Also in TString if the first n characters of cs conatin \0 it warns you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8225
https://github.com/root-project/root/issues/8226:174,deployability,contain,contained,174,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:39,integrability,sub,sub-directory,39,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:700,integrability,sub,subdirectory,700,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:784,integrability,sub,subdirectory,784,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:14,performance,multi-thread,multi-thread,14,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:84,usability,clear,clear,84,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/issues/8226:132,usability,behavi,behavior,132,"[DF] Crash in multi-thread Snapshot in sub-directory; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The following is a self-contained reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main(). {. ROOT::RDataFrame(1000).Define(""x"", [] { return 42; }).Snapshot<int>(""t"", ""f.root"", {""x""});. ROOT::EnableImplicitMT();. auto df_bkg = ROOT::RDataFrame(""t"", ""f.root"");. ROOT::RDF::RSnapshotOptions opts;. opts.fAutoFlush = 10;. df_bkg.Snapshot<int>(""somedir/DecayTree"", ""bkg.root"", {""x""}, opts);. }. ```. The cause of the crash is a use-after-delete or a double-delete, caused by the following lines in `TFileMerger::MergeOne` which wrongly setup the subdirectory (owned by the parent file, owned by RDF) for deletion. Deletion of the subdirectory in turn causes the deletion of the output TTree that RDF is still using:. ```cpp. 556 TList dirtodelete;. 557 auto getDirectory = [&dirtodelete](TDirectory *parent, const char *name, const TString &pathname). 558 {. 559 TDirectory *result = dynamic_cast<TDirectory*>(parent->GetList()->FindObject(name));. 560 if (!result). 561 result = parent->GetDirectory(pathname);. 562 else. 563 dirtodelete.Add(result);. 564. 565 return result;. 566 };. ```. The bug affects any application using TFileMerger this way, of course, not just RDataFrame::Snapshot, but that's the most prominent case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8226
https://github.com/root-project/root/pull/8227:32,availability,error,error,32,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:55,availability,error,error,55,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:38,integrability,messag,message,38,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:61,integrability,messag,message,61,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:38,interoperability,messag,message,38,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:61,interoperability,messag,message,61,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:32,performance,error,error,32,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:55,performance,error,error,55,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:114,performance,disk,disk,114,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:321,performance,disk,disk,321,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:93,reliability,doe,doesn,93,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:32,safety,error,error,32,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:55,safety,error,error,55,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:32,usability,error,error,32,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8227:55,usability,error,error,55,"[ntuple] Improve column casting error message; Improve error message when the requested type doesn't match the on-disk type:. ```cpp. // underlying column is a double. auto view = ntuple->GetView<float>(""myDouble"");. ```. Before:. ```. Unexpected column type: Real64 of column #0 for field myDouble. ```. After:. ```. On-disk type `Real64` of column #0 for field `myDouble` is not convertible to requested type `Real32`. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227
https://github.com/root-project/root/pull/8228:72,energy efficiency,load,loading,72,TFileMerger _actually_ delete directory only if we induced its creation/loading; This is the actual heart of 30fd4c79425 which incorrect did the reverse. of its intent. This fixes #8226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8228
https://github.com/root-project/root/pull/8228:72,performance,load,loading,72,TFileMerger _actually_ delete directory only if we induced its creation/loading; This is the actual heart of 30fd4c79425 which incorrect did the reverse. of its intent. This fixes #8226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8228
https://github.com/root-project/root/pull/8229:78,energy efficiency,load,loading,78,v624: TFileMerger _actually_ delete directory only if we induced its creation/loading; This is the actual heart of 30fd4c79425 which incorrect did the reverse. of its intent. This fixes #8226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8229
https://github.com/root-project/root/pull/8229:78,performance,load,loading,78,v624: TFileMerger _actually_ delete directory only if we induced its creation/loading; This is the actual heart of 30fd4c79425 which incorrect did the reverse. of its intent. This fixes #8226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8229
https://github.com/root-project/root/pull/8230:43,energy efficiency,model,model,43,Actually request the use of the large code model for ppc64/ppc64le; Partial fix for ppc64le. See #8072.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8230
https://github.com/root-project/root/pull/8230:43,security,model,model,43,Actually request the use of the large code model for ppc64/ppc64le; Partial fix for ppc64le. See #8072.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8230
https://github.com/root-project/root/issues/8231:330,deployability,contain,containing,330,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8231:355,energy efficiency,model,model,355,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8231:236,interoperability,specif,specify,236,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8231:657,modifiability,paramet,parameter,657,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8231:355,security,model,model,355,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8231:102,usability,behavi,behaviour,102,"[RF] Fitting RooSimultaneous with Range option not accounting for range on the indexCat; The expected behaviour here would be if I define a range on the indexCat, the fit should only involve the pdfs of the categories in the range if I specify `Range(""rangeName"")` as an option to the `fitTo` method. Attached is a demo workspace containing a two-channel model with a floating norm factor on each channel. Ranges ""r1"" and ""r2"" have been defined on the category var which respectively only include one of the channels. However, running:. ```C++. w->pdf(""simPdf"")->fitTo(*w->data(""obsData""),RooFit::Range(""r1"")). ```. on the workspace shows that the floating parameter for both channels gets fit to. . [simDemo.zip](https://github.com/root-project/root/files/6531739/simDemo.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8231
https://github.com/root-project/root/issues/8232:459,availability,cluster,clusters,459,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:505,availability,cluster,clusters,505,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:553,availability,cluster,clusters,553,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1314,availability,cluster,clusters,1314,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1524,availability,cluster,cluster,1524,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1718,availability,cluster,clusters,1718,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:366,deployability,log,logic,366,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:459,deployability,cluster,clusters,459,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:505,deployability,cluster,clusters,505,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:553,deployability,cluster,clusters,553,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:573,deployability,depend,depending,573,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:694,deployability,resourc,resources,694,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1314,deployability,cluster,clusters,1314,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1336,deployability,depend,depending,1336,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1429,deployability,resourc,resources,1429,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1524,deployability,cluster,cluster,1524,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1718,deployability,cluster,clusters,1718,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1948,deployability,updat,updates,1948,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:171,energy efficiency,Current,Currently,171,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:694,energy efficiency,resourc,resources,694,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1291,energy efficiency,estimat,estimate,1291,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1429,energy efficiency,resourc,resources,1429,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1532,energy efficiency,estimat,estimates,1532,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1708,energy efficiency,estimat,estimated,1708,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:573,integrability,depend,depending,573,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1336,integrability,depend,depending,1336,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1506,integrability,translat,translate,1506,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:24,interoperability,distribut,distributed,24,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:251,interoperability,distribut,distributed,251,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:682,interoperability,distribut,distributed,682,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:899,interoperability,specif,specifically,899,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1000,interoperability,bind,bindings,1000,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1078,interoperability,share,share,1078,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1417,interoperability,distribut,distributed,1417,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1506,interoperability,translat,translate,1506,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1628,interoperability,distribut,distributed,1628,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:573,modifiability,depend,depending,573,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:604,modifiability,paramet,parameter,604,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1000,modifiability,bind,bindings,1000,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1336,modifiability,depend,depending,1336,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:16,performance,time,time,16,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:694,performance,resourc,resources,694,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:849,performance,overhead,overhead,849,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1429,performance,resourc,resources,1429,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:366,safety,log,logic,366,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:573,safety,depend,depending,573,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:694,safety,resourc,resources,694,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1210,safety,avoid,avoid,1210,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1336,safety,depend,depending,1336,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1429,safety,resourc,resources,1429,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1948,safety,updat,updates,1948,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:366,security,log,logic,366,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1948,security,updat,updates,1948,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:366,testability,log,logic,366,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:573,testability,depend,depending,573,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:694,testability,resourc,resources,694,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1336,testability,depend,depending,1336,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1429,testability,resourc,resources,1429,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1787,testability,context,context,1787,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8232:1816,testability,context,context,1816,"Improve startup time of distributed RDataFrame application; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Currently there is a setup step done in the client before actually starting the distributed computations. During the setup, a list of ranges of entries from the original dataset is computed. The logic is as follows:. 1. For each file of the dataset, open it and compute a list of all the clusters in the file. 2. From the list of all clusters of all files, divide it into groups of clusters (`Range`s) depending on the `npartitions` parameter of the dataframe. Each `Range` will be assigned its own task in the distributed resources. The point 1. above can be particularly expensive to run since it relies on `TFile::Open` . If the files of the dataset are stored remotely, the overhead adds up pretty quickly. The call happens specifically in:. https://github.com/root-project/root/blob/db3d4240abbda1c946fd2a7af08544cf1b357911/bindings/experimental/distrdf/python/DistRDF/Node.py#L363-L368. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Ideally we could avoid calling TFile::Open in the client. @Axel-Naumann proposed on mattermost to estimate the number of clusters of each file depending on its size and consequently compute the number of tasks to run on the distributed resources:. ```. If you have these files:. 50MB. 100MB. 300MB. 3GB. then I'd translate that to cluster estimates:. 2. 3. 10. 100. and split this into n tasks accordingly. ```. The single task in the distributed worker would then be responsible to open only the file(s) where the estimated clusters should be stored. This needs to be explored. ### Additional context. <!--. Add any other context about the problem here. -->. Thanks to @stwunsch for bringing this up. This issue will keep track of further discussion and updates on the matter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8232
https://github.com/root-project/root/issues/8233:246,deployability,version,version,246,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:307,deployability,stack,stack,307,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:246,integrability,version,version,246,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:246,modifiability,version,version,246,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:222,reliability,doe,does,222,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:129,testability,understand,understand,129,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:313,testability,trace,trace,313,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:591,testability,simul,simulations,591,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:822,testability,simul,simulations,822,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:0,usability,Minim,Minimizer,0,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/issues/8233:95,usability,minim,minimizer,95,"Minimizer class bug in ROOT 6.24/00; Hi! I would like to report bug in the ROOT 6.24/00 in the minimizer class. Honestly I don't understand what the problem is, but nor mine, nor the example code _NumericalMinimization.C_ does not run under this version of ROOT. I don't think its necessary, but I'm adding stack trace from run of the _NumericalMinimization()_ function from the example code. cheers,. matus. ```. ===========================================================. #5 0x00007fc0f68a084c in NumericalMinimization(char const*, char const*, int) () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #6 0x00007fc0f689b059 in ?? (). #7 0x0000000001fdea40 in ?? (). #8 0x0000000001fdea40 in ?? (). #9 0x0000000001de3a50 in ?? (). #10 0x00007fc0f68a07c0 in ?? () from /home/mbalogh/runningIntegral/simulations/VW_compare/test_cxx.so. #11 0x00007ffea57b5a50 in ?? (). #12 0x00007ffea57b5a50 in ?? (). #13 0x0000000001e9b430 in ?? (). #14 0x00007fc0f0915425 in cling::IncrementalExecutor::executeWrapper(llvm::StringRef, cling::Value*) const () from /opt/root_v6.24/build_dir/lib/libCling.so. #15 0x00007fc0f088de85 in cling::Interpreter::RunFunction(clang::FunctionDecl const*, cling::Value*) () from /opt/root_v6.24/build_dir/lib/libCling.so. #16 0x00007fc0f088f66d in cling::Interpreter::EvaluateInternal(std::string const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /opt/root_v6.24/build_dir/lib/libCling.so. #17 0x00007fc0f088f858 in cling::Interpreter::process(std::string const&, cling::Value*, cling::Transaction**, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #18 0x00007fc0f0973e08 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /opt/root_v6.24/build_dir/lib/libCling.so. #19 0x00007fc0f079579c in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /opt/root_v6.24",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8233
https://github.com/root-project/root/pull/8234:87,deployability,contain,contained,87,[cmake] fix escape characters in regex for header folders #7009; If `CMAKE_SOURCE_DIR` contained a special regex character it would not be properly matched against header folders and prevent relevant paths from being added into the `headerdirs` array. `CMAKE_SOURCE_DIR` is now replaced by a temporary copy where special characters have been escaped.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8234
https://github.com/root-project/root/pull/8234:183,safety,prevent,prevent,183,[cmake] fix escape characters in regex for header folders #7009; If `CMAKE_SOURCE_DIR` contained a special regex character it would not be properly matched against header folders and prevent relevant paths from being added into the `headerdirs` array. `CMAKE_SOURCE_DIR` is now replaced by a temporary copy where special characters have been escaped.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8234
https://github.com/root-project/root/pull/8234:183,security,preven,prevent,183,[cmake] fix escape characters in regex for header folders #7009; If `CMAKE_SOURCE_DIR` contained a special regex character it would not be properly matched against header folders and prevent relevant paths from being added into the `headerdirs` array. `CMAKE_SOURCE_DIR` is now replaced by a temporary copy where special characters have been escaped.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8234
https://github.com/root-project/root/pull/8235:187,integrability,sub,sub-regions,187,Fixed title offsetting when using absolute-size fonts and multiple pads; Found there was a small bug in calculation of offset that was affecting the calculation if you have pads that are sub-regions of the main pad,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235
https://github.com/root-project/root/pull/8236:28,interoperability,distribut,distributed,28,[DF] [skip-ci] Add docs for distributed Snapshot;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8236
https://github.com/root-project/root/pull/8237:11,deployability,releas,release,11,Make a pre-release check of clad. DONT MERGE.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8237
https://github.com/root-project/root/pull/8238:239,availability,slo,slow-memory-leak,239,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:62,energy efficiency,alloc,allocations,62,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:117,integrability,messag,messages,117,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:117,interoperability,messag,messages,117,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:9,performance,memor,memory,9,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:244,performance,memor,memory-leak,244,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:239,reliability,slo,slow-memory-leak,239,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:46,safety,avoid,avoid,46,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:9,usability,memor,memory,9,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8238:244,usability,memor,memory-leak,244,[RF] Fix memory leak in RooSecondMoment; Also avoid some heap allocations of `RooArgSet`s in `RooAbsPdf`. See commit messages for more information. The leak was a problem reported in the forum:. https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8238
https://github.com/root-project/root/pull/8239:10,deployability,configurat,configuration,10,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:28,deployability,build,build,28,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:47,deployability,Version,Versions,47,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:10,integrability,configur,configuration,10,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:47,integrability,Version,Versions,47,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:10,modifiability,configur,configuration,10,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:47,modifiability,Version,Versions,47,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8239:10,security,configur,configuration,10,"Fix CMake configuration and build with oneTBB; Versions newer than 2021 don't have the header tbb/tbb_config.h,. see https://github.com/cms-sw/cmsdist/pull/6936",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8239
https://github.com/root-project/root/pull/8240:151,deployability,manag,manages,151,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:311,deployability,depend,dependencies,311,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:1001,deployability,observ,observable,1001,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:151,energy efficiency,manag,manages,151,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:373,energy efficiency,schedul,schedules,373,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:441,energy efficiency,schedul,schedule,441,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:1023,energy efficiency,model,model,1023,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:20,integrability,batch,batch,20,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:84,integrability,batch,batch,84,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:311,integrability,depend,dependencies,311,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:920,integrability,event,events,920,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:68,interoperability,skeleton,skeleton,68,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:688,interoperability,architectur,architecture-specific,688,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:311,modifiability,depend,dependencies,311,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:987,modifiability,paramet,parameter,987,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:20,performance,batch,batch,20,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:84,performance,batch,batch,84,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:337,performance,memor,memory,337,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:373,performance,schedul,schedules,373,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:441,performance,schedul,schedule,441,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:450,performance,multi-thread,multi-threaded,450,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:577,performance,perform,performing,577,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:151,safety,manag,manages,151,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:311,safety,depend,dependencies,311,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:1023,security,model,model,1023,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:311,testability,depend,dependencies,311,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:1001,testability,observ,observable,1001,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:337,usability,memor,memory,337,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8240:577,usability,perform,performing,577,"[RF] Introduce CUDA batch computations.; In this PR I implement the skeleton of the batch compute library as well as the new class RooFitDriver, which manages all the computations that need to be done in a fit and redirects them to the RooBatchCompute library. RooFitDriver: scans the computation graph for the dependencies, handles the memory needed for the computations, schedules the order of the computations (in the future it will also schedule multi-threaded computations). In other words it ""drives"" the computation library. RooBatchCompute: the library responsible for performing the actual computations. Each instance of it (eg RooBatchCompute_AVX, RooBatchCompute_CUDA etc) has architecture-specific code. To use it, one (a PDF or another RooAbsReal class) should call rbc::dispatch() and provide the enum name of the computing function to be used, the array in which the output should be store, the number of events and an rbc::DataMap object which holds the values for every parameter and observable in the fit model.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8240
https://github.com/root-project/root/pull/8241:27,interoperability,semant,semantics,27,[DF][NFC][skip-ci] Clarify semantics of ActionHelper::GetResultPtr;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8241
https://github.com/root-project/root/pull/8242:12,deployability,Fail,Fail,12,[tutorials] Fail gracefully if Minuit2 is not built (issue #8233);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8242
https://github.com/root-project/root/pull/8242:12,reliability,Fail,Fail,12,[tutorials] Fail gracefully if Minuit2 is not built (issue #8233);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8242
https://github.com/root-project/root/pull/8243:538,deployability,build,builds,538,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:6,interoperability,standard,standards-based,6,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:121,interoperability,standard,standards-based,121,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:160,interoperability,conflict,conflict,160,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:174,usability,user,user-defined,174,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:243,usability,behavi,behavior,243,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8243:323,usability,behavi,behavior,323,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backported from llvm-project 2ed4573e8f8619dc67647256ac070bf91f461392. Fixes GCC 11 builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8243
https://github.com/root-project/root/pull/8244:133,deployability,build,builds,133,[cling] Trust that GCC has `__attribute__` `visibility`:; GCC 4.8 (which we support...) does not have __has_attribute. Fixes CentOS7 builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8244
https://github.com/root-project/root/pull/8244:88,reliability,doe,does,88,[cling] Trust that GCC has `__attribute__` `visibility`:; GCC 4.8 (which we support...) does not have __has_attribute. Fixes CentOS7 builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8244
https://github.com/root-project/root/pull/8244:8,security,Trust,Trust,8,[cling] Trust that GCC has `__attribute__` `visibility`:; GCC 4.8 (which we support...) does not have __has_attribute. Fixes CentOS7 builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8244
https://github.com/root-project/root/pull/8244:76,usability,support,support,76,[cling] Trust that GCC has `__attribute__` `visibility`:; GCC 4.8 (which we support...) does not have __has_attribute. Fixes CentOS7 builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8244
https://github.com/root-project/root/issues/8245:5,availability,failur,failures,5,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:5,deployability,fail,failures,5,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:38,deployability,build,building,38,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:106,deployability,FAIL,FAILED,106,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:160,deployability,Fail,Failed,160,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:214,deployability,Fail,Failed,214,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:266,deployability,Fail,Failed,266,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:323,deployability,Fail,Failed,323,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:369,deployability,build,building,369,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:412,deployability,version,versions,412,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:612,deployability,version,versions,612,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:412,integrability,version,versions,412,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:612,integrability,version,versions,612,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:412,modifiability,version,versions,412,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:612,modifiability,version,versions,612,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:5,performance,failur,failures,5,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:5,reliability,fail,failures,5,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:106,reliability,FAIL,FAILED,106,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:160,reliability,Fail,Failed,160,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:214,reliability,Fail,Failed,214,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:266,reliability,Fail,Failed,266,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:323,reliability,Fail,Failed,323,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:0,safety,Test,Test,0,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:100,safety,test,tests,100,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:430,safety,test,tests,430,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:0,testability,Test,Test,0,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:100,testability,test,tests,100,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/issues/8245:430,testability,test,tests,430,"Test failures in tutorial-roofit when building without FFTW; On my system I get. ```. The following tests FAILED:. 1061 - tutorial-roofit-rf208_convolution-py (Failed). 1063 - tutorial-roofit-rf210_angularconv-py (Failed). 1064 - tutorial-roofit-rf211_paramconv-py (Failed). 1095 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. The reason seems to be that I'm building without FFTW, and while the macro versions of those tests are correctly vetoed:. https://github.com/root-project/root/blob/098dfcf94a3939597488fef9ee128b3d2e1e591f/tutorials/CMakeLists.txt#L191-L198. similar action is missing for the versions written in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8245
https://github.com/root-project/root/pull/8246:16,security,triag,triage,16,[github] Remove triage project workflow.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8246
https://github.com/root-project/root/pull/8246:31,usability,workflow,workflow,31,[github] Remove triage project workflow.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8246
https://github.com/root-project/root/pull/8247:254,availability,slo,slow-memory-leak,254,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:15,performance,memor,memory,15,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:154,performance,memor,memory,154,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:259,performance,memor,memory-leak,259,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:324,performance,memor,memory-leak,324,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:354,performance,time,time,354,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:254,reliability,slo,slow-memory-leak,254,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:15,usability,memor,memory,15,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:154,usability,memor,memory,154,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:259,usability,memor,memory-leak,259,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8247:324,usability,memor,memory-leak,324,[v624][RF] Fix memory leak in RooSecondMoment; Backport of https://github.com/root-project/root/pull/8238. The backport is motivated by the fact that the memory leak was already reported in the forum twice:. * https://root-forum.cern.ch/t/roomomentmorph-slow-memory-leak/45062. * https://root-forum.cern.ch/t/roomomentmorph-memory-leak/26756. ...and one time on the old roottalk:. https://groups.cern.ch/group/roottalk/Lists/Archive/Flat.aspx?RootFolder=%2fgroup%2froottalk%2fLists%2fArchive%2fRooMomentMorph%20getVal%28%29%20call%20increases%20memory%20a%20lot&FolderCTID=0x01200200A201AF59FD011C4E9284C43BF0CDA2A4,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8247
https://github.com/root-project/root/pull/8248:94,deployability,version,versions,94,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:204,deployability,build,build,204,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:210,deployability,configurat,configurations,210,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:94,integrability,version,versions,94,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:210,integrability,configur,configurations,210,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:94,modifiability,version,versions,94,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:210,modifiability,configur,configurations,210,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/pull/8248:210,security,configur,configurations,210,[RF][Tutorials] Add missing vetos for python RooFit tutorials; Some of the newly added python versions of RooFit tutorials from PR https://github.com/root-project/root/pull/8091 need to be vetoes in some build configurations. I checked the `CMakeLists.txt` file for vetes C++ tutorials to see where I was missing to veto a corresponding new python tutorial. This fixes issue https://github.com/root-project/root/issues/8245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8248
https://github.com/root-project/root/issues/8250:434,availability,avail,available,434,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:445,availability,Error,Error,445,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:523,availability,Error,Error,523,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:339,deployability,fail,fails,339,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:891,deployability,version,versions,891,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:189,integrability,coupl,couple,189,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:248,integrability,event,event,248,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:315,integrability,Event,EventDis,315,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:419,integrability,Event,EventPythia,419,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:891,integrability,version,versions,891,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:111,modifiability,inherit,inherits,111,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:189,modifiability,coupl,couple,189,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:291,modifiability,Inherit,InheritsFrom,291,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:891,modifiability,version,versions,891,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:445,performance,Error,Error,445,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:523,performance,Error,Error,523,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:339,reliability,fail,fails,339,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:434,reliability,availab,available,434,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:434,safety,avail,available,434,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:445,safety,Error,Error,445,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:523,safety,Error,Error,523,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:783,safety,test,tested,783,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:880,safety,test,test,880,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:434,security,availab,available,434,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:189,testability,coupl,couple,189,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:783,testability,test,tested,783,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:880,testability,test,test,880,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:445,usability,Error,Error,445,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:523,usability,Error,Error,523,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:620,usability,interact,interactively,620,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:693,usability,minim,minimal,693,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/issues/8250:753,usability,behavi,behavior,753,"Root 6.20.06+ - New bug with compiled code using TClass / dictionaries; I'm creating a TTree with a class that inherits from a base class, without a problem. However, in the same program a couple lines later,. ```. TClass branchClass(c->GetBranch(""event"")->GetClassName());. if (branchClass.InheritsFrom(""dicttest::EventDis"") {....}. ```. fails with. ```. Warning in <TClass::TClass>: no dictionary for class dicttest::EventPythia is available. Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). Error in <TObjArray::At>: index 0 out of bounds (size: 1, this: 0x127faed70). ```. It works fine interactively but not when compiled. I have a demonstrator that's pretty minimal here:. https://github.com/kkauder/rootbreaker. This behavior is new to root 6.24, tested on Apple M1 and Ubuntu. The same code worked fine in root 6.20.04; I haven't been able to test other versions. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8250
https://github.com/root-project/root/pull/8251:15,deployability,scale,scale,15,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:103,deployability,scale,scale-for-plotting,103,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:15,energy efficiency,scale,scale,15,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:103,energy efficiency,scale,scale-for-plotting,103,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:15,modifiability,scal,scale,15,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:103,modifiability,scal,scale-for-plotting,103,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:15,performance,scale,scale,15,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/pull/8251:103,performance,scale,scale-for-plotting,103,Provide symlog scale for RAxis; Triggered by discussion on forum:. https://root-forum.cern.ch/t/symlog-scale-for-plotting/. Include tutorial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8251
https://github.com/root-project/root/issues/8252:98,availability,operat,operator,98,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:364,energy efficiency,Draw,Draw,364,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:548,energy efficiency,Draw,Draw,548,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:47,performance,time,time,47,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:583,performance,perform,performs,583,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:740,testability,simpl,simple,740,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:583,usability,perform,performs,583,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/issues/8252:740,usability,simpl,simple,740,"Bug when using a Convolution in TF1 the second time with a different range; When using the `CONV` operator in TF1 with a different range, but re-using the same function, the new range is not used correctly. . This code shows the problem: . ```. auto f1 = new TF1(""f1"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",0,10);. f1->SetParameters(5,1,1,0,1); . f1->Draw(); // this is ok. // do convolution in a different range. auto f2 = new TF1(""f2"",""CONV(ROOT::Math::breitwigner_pdf(x,[1],[0]),gaus)"",10,20); . f2->SetParameters(15,1,1,0,1);. f2->Draw(); // WRONG result because it performs convolution in 0,10 instead of 10,20. ```. This problem has been reported in https://root-forum.cern.ch/t/fitting-histograms-convolution/44973/7. A simple workaround is just to call:. ```. f2-SetRange(10,20); . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8252
https://github.com/root-project/root/pull/8253:50,availability,operat,operator,50,Fix setting convolution range when using the CONV operator.; This fixes ROOT issue #8252,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8253
https://github.com/root-project/root/pull/8255:67,availability,error,errors,67,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:480,availability,error,error,480,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:80,deployability,build,building,80,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:208,deployability,Releas,Release,208,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:880,deployability,build,build,880,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:906,deployability,fail,failed,906,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:746,energy efficiency,core,core,746,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:895,integrability,sub,subcommand,895,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:67,performance,error,errors,67,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:480,performance,error,error,480,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:906,reliability,fail,failed,906,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:67,safety,error,errors,67,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:480,safety,error,error,480,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:67,usability,error,errors,67,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:133,usability,command,command,133,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:480,usability,error,error,480,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/pull/8255:886,usability,stop,stopped,886,"Fix invalid use of incomplete class in RWebBrowserImp; I got these errors while building from master on Fedora 32 with the following command `cmake -GNinja -Ddev=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release` . ```. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx: In member function ‘virtual void ROOT::Experimental::RWebBrowserImp::BrowseObj(TObject*)’:. /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:89:31: error: invalid use of incomplete type ‘class TSeqCollection’. 89 | if (gROOT->GetListOfFiles()->FindObject(obj)). | ^~. In file included from /home/vpadulan/Programs/rootproject/root/gui/browserv7/src/RWebBrowserImp.cxx:15:. /home/vpadulan/Programs/rootproject/root/core/base/inc/TROOT.h:59:7: note: forward declaration of ‘class TSeqCollection’. 59 | class TSeqCollection;. | ^~~~~~~~~~~~~~. ninja: build stopped: subcommand failed. ```. Not sure if it's the right fix, but I thought it was worth mentioning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8255
https://github.com/root-project/root/issues/8256:204,availability,error,error,204,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15280,availability,state,statements,15280,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15386,availability,error,error,15386,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15488,availability,error,error,15488,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1002,energy efficiency,Draw,Draw,1002,"rupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1022,energy efficiency,Draw,Draw,1022,"_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15275,energy efficiency,draw,draw,15275,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15362,energy efficiency,draw,draw,15362,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15405,energy efficiency,reduc,reduce,15405,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15280,integrability,state,statements,15280,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1117,interoperability,share,shared,1117," program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c0000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:204,performance,error,error,204,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1779,performance,Memor,Memory,1779," ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd64074400",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15386,performance,error,error,15386,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15475,performance,content,content,15475,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15488,performance,error,error,15488,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:204,safety,error,error,204,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:525,safety,test,test,525,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1048,safety,test,test,1048,"inter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1163,safety,test,test,1163,"ith the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd64",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1168,safety,test,test,1168,"he 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c30",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1227,safety,test,test,1227,"nimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1856,safety,test,test,1856,"s *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd6409",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1861,safety,test,test,1861,"= new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1922,safety,test,test,1922,"nt(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1927,safety,test,test,1927," i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1988,safety,test,test,1988,"e(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640945000-7fd640946000 rw-p 00003000 08:02 80985 /usr/li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1993,safety,test,test,1993,";. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640945000-7fd640946000 rw-p 00003000 08:02 80985 /usr/lib64/l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15386,safety,error,error,15386,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15488,safety,error,error,15488,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:461,testability,UNIT,UNITS,461,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:505,testability,UNIT,UNITS,505,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:525,testability,test,test,525,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:663,testability,UNIT,UNITS,663,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1048,testability,test,test,1048,"inter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1163,testability,test,test,1163,"ith the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd64",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1168,testability,test,test,1168,"he 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c30",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1227,testability,test,test,1227,"nimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1856,testability,test,test,1856,"s *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd6409",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1861,testability,test,test,1861,"= new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1922,testability,test,test,1922,"nt(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1927,testability,test,test,1927," i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1988,testability,test,test,1988,"e(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640945000-7fd640946000 rw-p 00003000 08:02 80985 /usr/li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1993,testability,test,test,1993,";. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640744000-7fd640944000 ---p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640944000-7fd640945000 r--p 00002000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd640945000-7fd640946000 rw-p 00003000 08:02 80985 /usr/lib64/l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15243,testability,UNIT,UNITS,15243,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15430,testability,UNIT,UNITS,15430,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:204,usability,error,error,204,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:227,usability,minim,minimum,227,"'corrupted size vs. prev_size' triggered by HistPainter; Hello: . I came across a problem with ROOT recently, though the program gives the expected result, it ends with the 'corrupted size vs. prev_size' error. Here I show the minimum code that can reproduce the code. Running conditions:. * OS: Linux_CentOS7.7.1908-x86_64-gcc5.2.0. * ROOT: 6.08.00. * GCC: 5.2.0. . code: . file1: inc.cxx. ```cpp. #include <map>. // extern std::map<std::string, const double> UNITS;. std::map<std::string, const double> UNITS;. ```. file2: test.cxx. ```cpp. #include <map>. #include ""TGraphErrors.h"". #include ""TH1F.h"". #include ""TCanvas.h"". std::map<std::string, const double> UNITS = {. {"""",	1},. {""mm"", 1e-3},. };. int main() {. 	double value[] = {1, 2, 3, 4, 5};. TCanvas *c = new TCanvas(""c"", ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:1779,usability,Memor,Memory,1779," ""c"", 1200, 900);. 	TH1F *h = new TH1F(""h"", ""h"", 5, 0.5, 5.5);. 	TGraphErrors *g = new TGraphErrors();. 	for(int i=0; i<5; i++) {. 		g->SetPoint(i, i+1, value[i]);. 		h->Fill(value[i]);. 	}. 	g->SetMarkerStyle(20);. 	g->Draw(""AP"");. 	// h->Draw(""HIST"");. 	c->Print(""test.png"");. return 0;. }. ```. compiling:. * g++ -std=c++11 -fPIC --shared -o inc.so inc.cxx. * g++ -std=c++11 -o test test.cxx inc.so `root-config --libs --glibs --cflags` && ./test. . result:. ```. ======= Backtrace: =========. /lib64/libc.so.6(+0x80f87)[0x7fd6589a6f87]. /lib64/libc.so.6(+0x8155e)[0x7fd6589a755e]. /lib64/libfreetype.so.6(+0x3ea1c)[0x7fd65771ea1c]. /lib64/libfreetype.so.6(+0x3fa02)[0x7fd65771fa02]. /lib64/libfreetype.so.6(+0x1fd4c)[0x7fd6576ffd4c]. /lib64/libfreetype.so.6(FT_Done_Face+0xa1)[0x7fd6576ffe51]. /root/6.08.00/lib/libGraf.so.6.08(_ZN3TTF7CleanupEv+0x5e)[0x7fd65bb62a7e]. /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd65896000a]. /root/6.08.00/lib/libGraf.so.6.08(+0x638a3)[0x7fd65baef8a3]. ======= Memory map: ========. 00400000-0040b000 r-xp 00000000 00:2e 3242707291 /work/test/test. 0060a000-0060b000 r--p 0000a000 00:2e 3242707291 /work/test/test. 0060b000-0060c000 rw-p 0000b000 00:2e 3242707291 /work/test/test. 01644000-02e78000 rw-p 00000000 00:00 0 [heap]. 7fd638000000-7fd638021000 rw-p 00000000 00:00 0 . 7fd638021000-7fd63c000000 ---p 00000000 00:00 0 . 7fd63ffc8000-7fd6400c3000 r--p 00000000 00:32 432514122 /root/6.08.00/fonts/FreeSans.otf. 7fd6400c3000-7fd640142000 r-xp 00000000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640142000-7fd640342000 ---p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640342000-7fd640344000 r--p 0007f000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640344000-7fd640346000 rw-p 00081000 00:32 432291140 /root/6.08.00/lib/libHistPainter.so.6.08.00. 7fd640346000-7fd640347000 rw-p 00000000 00:00 0 . 7fd640742000-7fd640744000 r-xp 00000000 08:02 80985 /usr/lib64/libXau.so.6.0.0. 7fd64074400",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15386,usability,error,error,15386,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/issues/8256:15488,usability,error,error,15488,"f000-7fd6579a7000 r-xp 00000000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd6579a7000-7fd657ba6000 ---p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba6000-7fd657ba7000 r--p 00007000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba7000-7fd657ba8000 rw-p 00008000 08:02 80449 /usr/lib64/libcrypt-2.17.so. 7fd657ba8000-7fd657bd6000 rw-p 00000000 00:00 0 . 7fd657bd6000-7fd657e0c000 r-xp 00000000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd657e0c000-7fd65800c000 ---p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd65800c000-7fd658028000 r--p 00236000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658028000-7fd658035000 rw-p 00252000 08:02 344532 /usr/lib64/libcrypto.so.1.0.2k. 7fd658035000-7fd658039000 rw-p 00000000 00:00 0 . 7fd658039000-7fd6580a0000 r-xp 00000000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6580a0000-7fd6582a0000 ---p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a0000-7fd6582a4000 r--p 00067000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582a4000-7fd6582ab000 rw-p 0006b000 08:02 344534 /usr/lib64/libssl.so.1.0.2k. 7fd6582ab000-7fd6582c0000 r-xp 00000000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6582c0000-7fd6584bf000 ---p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584bf000-7fd6584c0000 r--p 00014000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c0000-7fd6584c1000 rw-p 00015000 08:02 80883 /usr/lib64/libz.so.1.2.7. 7fd6584c1000-7fd6584c3000 r-xp 00000000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6584c3000-7fd6586c2000 ---p 00002000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1. 7fd6586c2000-7fd6586c3000 r--p 00001000 08:02 80878 /usr/lib64/libpcreposix.so.0.0.1bash-4.2$ . ```. Obviously, the problem is the redefinition of UNITS; but if I comment out the draw statements, that the program can run smoothly, so it looks to me that somehow the draw method trigger the error. And I can't reduce the definition of UNITS further, when I comment out any of the content, the error become 'double free or corruption'",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8256
https://github.com/root-project/root/pull/8258:21,interoperability,semant,semantic,21,Cling visibility and semantic interposition v624; Backport of https://github.com/root-project/root/pull/8204 and https://github.com/root-project/root/pull/8244,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8258
https://github.com/root-project/root/pull/8259:6,interoperability,standard,standards-based,6,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/pull/8259:121,interoperability,standard,standards-based,121,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/pull/8259:160,interoperability,conflict,conflict,160,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/pull/8259:174,usability,user,user-defined,174,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/pull/8259:243,usability,behavi,behavior,243,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/pull/8259:323,usability,behavi,behavior,323,"Allow standards-based attributes to have leading and trailing underscores.; This gives library implementers a way to use standards-based attributes that do not conflict with user-defined macros of the same name. Attributes in C2x require this behavior normatively (C2x 6.7.11p4), but there's no reason to not have the same behavior in C++, especially given that such attributes may be used by a C library consumed by a C++ compilation. llvm-svn: 369033. Backport of https://github.com/root-project/root/pull/8243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8259
https://github.com/root-project/root/issues/8260:0,deployability,Build,Build,0,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:27,deployability,version,version,27,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:99,deployability,version,versions,99,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:53,energy efficiency,current,current,53,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:27,integrability,version,version,27,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:99,integrability,version,versions,99,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:27,modifiability,version,version,27,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:99,modifiability,version,versions,99,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:20,safety,detect,detect,20,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:92,safety,detect,detect,92,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:20,security,detect,detect,20,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8260:92,security,detect,detect,92,"Build system cannot detect version of oneTBB; ROOT's current copy of `FindTBB.cmake` cannot detect versions of newer TBBs without the header `tbb/tbb_stddef.h`. As a result, `TBB_VERSION` is unset and cannot be used for further checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8260
https://github.com/root-project/root/issues/8261:133,deployability,Fail,Failed,133,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:187,deployability,Fail,Failed,187,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:239,deployability,Fail,Failed,239,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:296,deployability,Fail,Failed,296,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:410,integrability,Configur,Configure,410,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:410,modifiability,Configur,Configure,410,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:133,reliability,Fail,Failed,133,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:187,reliability,Fail,Failed,187,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:239,reliability,Fail,Failed,239,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:296,reliability,Fail,Failed,296,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:425,safety,test,testing,425,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:451,safety,test,tests,451,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:410,security,Configur,Configure,410,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:425,testability,test,testing,425,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:451,testability,test,tests,451,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:473,testability,context,context,473,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/issues/8261:355,usability,behavi,behavior,355,"[RF] tutorial/rf208,210,211,512 must be disabled without FFT; ### Describe the bug. ``` 1018 - tutorial-roofit-rf208_convolution-py (Failed). 1020 - tutorial-roofit-rf210_angularconv-py (Failed). 1021 - tutorial-roofit-rf211_paramconv-py (Failed). 1052 - tutorial-roofit-rf512_wsfactory_oper-py (Failed). ```. if ROOT is not built with fft3. ### Expected behavior. The tutorials are skipped. ### To Reproduce. Configure with testing, without fft, run tests. ### Additional context. Add to `fftw3_veto` in `tutorials/CMakeLists.txt`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8261
https://github.com/root-project/root/pull/8262:5,deployability,Updat,Update,5,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:257,deployability,version,versions,257,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:257,integrability,version,versions,257,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:247,modifiability,paramet,parameter,247,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:257,modifiability,version,versions,257,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:398,performance,memor,memory,398,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:5,safety,Updat,Update,5,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:5,security,Updat,Update,5,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8262:398,usability,memor,memory,398,"[RF] Update RooAbsReal to use less owning pointers; A modernization that came to my mind when I read the `RooAbsReal` source code to investigate an issue reported on the forum. Using less owning pointers in RooAbsReal is achieved using the output parameter versions of. `RooAbsArg::getParameters`, `RooAbsArg::getObservables`, and. `RooAbsCollection::selectCommon`. This also fixes multiple actual memory leaks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8262
https://github.com/root-project/root/pull/8263:314,deployability,API,API,314,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:398,deployability,fail,fails,398,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:263,integrability,wrap,wrapper,263,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:314,integrability,API,API,314,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:431,integrability,wrap,wrapper,431,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:181,interoperability,standard,standard,181,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:263,interoperability,wrapper,wrapper,263,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:314,interoperability,API,API,314,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:431,interoperability,wrapper,wrapper,431,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:294,modifiability,paramet,parameter,294,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8263:398,reliability,fail,fails,398,"[PyROOT][8152] Ignore warnings about register keyword; Python2 headers still use the register keyword, which causes. issues when compiling ROOT with C++ 17, since that is also the. standard that will be used for jitting. In particular, when cppyy generates a C++ wrapper for a Python. callable parameter, CPyCppyy/API.h is jitted and so are the. Python headers. In Python2 with C++17, such jitting fails and,. as a result, the C++ wrapper can't be generated. This commit ignores -Wregister when in Python2 and C++ 17. Fixes #8152",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8263
https://github.com/root-project/root/pull/8265:1,energy efficiency,core,core,1,[core/cling] modernize nullptr; by clang-tidy,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8265
https://github.com/root-project/root/issues/8267:295,energy efficiency,core,core,295,"-Wundef RStringView MSVC_LANG; ### Describe the bug. New warnings appearing when using ROOT in my projects:. `/opt/root/include/ROOT/RStringView.hxx: warning: ""_MSVC_LANG"" is not defined, evaluates to 0 [-Wundef]`. after the recent commits on https://github.com/root-project/root/commits/master/core/foundation/inc/ROOT/RStringView.hxx. ### Expected behavior. No warnings. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. Self-built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8267
https://github.com/root-project/root/issues/8267:350,usability,behavi,behavior,350,"-Wundef RStringView MSVC_LANG; ### Describe the bug. New warnings appearing when using ROOT in my projects:. `/opt/root/include/ROOT/RStringView.hxx: warning: ""_MSVC_LANG"" is not defined, evaluates to 0 [-Wundef]`. after the recent commits on https://github.com/root-project/root/commits/master/core/foundation/inc/ROOT/RStringView.hxx. ### Expected behavior. No warnings. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. Self-built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8267
https://github.com/root-project/root/issues/8268:0,availability,Error,Error,0,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:115,availability,Error,Error,115,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1536,availability,Error,Error,1536,"on_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=36",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1672,availability,Error,Error,1672,"ent.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3392,availability,Operat,Operating,3392,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3440,availability,down,download,3440,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1933,deployability,version,version,1933,""", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2063,deployability,version,versions,2063,"d"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2239,deployability,version,version,2239,"he example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2464,deployability,version,version,2464,"st.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it your",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2742,deployability,version,version,2742,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2967,deployability,version,version,2967,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3157,deployability,version,version,3157,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3350,deployability,version,version,3350,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3379,deployability,patch,patches,3379,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1495,energy efficiency,Load,Load,1495,"est_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:387,integrability,pub,public,387,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:405,integrability,pub,public,405,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1933,integrability,version,version,1933,""", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2063,integrability,version,versions,2063,"d"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2239,integrability,version,version,2239,"he example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2464,integrability,version,version,2464,"st.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it your",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2742,integrability,version,version,2742,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2967,integrability,version,version,2967,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3157,integrability,version,version,3157,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3350,integrability,version,version,3350,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1933,modifiability,version,version,1933,""", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2063,modifiability,version,versions,2063,"d"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2239,modifiability,version,version,2239,"he example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2464,modifiability,version,version,2464,"st.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it your",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2742,modifiability,version,version,2742,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2967,modifiability,version,version,2967,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3157,modifiability,version,version,3157,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3350,modifiability,version,version,3350,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:0,performance,Error,Error,0,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:115,performance,Error,Error,115,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1495,performance,Load,Load,1495,"est_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1536,performance,Error,Error,1536,"on_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=36",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1672,performance,Error,Error,1672,"ent.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:0,safety,Error,Error,0,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:115,safety,Error,Error,115,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:256,safety,test,test,256,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:375,safety,Test,TestClass,375,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:414,safety,Test,TestClass,414,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:790,safety,Test,TestClass,790,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:819,safety,Test,TestClass,819,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:838,safety,test,test,838,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:868,safety,Test,TestClass,868,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:928,safety,test,test,928,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1051,safety,test,test,1051," 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1094,safety,Test,TestClass,1094,"scribe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (las",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1207,safety,test,test,1207,"example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . Strea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1328,safety,test,test,1328,"ude ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1348,safety,test,test,1348,"clude ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1466,safety,test,test,1466,"aaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, vers",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1536,safety,Error,Error,1536,"on_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=36",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1661,safety,test,test,1661," "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo().",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1672,safety,Error,Error,1672,"ent.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1865,safety,test,test,1865," TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offse",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2228,safety,Test,TestClass,2228," Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2731,safety,Test,TestClass,2731,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3379,safety,patch,patches,3379,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1612,security,checksum,checksum,1612," element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2250,security,checksum,checksum,2250," With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortuna",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2475,security,checksum,checksum,2475,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2753,security,checksum,checksum,2753,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2978,security,checksum,checksum,2978,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3168,security,checksum,checksum,3168,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3379,security,patch,patches,3379,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:256,testability,test,test,256,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:375,testability,Test,TestClass,375,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:414,testability,Test,TestClass,414,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:790,testability,Test,TestClass,790,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:819,testability,Test,TestClass,819,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:838,testability,test,test,838,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:868,testability,Test,TestClass,868,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:928,testability,test,test,928,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1051,testability,test,test,1051," 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1094,testability,Test,TestClass,1094,"scribe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (las",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1207,testability,test,test,1207,"example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . Strea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1328,testability,test,test,1328,"ude ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1348,testability,test,test,1348,"clude ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1466,testability,test,test,1466,"aaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, vers",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1661,testability,test,test,1661," "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo().",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1865,testability,test,test,1865," TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offse",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2228,testability,Test,TestClass,2228," Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:2731,testability,Test,TestClass,2731,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3038,testability,Emul,Emulation,3038,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:3103,testability,Emul,Emulation,3103,"ot. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0xb5fb752. array<string,2> first offset= 0 type=62 Emulation. string second offset= 0 type=300 ,stl=365, ctype=365, Emulation. . StreamerInfo for class: array<string,2>, version=1, checksum=0x6b3ba626. string _M_elems offset= 0 type=320 ,stl=365, ctype=365. Unfortunately, I don't how to proceed further. ### Setup. 1. Reproduced with ROOT 6.22.08, 6.24 (today's version from the branch with patches). 2. Operating system Fedora 33 / centos7. 3. binary download / you built it yourself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:0,usability,Error,Error,0,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:14,usability,custom,custom,14,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:115,usability,Error,Error,115,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:201,usability,Minim,Minimal,201,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:985,usability,Close,Close,985,"Error reading custom class object from file with ROOT 6.22,24; - [x] Checked for duplicates. ### Describe the bug. Error reading object from file. Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some addi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1142,usability,Close,Close,1142,". Please find a short example to reproduce below. . ### Minimal example to reproduce. Below I refer to it as **test.cpp**. #include ""map"". #include ""array"". #include ""iostream"". . #include ""TObject.h"". #include ""TFile.h"". . class TestClass : public TObject {. public:. TestClass(){. std::array<std::string, 2> test_array{""aaaa"", ""bbbbbb""};. test_map_[test_array] = ""cccc"";. }. . void Print(Option_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->Show",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1536,usability,Error,Error,1536,"on_t *option="""") const {. for(const auto& element : test_map_){. std::cout << element.first[0] << "" "" << element.first[1] << "" "" << element.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=36",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8268:1672,usability,Error,Error,1672,"ent.second << std::endl;. }. }. private:. std::map<std::array<std::string, 2>, std::string> test_map_{};. ClassDef(TestClass, 1);. };. ClassImp(TestClass). . void test(){. auto* test_obj = new TestClass;. test_obj->Print();. . auto* file = TFile::Open(""test.root"", ""recreate"");. test_obj->Write(""obj"");. file->Close();. . delete file;. delete test_obj;. . file = TFile::Open(""test.root"", ""read"");. test_obj = file->Get<TestClass>(""obj"");. test_obj->Print();. . file->Close();. delete file;. }. . int main(int argc, char* argv[]) {. test();. return 0;. }. ### Running the example. With a compiled code everything works as expected:. root -l. root [0] .L test.cpp+. root [1] test(). gives correct output:. aaaa bbbbbb cccc. aaaa bbbbbb cccc. But if I try to read again the same file:. root -l test.root. root [0] gSystem->Load(""test_cpp""). root [1] obj->Print(). Error in <TBufferFile::ReadVersion>: Could not find the StreamerInfo with a checksum of 0x6b3ba626 for the class ""string"" in test.root. Error in <TBufferFile::CheckByteCount>: object of class string read too many bytes: 72 instead of 24. Warning in <TBufferFile::CheckByteCount>: string::Streamer() not in sync with data on file test.root, fix Streamer(). aaaabbbbbb@ cccc�i�� cccc. With an older version of ROOT (6.18), everything works as expected. ### Some additional information. I tried to compare StreamerInfo for 2 ROOT versions and they are different (last item):. **root 6.18**. root [2] _file0->ShowStreamerInfo(). OBJ: TList TList Doubly linked list : 0. . StreamerInfo for class: TestClass, version=1, checksum=0x84f55819. TObject BASE offset= 0 type=66 Basic ROOT object. map<array<string,2>,string> test_map_ offset= 0 type=300 (nodelete) ,stl=4, ctype=61,. . StreamerInfo for class: pair<array<string,2>,string>, version=1, checksum=0x64321048. string first [2] offset= 0 type=320 ,stl=365, ctype=365,. string second offset= 0 type=300 ,stl=365, ctype=365,. **root 6.22,24**. root [3] _file0->ShowStreamerInfo(). OBJ: TList ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8268
https://github.com/root-project/root/issues/8269:132,availability,redund,redundant,132,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:413,availability,slo,slot,413,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:132,deployability,redundan,redundant,132,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:599,integrability,event,event,599,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:874,modifiability,Inherit,InheritsFrom,874,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:593,performance,time,timer,593,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1426,performance,time,timer,1426,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1450,performance,perform,performance,1450,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1668,performance,lock,lock-program-freezes,1668,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:132,reliability,redundan,redundant,132,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:413,reliability,slo,slot,413,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:132,safety,redund,redundant,132,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:406,security,sign,signal,406,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1038,security,session,session,1038,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1216,security,session,session,1216,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1668,security,lock,lock-program-freezes,1668,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:151,testability,understand,understand,151,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1607,testability,context,context,1607,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1161,usability,Command,Command,1161,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1312,usability,Command,Command,1312,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1417,usability,stop,stop,1417,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1439,usability,user,user,1439,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/issues/8269:1450,usability,perform,performance,1450,"TGCommandPlugin TTimer; ### Explain what you would like to see improved. The TGCommandPlugin has an internal TTimer that I think is redundant. I don't understand why the function CheckRemote needs to be checked every one second, which also calls frame->Layout(). Shouldn't it be better to just check in the beginning with a TTimer::SingleShot? Or if gROOT->GetApplication() changes during lifetime, with a signal/slot ? ```. fTimer = new TTimer(this, 1000);. fTimer->Reset();. fTimer->TurnOn();. ... ////////////////////////////////////////////////////////////////////////////////. /// Handle timer event. Bool_t TGCommandPlugin::HandleTimer(TTimer *t). {. if ((fTimer == 0) || (t != fTimer)) return kTRUE;. CheckRemote("""");. return kTRUE;. }. void TGCommandPlugin::CheckRemote(const char * /*str*/). {. Pixel_t pxl;. TApplication *app = gROOT->GetApplication();. if (!app->InheritsFrom(""TRint"")). return;. TString sPrompt = ((TRint*)app)->GetPrompt();. Int_t end = sPrompt.Index("":root ["", 0);. if (end > 0 && end != kNPOS) {. // remote session. sPrompt.Remove(end);. gClient->GetColorByName(""#ff0000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(Form(""Command (%s):"", sPrompt.Data()));. }. else {. // local session. gClient->GetColorByName(""#000000"", pxl);. fLabel->SetTextColor(pxl);. fLabel->SetText(""Command (local):"");. }. fHf->Layout();. }. ```. Alternatively, it would be nice to provide a function to stop the timer by the user, when performance is needed and you are sure that TApplication is always the same. ### Setup. 1. ROOT from git master. 2. Ubuntu 20. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8269
https://github.com/root-project/root/pull/8270:49,safety,Prevent,Prevent,49,[PyROOT] Add Python include paths with -isystem; Prevent warnings about the 'register' keyword in Python2 headers. The explicit silencing of such warnings can also be removed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8270
https://github.com/root-project/root/pull/8270:49,security,Preven,Prevent,49,[PyROOT] Add Python include paths with -isystem; Prevent warnings about the 'register' keyword in Python2 headers. The explicit silencing of such warnings can also be removed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8270
https://github.com/root-project/root/pull/8272:305,modifiability,deco,decoupling,305,"[PyROOT][8183] Fix TTreeReader iteration; The out-of-the-box iterator provided by cppyy is not fully. applicable in the case of TTreeReader: in a given iteration, the. entry number returned by the iterator is correct, but it is. always behind the entry number of the reader itself. This commit fixes such decoupling by relying on TTreeReader::Next(). and adds a test for it. Fixes #8183",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8272
https://github.com/root-project/root/pull/8272:362,safety,test,test,362,"[PyROOT][8183] Fix TTreeReader iteration; The out-of-the-box iterator provided by cppyy is not fully. applicable in the case of TTreeReader: in a given iteration, the. entry number returned by the iterator is correct, but it is. always behind the entry number of the reader itself. This commit fixes such decoupling by relying on TTreeReader::Next(). and adds a test for it. Fixes #8183",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8272
https://github.com/root-project/root/pull/8272:362,testability,test,test,362,"[PyROOT][8183] Fix TTreeReader iteration; The out-of-the-box iterator provided by cppyy is not fully. applicable in the case of TTreeReader: in a given iteration, the. entry number returned by the iterator is correct, but it is. always behind the entry number of the reader itself. This commit fixes such decoupling by relying on TTreeReader::Next(). and adds a test for it. Fixes #8183",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8272
https://github.com/root-project/root/pull/8273:146,usability,support,supporting,146,"Use RooMinimizer instead of RooMinuit; The tutorials should show the use of the RooMinimizer class instead of RooMinuit, which is the older class supporting only TMinuit and it will be deprecated in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8273
https://github.com/root-project/root/pull/8274:60,deployability,automat,automatically,60,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:180,deployability,API,API,180,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:180,integrability,API,API,180,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:588,integrability,sub,subclasses,588,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:180,interoperability,API,API,180,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:14,modifiability,inherit,inheritance,14,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:151,modifiability,inherit,inherit,151,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:1,reliability,rca,rcanvas,1,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:121,security,access,access,121,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:60,testability,automat,automatically,60,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:109,testability,simpl,simplifies,109,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8274:109,usability,simpl,simplifies,109,"[rcanvas] use inheritance approach for attributes ; 1. This automatically provides setter/getter methods and simplifies. access to fields. Now `RLine` inherit from `RAttrLine` and API changes are:. before: `line->AttrLine().SetWidth(10)`. now: `line->SetLineWidth(10)`. One still can do: `line1->AttrLine() = line2->AttrLine()` while RAttrLine class still provides method like. `RAttrLine& AttrLine() { return *this; }` . 2. Same done for RAttrFill, RAttrText, RAttrMarker and with used classes. 3. Adjust tutorials and JSROOT code. 4. Change RLegend class - split RLegend::REntry on two subclasses.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8274
https://github.com/root-project/root/pull/8275:17,deployability,version,version,17,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:43,deployability,releas,release,43,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:271,deployability,Releas,ReleaseNotes,271,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:17,integrability,version,version,17,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:177,integrability,interfac,interface,177,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:177,interoperability,interfac,interface,177,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:17,modifiability,version,version,17,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:177,modifiability,interfac,interface,177,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:93,reliability,pra,pragma,93,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:123,security,control,control,123,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:123,testability,control,control,123,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/pull/8275:191,usability,interact,interactive,191,[clad] Bump clad version to v0.8.; The new release includes some improvements:. * Implement #pragma clad ON/OFF/DEFAULT to control regions where clad is active. * Add getCode() interface for interactive use. See more at: https://github.com/vgvassilev/clad/blob/v0.8/docs/ReleaseNotes.md,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8275
https://github.com/root-project/root/issues/8276:305,deployability,build,build,305,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:917,deployability,stack,stack-allocated,917,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:923,energy efficiency,alloc,allocated,923,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:879,reliability,doe,does,879,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:956,reliability,doe,does,956,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:259,safety,input,input,259,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:114,usability,behavi,behavior,114,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/issues/8276:259,usability,input,input,259,"[DF] Possible use after delete of the functor passed to PassAsVec; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code:. ```cpp. #include <iostream>. #include <utility>. #include <vector>. #include <ROOT/RDFHelpers.hxx>. auto foo() {. double f = 42.;. auto fn = [f](std::vector<int>) { std::cout << f << std::endl; };. fn({});. auto f2 = ROOT::RDF::PassAsVec<1, int>(fn);. f2(3);. return f2;. }. int main() {. auto fn = foo();. fn(1);. return 0;. }. ```. prints. ```. 42. 42. 4.66901e-310. ```. instead of. ```. 42. 42. 42. ```. The problem is that the `PassAsVecHelper` type stores a reference to the the lambda function. Valgrind does not see the problem (lambdas are stack-allocated), `-fsanitize=address` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8276
https://github.com/root-project/root/pull/8279:30,availability,failur,failures,30,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/pull/8279:30,deployability,fail,failures,30,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/pull/8279:30,performance,failur,failures,30,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/pull/8279:30,reliability,fail,failures,30,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/pull/8279:25,safety,test,test,25,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/pull/8279:25,testability,test,test,25,[DF] Fix datasource_more test failures on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8279
https://github.com/root-project/root/issues/8280:11,deployability,fail,fails,11,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:68,deployability,version,version,68,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:274,deployability,configurat,configuration,274,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:329,deployability,version,version,329,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:68,integrability,version,version,68,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:163,integrability,messag,message,163,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:274,integrability,configur,configuration,274,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:329,integrability,version,version,329,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:163,interoperability,messag,message,163,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:32,modifiability,pac,package,32,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:68,modifiability,version,version,68,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:274,modifiability,configur,configuration,274,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:299,modifiability,pac,package,299,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:329,modifiability,version,version,329,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:11,reliability,fail,fails,11,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:274,security,configur,configuration,274,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:54,usability,minim,minimum,54,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8280:321,usability,minim,minimum,321,"ROOT CMake fails if an external package sets a higher minimum CMake version; The code. ```. if (${CMAKE_MINIMUM_REQUIRED_VERSION} VERSION_GREATER_EQUAL ""3.10.0""). message(FATAL_ERROR ""Remove this condition""). ```. in the ROOT CMakeLists introduced in #6605 breaks the CMake configuration if another package sets a higher minimum version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8280
https://github.com/root-project/root/issues/8281:300,availability,error,error,300,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1131,availability,error,error,1131,"e enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 346",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1370,availability,error,error,1370,"oundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1599,availability,error,error,1599,"m /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backporte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2354,availability,Error,Error,2354,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2459,availability,Error,Error,2459,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2498,availability,Error,Error,2498,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:10,deployability,fail,fails,10,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:349,deployability,depend,dependencies,349,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:398,deployability,Build,Building,398,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2257,deployability,build,build,2257,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:418,energy efficiency,core,core,418,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:541,energy efficiency,core,core,541,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:623,energy efficiency,core,core,623,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:693,energy efficiency,core,core,693,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:755,energy efficiency,core,core,755,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:825,energy efficiency,core,core,825,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1077,energy efficiency,core,core,1077,"tps://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1316,energy efficiency,core,core,1316,"Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1545,energy efficiency,core,core,1545,"oundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1896,energy efficiency,core,core,1896,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1968,energy efficiency,core,core,1968,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2208,energy efficiency,core,core,2208,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2272,energy efficiency,core,core,2272,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2405,energy efficiency,core,core,2405,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:146,integrability,configur,configure,146,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:349,integrability,depend,dependencies,349,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:146,modifiability,configur,configure,146,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:349,modifiability,depend,dependencies,349,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:300,performance,error,error,300,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1131,performance,error,error,1131,"e enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 346",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1370,performance,error,error,1370,"oundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1599,performance,error,error,1599,"m /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backporte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2354,performance,Error,Error,2354,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2459,performance,Error,Error,2459,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2498,performance,Error,Error,2498,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:10,reliability,fail,fails,10,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:300,safety,error,error,300,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:349,safety,depend,dependencies,349,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1131,safety,error,error,1131,"e enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 346",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1370,safety,error,error,1370,"oundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1599,safety,error,error,1599,"m /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backporte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2354,safety,Error,Error,2354,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2459,safety,Error,Error,2459,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2498,safety,Error,Error,2498,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2607,safety,test,tested,2607,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:146,security,configur,configure,146,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1416,security,token,token,1416,"ore/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundatio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:349,testability,depend,dependencies,349,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2607,testability,test,tested,2607,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:300,usability,error,error,300,"ROOT 6.24 fails to compile with GCC 11.1 in C++11 mode; First reported here: https://bugs.gentoo.org/793002. To reproduce, it should be enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1131,usability,error,error,1131,"e enough to configure with. ```. $ cmake .. -DCMAKE_C_COMPILER=gcc-11.1.0 -DCMAKE_CXX_COMPILER=g++-11.1.0 -DCMAKE_CXX_STANDARD=11 -Dminimal=ON. ```. to reproduce the error below. ```. Consolidate compiler generated dependencies of target Foundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 346",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1370,usability,error,error,1370,"oundation_Stage1. [ 18%] Building CXX object core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o. In file included from /srv/root/src/root/core/foundation/inc/ROOT/RWrap_libcpp_string_view.h:545,. from /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:1599,usability,error,error,1599,"m /srv/root/src/root/core/foundation/inc/ROOT/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backporte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2354,usability,Error,Error,2354,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2459,usability,Error,Error,2459,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2498,usability,Error,Error,2498,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/issues/8281:2623,usability,tip,tip,2623,"/RStringView.hxx:26,. from /srv/root/src/root/core/foundation/inc/TClassEdit.h:65,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:18:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h: In member function ‘constexpr std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::size_type std::experimental::__ROOT::basic_string_view<_CharT, _Traits>::max_size() const’:. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:63: error: ‘numeric_limits’ is not a member of ‘std’. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~~~~~~~~~~~~. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:87: error: expected primary-expression before ‘>’ token. 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^. /srv/root/src/root/core/foundation/inc/ROOT/libcpp_string_view.h:275:90: error: ‘::max’ has not been declared; did you mean ‘std::max’? 275 | size_type max_size() const _NOEXCEPT { return (_VSTD::numeric_limits<size_type>::max)(); }. | ^~~. | std::max. In file included from /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/algorithm:62,. from /srv/root/src/root/core/foundation/res/TSchemaRuleProcessor.h:15,. from /srv/root/src/root/core/foundation/src/RConversionRuleParser.cxx:17:. /usr/lib/gcc/x86_64-pc-linux-gnu/11.1.0/include/g++-v11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here. 3467 | max(initializer_list<_Tp> __l, _Compare __comp). | ^~~. make[2]: *** [core/foundation/CMakeFiles/Foundation_Stage1.dir/build.make:90: core/foundation/CMakeFiles/Foundation_Stage1.dir/src/RConversionRuleParser.cxx.o] Error 1. make[1]: *** [CMakeFiles/Makefile2:23284: core/foundation/CMakeFiles/Foundation_Stage1.dir/all] Error 2. make: *** [Makefile:156: all] Error 2. ```. The master branch seems to go past this point, so probably something needs to be backported (I tested with the tip of the 6.24 branch).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8281
https://github.com/root-project/root/pull/8282:209,energy efficiency,current,current,209,"[PyROOT][8183] Do not increment STL-like iterator in first iteration; This fixes the iteration over a TTreeReader, since incrementing its. iterator before the loop body of the first iteration runs causes. the current entry of the reader to always be one position ahead. From:. https://bitbucket.org/wlav/cpycppyy/commits/8222848093bd687d67f2b89172764e0964cb14f0. Fixes #8183",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8282
https://github.com/root-project/root/issues/8283:175,energy efficiency,clock,clock,175,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:347,interoperability,share,share,347,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:14,performance,perform,performance,14,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:121,performance,Perform,Performance,121,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:321,performance,throughput,throughput,321,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:446,performance,time,timeWallWrite,446,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:461,performance,time,timeWallZip,461,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:474,performance,time,timeCpuWrite,474,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:488,performance,time,timeCpuZip,488,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:14,usability,perform,performance,14,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:121,usability,Perform,Performance,121,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8283:279,usability,minim,minimum,279,"[rntuple] Add performance counters to classes derived from `RPageSink`; ### Explain what you would like to see improved. Performance counters (e.g., total bytes written, wall clock spent writing, etc.) should be added to the `RPageSinkFile` and `RPageSinkDaos` classes. The bare minimum should allow to compute the write throughput. ### Optional: share how it could be improved. In particular, four new `RCounter`s will be added: szWritePayload, timeWallWrite, timeWallZip, timeCpuWrite, timeCpuZip.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8283
https://github.com/root-project/root/issues/8284:84,availability,error,errors,84,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:608,availability,error,errors,608,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1762,availability,Operat,Operating,1762,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1837,availability,down,download,1837,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1263,deployability,releas,release,1263,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1670,deployability,build,build,1670,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1750,deployability,version,version,1750,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1819,deployability,instal,install,1819,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1211,integrability,Event,Events,1211,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1313,integrability,Event,Events,1313,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1750,integrability,version,version,1750,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1750,modifiability,version,version,1750,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:84,performance,error,errors,84,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:608,performance,error,errors,608,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:84,safety,error,errors,84,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:608,safety,error,errors,608,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:803,safety,except,exception,803,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1624,safety,input,input,1624,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:84,usability,error,errors,84,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:608,usability,error,errors,608,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:633,usability,clear,clear,633,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:681,usability,behavi,behavior,681,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:712,usability,behavi,behavior,712,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:869,usability,clear,clear,869,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1248,usability,Close,Close,1248,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1479,usability,behavi,behavior,1479,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/issues/8284:1624,usability,input,input,1624,"[ntuple] TKey with the same name as requested RNTuple causes internal RNTupleReader errors; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. TKeys in a TFile with the same name as the requested RNTuple will be attempted to be parsed as an RNTuple, leading to internal parser errors later on. <!--. A clear and concise description of what the wrong behavior is. -->. ### Expected behavior. The RNTupleReader should check the type of the TKey before parsing (and throw an exception if there's no RNTuple with the requested name). <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Create a TFile with a TKey with a certain name, then try to open that file as an RNTuple. ```cpp. std::string filename = ""some_file.root"";. {. auto file = std::make_unique<TFile>(filename.c_str(), ""RECREATE"", """", 209);. auto tree = std::make_unique<TTree>(""Events"", """");. file->Write();. file->Close();. tree.release();. }. auto ntuple = RNTupleReader::Open(""Events"", filename);. ```. ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Root master. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8284
https://github.com/root-project/root/pull/8285:200,availability,failur,failures,200,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:355,availability,error,error,355,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:200,deployability,fail,failures,200,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:265,integrability,Event,Events,265,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:309,integrability,Event,Events,309,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:563,integrability,Event,Events,563,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:200,performance,failur,failures,200,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:355,performance,error,error,355,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:200,reliability,fail,failures,200,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:355,safety,error,error,355,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:482,safety,Except,Exception,482,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:517,safety,except,exception,517,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:618,security,access,access,618,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:193,testability,assert,assert,193,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8285:355,usability,error,error,355,"[ntuple] Check TKey class name is RNTuple; Fixes issue #8284 where TKeys with the same name as the requested RNTuple. would be attempted to be parsed as an RNTuple, leading to internal. parser assert failures later on. e.g. ```cpp. // actually holds a TTree named ""Events"". auto reader = RNTupleReader::Open(""Events"", ""test80X_NANO.root"");. ```. Internal error before: . ```. Fatal: nread == nbytes violated at line 1011 of `~/root/tree/ntuple/v7/src/RMiniFile.cxx'. aborting. ```. Exception thrown after: . ```. C++ exception with description ""no RNTuple named 'Events' in file 'test80X_NANO.root' (unchecked RResult access!). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8285
https://github.com/root-project/root/pull/8286:5,safety,Avoid,Avoid,5,[DF] Avoid potential nullptr dereference; TLeaf::GetTypeName might return a nullptr if dictionaries for the. type are missing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8286
https://github.com/root-project/root/pull/8287:1,energy efficiency,core,core,1,[core][6.24] Missing include in string_view header; FIxes #8281,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8287
https://github.com/root-project/root/pull/8288:43,availability,avail,available,43,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:106,availability,avail,available,106,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:136,availability,error,error,136,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:193,availability,avail,available,193,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:142,integrability,messag,message,142,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:142,interoperability,messag,message,142,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:136,performance,error,error,136,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:43,reliability,availab,available,43,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:106,reliability,availab,available,106,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:193,reliability,availab,available,193,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:43,safety,avail,available,43,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:106,safety,avail,available,106,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:136,safety,error,error,136,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:193,safety,avail,available,193,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:43,security,availab,available,43,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:106,security,availab,available,106,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:193,security,availab,available,193,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8288:136,usability,error,error,136,Fix Math tutorials when libMathmore is not available; - Veto tutorial multiVarGaus.C when mathmore is not available. - Disable printing error message in exampleFunction.py when mathmore is not available. This fixes ROOT-8145,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8288
https://github.com/root-project/root/pull/8289:1,energy efficiency,core,core,1,[core][6.22][skip-ci] Missing include in string_view header; 6.22 Backport of #8107 according to discussion in #8281,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8289
https://github.com/root-project/root/pull/8290:1,energy efficiency,core,core,1,[core][6.20][skip-ci] Missing include in string_view header; 6.20 Backport of #8107 according to discussion in #8281,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8290
https://github.com/root-project/root/pull/8291:1,energy efficiency,core,core,1,[core][6.18][skip-ci] Missing include in string_view header; 6.18 Backport of #8107 according to discussion in #8281,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8291
https://github.com/root-project/root/issues/8292:12,availability,error,error,12,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:755,availability,down,download,755,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:770,availability,down,download,770,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1404,availability,error,error,1404,"arget clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooSta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1543,availability,Error,Error,1543,"opying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1644,availability,failur,failure,1644,"tall. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1827,availability,Error,Error,1827,"t vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1921,availability,Error,Error,1921,"eed it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2711,availability,down,download,2711,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2726,availability,down,download,2726,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:298,deployability,build,build,298,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:308,deployability,instal,install,308,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:440,deployability,depend,dependencies,440,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:506,deployability,depend,dependencies,506,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:558,deployability,resourc,resource,558,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:635,deployability,build,build,635,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:645,deployability,instal,install,645,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1056,deployability,build,build,1056,"eck here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dv",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1066,deployability,instal,install,1066,"https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1644,deployability,fail,failure,1644,"tall. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1784,deployability,build,build,1784,"and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2140,deployability,build,build,2140,"ating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2150,deployability,instal,install,2150,"rward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2174,deployability,Build,Building,2174,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2265,deployability,Build,Building,2265,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2354,deployability,Build,Building,2354,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2448,deployability,Build,Building,2448,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2647,deployability,build,build,2647,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2657,deployability,instal,install,2657,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2913,deployability,build,build,2913,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2923,deployability,instal,install,2923,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2962,deployability,releas,release,2962,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:3071,deployability,instal,installation,3071,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:3101,deployability,Version,Version,3101,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:558,energy efficiency,resourc,resource,558,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1588,energy efficiency,core,core,1588,"] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooSta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1747,energy efficiency,core,core,1747,"rming download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1800,energy efficiency,core,core,1800,"r ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cma",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1879,energy efficiency,core,core,1879," mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_in",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:440,integrability,depend,dependencies,440,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:506,integrability,depend,dependencies,506,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:3101,integrability,Version,Version,3101,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2558,interoperability,share,shared,2558,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:440,modifiability,depend,dependencies,440,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:506,modifiability,depend,dependencies,506,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:3101,modifiability,Version,Version,3101,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:12,performance,error,error,12,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:558,performance,resourc,resource,558,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:744,performance,Perform,Performing,744,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:841,performance,network,network,841,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1404,performance,error,error,1404,"arget clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooSta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1543,performance,Error,Error,1543,"opying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1644,performance,failur,failure,1644,"tall. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1827,performance,Error,Error,1827,"t vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1921,performance,Error,Error,1921,"eed it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2700,performance,Perform,Performing,2700,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:107,reliability,doe,does-not-complile-on-redhat-,107,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1644,reliability,fail,failure,1644,"tall. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:12,safety,error,error,12,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:116,safety,compl,complile-on-redhat-,116,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:440,safety,depend,dependencies,440,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:506,safety,depend,dependencies,506,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:558,safety,resourc,resource,558,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1404,safety,error,error,1404,"arget clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooSta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1543,safety,Error,Error,1543,"opying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1827,safety,Error,Error,1827,"t vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1921,safety,Error,Error,1921,"eed it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:116,security,compl,complile-on-redhat-,116,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:841,security,network,network,841,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:849,security,access,access,849,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:3055,security,access,access,3055,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:440,testability,depend,dependencies,440,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:506,testability,depend,dependencies,506,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:558,testability,resourc,resource,558,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:780,testability,verif,verify,780,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2736,testability,verif,verify,2736,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:12,usability,error,error,12,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:744,usability,Perform,Performing,744,"Compilation error on redhat 8.3 / no internet; Hi please check here:. https://root-forum.cern.ch/t/6-24-00-does-not-complile-on-redhat-8-3/45161. details:. Hello,. I’m running into problems compiling root 6.24.00:. $ cmake -Dclad=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j8. …. [ 76%] Linking CXX static library …/…/…/…/lib/libclingInterpreter.a. [ 76%] Built target clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1404,usability,error,error,1404,"arget clingInterpreter. Scanning dependencies of target CLING. [ 76%] Built target CLING. Scanning dependencies of target LLVMRES. [ 76%] Copying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooSta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1543,usability,Error,Error,1543,"opying LLVM resource and header files. [ 76%] Built target LLVMRES. (stucks…). $ cmake --build . --install. [ 0%] Built target AFTERIMAGE. [ 0%] Built target OPENUI5. [ 0%] Built target LZMA. [ 0%] Performing download step (download, verify and extract) for ‘VDT’. (stucks). seems that vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1827,usability,Error,Error,1827,"t vdt uses network access, which I do not have (not mentioned in the docs). I think I do not need it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:1921,usability,Error,Error,1921,"eed it anyhow…. so again:. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . --install. …. [ 79%] Generating G__Thread.cxx, …/…/lib/Thread.pcm. [ 79%] Generating G__forward_listDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/issues/8292:2700,usability,Perform,Performing,2700,"tDict.cxx, …/…/lib/libforward_listDict.rootmap. [ 79%] Generating G__vectorDict.cxx, …/…/lib/libvectorDict.rootmap. In file included from input_line_7:21:. /srv/ussapc/home/ussapc/sw/root_build/include/ROOT/TReentrantRWLock.hxx:26:10: fatal error: ‘tbb/enumerable_thread_specific.h’ file not found. #include “tbb/enumerable_thread_specific.h”. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Error: /srv/ussapc/home/ussapc/sw/root_build/core/rootcling_stage1/src/rootcling_stage1: compilation failure (/srv/ussapc/home/ussapc/sw/root_build/lib/libThreaddb2bde6cdd_dictUmbrella.h). gmake[2]: *** [core/thread/CMakeFiles/G__Thread.dir/build.make:109: core/thread/G__Thread.cxx] Error 1. gmake[1]: *** [CMakeFiles/Makefile2:27339: core/thread/CMakeFiles/G__Thread.dir/all] Error 2. gmake[1]: *** Waiting for unfinished jobs…. I found out that tbb is required by imt, so again. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. …. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCSampler.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/ToyMCStudy.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UniformProposal.cxx.o. [100%] Building CXX object roofit/roostats/CMakeFiles/RooStats.dir/src/UpperLimitMCSModule.cxx.o. [100%] Linking CXX shared library …/…/lib/libRooStats.so. [100%] Built target RooStats. (stucks). $ cmake --build . – install. [ 0%] Built target OPENUI5. [ 0%] Performing download step (download, verify and extract) for ‘XROOTD’. unbeliveable…. $ rm -rf *. $ cmake -Dclad=OFF -Dvdt=OFF -Dimt=OFF -Dxrootd=OFF -DCMAKE_INSTALL_PREFIX=…/root_install …/root-6.24.00. $ cmake --build . – install -j 8. runs. Please fix at next release. I would recommend to implement a “localonly” option in case you don’t have internet access from the installation PC. Georg. _ROOT Version: 6.24.00. _Platform: RetHat 8.3. _Compiler:gcc 8.3.1-5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292
https://github.com/root-project/root/pull/8293:101,availability,state,state,101,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:320,availability,state,state,320,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:502,availability,restor,restores,502,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:236,deployability,modul,modulus,236,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:283,energy efficiency,power,power,283,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:101,integrability,state,state,101,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:320,integrability,state,state,320,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:596,integrability,sub,subtract-with-borrow,596,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:236,modifiability,modul,modulus,236,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:61,reliability,doe,does,61,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:502,reliability,restor,restores,502,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:133,safety,avoid,avoid,133,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:236,safety,modul,modulus,236,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8293:569,testability,understand,understanding,569,"Fix bias in RANLUX++; From a high-level perspective, this PR does two things:. * It converts the LCG state back to RANLUX numbers to avoid a bias in the generated numbers as reported by Martin Lüscher. This comes from the fact that the modulus `m = 2 ** 576 - 2 ** 240 + 1` is not a power of 2, so just treating the LCG state as a pool of entropy means that the upper `576 - 240 = 336` bits have a higher probability of being 0 than 1. * Extract only 48 bits instead of 52 bits per random number. This restores the connection to the theoretical properties derived from understanding the original subtract-with-borrow recursion as a dynamical system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8293
https://github.com/root-project/root/pull/8294:1601,availability,replic,replicate,1601,"tiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1792,availability,replic,replication,1792,"me attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2103,availability,error,errors,2103,"t code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be acc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1999,deployability,upgrad,upgrade,1999,"w to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2257,deployability,probe,probe,2257,"reas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculati",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3330,deployability,contain,contains,3330,"s. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3360,deployability,version,version,3360," to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3684,deployability,version,version,3684,"parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,deployability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4072,deployability,infrastructur,infrastructure,4072,"ew functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5236,deployability,updat,updating,5236,"stics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5573,deployability,version,version,5573,"ct has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6105,deployability,version,version,6105,"f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6264,deployability,version,version,6264," done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7359,deployability,stage,stage,7359,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7397,deployability,version,version,7397,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7412,deployability,version,version,7412,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:370,energy efficiency,Current,Currently,370,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:827,energy efficiency,current,current,827,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2377,energy efficiency,adapt,adapter,2377,"IGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2798,energy efficiency,CPU,CPUAffinity,2798," `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2929,energy efficiency,CPU,CPU,2929,"ulation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented exi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2933,energy efficiency,core,cores,2933,"on code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3266,energy efficiency,GPU,GPUs,3266,"ions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGra",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5530,energy efficiency,optim,optimization,5530,"hat of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved ther",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:156,integrability,interfac,interface,156,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:555,integrability,wrap,wrapper,555,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1165,integrability,sub,subclass,1165,"the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1522,integrability,transform,transformation,1522,"ew weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2024,integrability,transform,transformation,2024,"e above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as w",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2377,integrability,adapt,adapter,2377,"IGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2476,integrability,abstract,abstract,2476,"that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/327",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3360,integrability,version,version,3360," to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3450,integrability,event,event,3450,"lity was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3640,integrability,event,event,3640,"external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contri",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3684,integrability,version,version,3684,"parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,integrability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5179,integrability,Queue,Queue,5179,"ocessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiP",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5350,integrability,Queue,Queue,5350," 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5371,integrability,Queue,Queue,5371,"lling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5573,integrability,version,version,5573,"ct has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6105,integrability,version,version,6105,"f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6264,integrability,version,version,6264," done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6577,integrability,event,event-based,6577,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7397,integrability,version,version,7397,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7412,integrability,version,version,7412,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:156,interoperability,interfac,interface,156,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:555,interoperability,wrapper,wrapper,555,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1522,interoperability,transform,transformation,1522,"ew weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2024,interoperability,transform,transformation,2024,"e above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as w",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2377,interoperability,adapt,adapter,2377,"IGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3058,interoperability,compatib,compatible,3058," instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,interoperability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5209,interoperability,distribut,distribution,5209,"Process_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been part",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5308,interoperability,socket,sockets,5308,"oRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6577,interoperability,event-bas,event-based,6577,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:145,modifiability,extens,extensible,145,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:156,modifiability,interfac,interface,156,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:194,modifiability,pac,package,194,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:208,modifiability,refact,refactored,208,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1359,modifiability,paramet,parameter,1359,"sses. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1438,modifiability,paramet,parameter,1438,"stics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1464,modifiability,paramet,parameter,1464," still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1999,modifiability,upgrad,upgrade,1999,"w to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2377,modifiability,adapt,adapter,2377,"IGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2476,modifiability,abstract,abstract,2476,"that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/327",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2787,modifiability,paramet,parameter,2787,"replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3360,modifiability,version,version,3360," to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3684,modifiability,version,version,3684,"parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,modifiability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3982,modifiability,pac,packages,3982,"ks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4852,modifiability,extens,extension,4852,"closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5226,modifiability,paramet,parameter,5226,"TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5573,modifiability,version,version,5573,"ct has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5594,modifiability,scal,scaling,5594," has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based paralleli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6105,modifiability,version,version,6105,"f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6221,modifiability,maintain,maintained,6221,"parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on Zero",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6264,modifiability,version,version,6264," done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7397,modifiability,version,version,7397,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7412,modifiability,version,version,7412,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:68,performance,Parallel,Parallelism,68,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:208,performance,refactor,refactored,208,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1686,performance,parallel,parallelize,1686,"rn.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with para",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2103,performance,error,errors,2103,"t code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be acc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2688,performance,parallel,parallel,2688,"elize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2798,performance,CPU,CPUAffinity,2798," `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2867,performance,parallel,parallelization,2867," already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2929,performance,CPU,CPU,2929,"ulation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented exi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3266,performance,GPU,GPUs,3266,"ions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGra",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3788,performance,time,time,3788,"ameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4594,performance,time,time,4594,"orkshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The sc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4971,performance,time,time,4971," The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the rework",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5179,performance,Queue,Queue,5179,"ocessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiP",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5350,performance,Queue,Queue,5350," 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5371,performance,Queue,Queue,5371,"lling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5530,performance,optimiz,optimization,5530,"hat of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved ther",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6589,performance,parallel,parallelization,6589,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,reliability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:24,safety,Test,TestStatistics,24,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:219,safety,test,test,219,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:389,safety,Test,TestStatistics,389,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:434,safety,Test,TestStatistics,434,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2103,safety,error,errors,2103,"t code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be acc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3806,safety,test,test,3806,"y`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4013,safety,test,tests,4013,"uite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4064,safety,test,testing,4064,", but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4231,safety,Test,TestStatistics,4231,"ds, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter up",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4251,safety,test,testLikelihoodGradientJob,4251,"n GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4281,safety,test,testLikelihoodSerial,4281,"ed frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using ap",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4306,safety,test,testRooRealL,4306,"mmit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sock",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4457,safety,test,testRooGradMinimizer,4457,"ributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4482,safety,test,testBidirMMapPipe,4482,"[CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess fun",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4504,safety,test,testMPFEnll,4504,"i.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4658,safety,except,except,4658,"tions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) shou",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5236,safety,updat,updating,5236,"stics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5818,safety,test,tests,5818,"work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is pr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:6221,safety,maintain,maintained,6221,"parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on Zero",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7311,safety,input,input,7311,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:653,security,Modif,Modified,653,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1064,security,modif,modifications,1064,"allelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3103,security,access,accessed,3103,"rs would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiPr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,security,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5097,security,sign,signals-,5097,"ultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-conc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5236,security,updat,updating,5236,"stics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5308,security,soc,sockets,5308,"oRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:24,testability,Test,TestStatistics,24,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:219,testability,test,test,219,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:389,testability,Test,TestStatistics,389,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:434,testability,Test,TestStatistics,434,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3736,testability,integr,integrate,3736,"alMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3806,testability,test,test,3806,"y`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for pos",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4013,testability,test,tests,4013,"uite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4064,testability,test,testing,4064,", but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4231,testability,Test,TestStatistics,4231,"ds, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter up",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4251,testability,test,testLikelihoodGradientJob,4251,"n GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4281,testability,test,testLikelihoodSerial,4281,"ed frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using ap",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4306,testability,test,testRooRealL,4306,"mmit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sock",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4457,testability,test,testRooGradMinimizer,4457,"ributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4482,testability,test,testBidirMMapPipe,4482,"[CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess fun",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4504,testability,test,testMPFEnll,4504,"i.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:5818,testability,test,tests,5818,"work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is pr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:115,usability,minim,minimization,115,"RooFit MultiProcess and TestStatistics; This PR adds to RooFit:. 1. Parallelism to gradient calculation in Minuit2 minimization in the form of a extensible interface in the RooFit::MultiProcess package. 2. A refactored test statistics framework with cleaner separation of computation and physics/statistics concepts than in existing RooAbsTestStatistic derived classes. Currently, RooFit::TestStatistics is part of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:1407,usability,user,user,1407,"rt of roofitcore. Note: `TestStatistics/likelihood_builders` still has to be finished, this will be done in the coming few weeks. 3. RooFitZMQ, a wrapper of ZeroMQ functionality used in RooFit::MultiProcess for communication between processes. Modified after [code](https://gitlab.cern.ch/raaij/generate_and_sort/-/tree/master/ZMQ), contributed by @roelaaij. RooFitZMQ maybe still needs some attention, because in its current form it includes a big part of the libzmq source tree (needed for ppoll, see below), which I'm sure causes licensing issues (it's LGPLv3). I'm open to suggestions on how to handle this. To make the above additions possible, some modifications to both RooFit and non-RooFit code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. I",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2103,usability,error,errors,2103,"t code were made as well:. 1. In `Minuit2`:. 1. We added a subclass of the AnalyticalGradientCalculator called the ExternalInternalGradientCalculator. Whereas the AGC assumes that the gradient that is passed to it (from outside of Minuit2) is in normal parameter space, the EIGC allows its (External) user to use Minuit2 ""Internal"" parameter space, i.e. the parameter space that may be bounded into some range using transformation functions. This allowed us to exactly (floating point bit-wise) replicate the Minuit2 gradient calculation outside of Minuit2 itself, allowing us to parallelize this gradient calculation process exactly without having to worry about breaking Minuit2. The replication, `NumericalDerivatorMinuit2`, was based on earlier work by @lmoneta who already had separated out the bulk of the gradient calculation code from Minuit2. 2. To make this all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be acc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:2965,usability,minim,minimization,2965,"is all work, we also had to upgrade precision of the transformation functions to long double instead of double, otherwise round off errors would still persist and ruin any chances of exact bit-wise equality. 2. In `mathcore`: Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3192,usability,user,users,3192,": Some additions to `IFunction` were made to allow Minuit2 to probe functions for their ability to generate gradients and second derivatives. Similar additions were made to function adapter classes in Minuit2. 3. In RooFit:. 1. Most RooMinimizerFcn functionality was moved into an abstract base class RooAbsMinimizerFcn, which in turn forms the base class of the new RooMinimizerFcn, but also of the added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3589,usability,User,Users,3589,"he added RooGradMinimizerFcn (serial, but gradient external to Minuit2) and MinuitFcnGrad (with parallel MultiProcess back-end) classes. 2. The RooRealMPFE based classes can make use of an added parameter `CPUAffinity`. In Unix systems (not macOS), this makes the MPFE based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended an",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:3857,usability,close,closer,3857," based parallelization a lot faster by pinning processes to physical CPU cores. 3. To accomodate the new minimization frameworks, RooMinimizer was changed quite a bit as well. It is still backwards compatible, but the new functionality can be accessed through a new `create` template factory function. This template function allows users to pass in their own calculation back-ends, e.g. for calculating on GPUs or in autograd enabled frameworks. The commit history also contains the proof of concept version, the benchmark results of which were presented at [ACAT19](https://indico.cern.ch/event/708041/contributions/3276177/) and [CHEP19](https://doi.org/10.1051/epjconf/202024506027) (and [preliminary results at the 2018 ROOT Users workshop in Sarajevo](https://indico.cern.ch/event/697389/contributions/3062028/)). That version was redesigned starting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extensio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:4708,usability,help,help,4708,"rting from 2019 to better integrate with the rest of the code and at the same time untangle the test statistics classes to conceptually bring them closer to the math, instead of the more implementation-detail oriented existing design (RooAbsTestStatistic et al.). The new packages include the following tests, which should probably still be added to the testing infrastructure somehow:. 1. MultiProcess:. 1. test_RooFitMultiProcess_Messenger. 2. test_RooFitMultiProcess_ProcessManager. 3. test_RooFitMultiProcess_Job. 2. TestStatistics:. 1. testLikelihoodGradientJob. 2. testLikelihoodSerial. 3. testRooRealL. 3. RooFitZMQ:. 1. test_RooFitZMQ. 2. test_RooFitZMQ_polling. 3. test_RooFitZMQ_HWM. 4. test_RooFitZMQ_load_balancing. 4. RooFitCore:. 1. testRooGradMinimizer. 2. testBidirMMapPipe. 3. testMPFEnll. From my side (and that of the NL eScience Center), the project has ended and time has run out to make any further major contributions to it, except, of course finishing this PR and providing help to get it working and to possibly hand over further development :). Here are some notes for possible future work:. - RooFitZMQ includes an extension of ZeroMQ itself: a ppoll function. This function should ideally be contributed to ZeroMQ, but I have had no time for this. The motivation behind ppoll is given in this [blog post](https://blog.esciencecenter.nl/combining-zeromq-posix-signals-b754f6f29cd6). - At the last moment, I decided to reimplement part of the Queue functionality. The task distribution and parameter updating functionalities are now done directly using appropriate ZeroMQ sockets instead of indirectly through the Queue. The old-style Queue functionality, however, has not been cleaned up yet. Doing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7238,usability,support,support,7238,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/pull/8294:7311,usability,input,input,7311,"oing so will clean up the ""plumbing"" of the MultiProcess functions quite a bit. - Benchmarking and optimization still has to be done for this version as well. The scaling results of the proof of concept (see references above) should be reproducible with this reimplementation, but this possibly still needs some tuning. - After the most recent merging in of master, the RooGradMinimizer tests no longer pass, because the numbers are no longer floating point exactly the same. We have not looked into why, but one possible source is the reworked Kahan summation class. This was applied in RooMinimizerFcn, but not yet in our external-gradient classes. - The proof-of-concept version classes are also still present in the source tree (`roofitcore/MultiProcess`), but have only been partially maintained since we started with the final version. Probably the best thing to do there is to remove that, but maybe people disagree and want to keep it for comparison while benchmarking and reproducing the results of the proof-of-concept benchmarks. Note: BidirMMapPipe is in there as well, since it was moved there. This class is used in the RooRealMPFE event-based parallelization method that was present already before I started. `RooGaussMinimizerFcn` and `RooTaskSpec` were also part of our proof-of-concept exploration work. - Similarly, there is some left-over code from benchmarks that is probably now deprecated. In particular, `RooTimer` and `RooJSONListFile`, but also strewn around the code there are still some `chrono` includes or other timing remnants. This work was done over the past 5 years at the initiative of Wouter Verkerke @wverkerke under a Netherlands eScience Center grant, with direct code contributions from @vincecr0ft and @ipelupessy on the RooFit side and @roelaaij on ZeroMQ, lots of support from @cburgard, Lydia Brenner and @jiskattema, invaluable design input from @hageboeck and @lmoneta in the final stage of moving from proof of concept version to the version before you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8294
https://github.com/root-project/root/issues/8295:17,deployability,fail,failing,17,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:673,deployability,build,build,673,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:29,integrability,sub,sub-branches,29,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:890,integrability,pub,public,890,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:17,reliability,fail,failing,17,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:842,reliability,pra,pragma,842,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:627,safety,input,input,627,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:741,testability,emul,emulates,741,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:2549,testability,context,context,2549,"nside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next();. *ri;. *rx;. *rxy;. std::cout << ""x: "" << *rx << '\n';. t.Fill();. t.Write();. }. TFile f(""out.root"");. f.Get<TTree>(""t"")->Scan();. }. ```. Can be run with:. ```. $ root -l -b -q xy_t.h+; g++ -o main main.cpp xy_t_h.so $(root-config --libs --cflags) && env LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:."" ./main. ```. Reading and writing of the `xy` branch can be removed, in which case a warning is printed but wrong data is still written to file. Removing the `ClassDef` from `xy_t` removes the problem and the correct data is written out. ### Additional context. <!--. Add any other context about the problem here. -->. The original report is https://root-forum.cern.ch/t/rdataframe-multi-file-with-class-branch-bug-report/45156, in the context of RDataFrame::Snapshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:2578,testability,context,context,2578,"nside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next();. *ri;. *rx;. *rxy;. std::cout << ""x: "" << *rx << '\n';. t.Fill();. t.Write();. }. TFile f(""out.root"");. f.Get<TTree>(""t"")->Scan();. }. ```. Can be run with:. ```. $ root -l -b -q xy_t.h+; g++ -o main main.cpp xy_t_h.so $(root-config --libs --cflags) && env LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:."" ./main. ```. Reading and writing of the `xy` branch can be removed, in which case a warning is printed but wrong data is still written to file. Removing the `ClassDef` from `xy_t` removes the problem and the correct data is written out. ### Additional context. <!--. Add any other context about the problem here. -->. The original report is https://root-forum.cern.ch/t/rdataframe-multi-file-with-class-branch-bug-report/45156, in the context of RDataFrame::Snapshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:2732,testability,context,context,2732,"nside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next();. *ri;. *rx;. *rxy;. std::cout << ""x: "" << *rx << '\n';. t.Fill();. t.Write();. }. TFile f(""out.root"");. f.Get<TTree>(""t"")->Scan();. }. ```. Can be run with:. ```. $ root -l -b -q xy_t.h+; g++ -o main main.cpp xy_t_h.so $(root-config --libs --cflags) && env LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:."" ./main. ```. Reading and writing of the `xy` branch can be removed, in which case a warning is printed but wrong data is still written to file. Removing the `ClassDef` from `xy_t` removes the problem and the correct data is written out. ### Additional context. <!--. Add any other context about the problem here. -->. The original report is https://root-forum.cern.ch/t/rdataframe-multi-file-with-class-branch-bug-report/45156, in the context of RDataFrame::Snapshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:482,usability,behavi,behavior,482,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:627,usability,input,input,627,"TChain::AddClone failing for sub-branches of branch of type with ClassDef; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:1390,usability,Close,Close,1390,"sue still exists in today's master"". -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next();. *ri;. *rx;. *rxy;. std::cout << ""x: "" << *rx << '\n';. t.Fill();. t.Write();. }. TFile f(""out.root"");. f.Get<TTree>(""t"")->Scan();. }. ```. Can be run with:. ```. $ root -l -b -q xy_t.h+; g++ -o main main.cpp xy_t_h.so $(root-config --libs --cflags) && env LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:."" ./main. ```. Reading and writing of the `xy` branch can be removed, in which case a warning is p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8295:1553,usability,Close,Close,1553,"something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. The following code, which emulates what happens inside a RDataFrame Snapshot, silently writes wrong data:. ```cpp. // xy_t.h. #pragma once. #include <Rtypes.h>. class xy_t {. public:. double x;. double y;. xy_t() : x(-1), y(-1) {}. ~xy_t(){};. ClassDef(xy_t, 1); // remove this to remove the problem. };. ```. ```cpp. // main.cpp. #include <TFile.h>. #include <TChain.h>. #include <TSystem.h>. #include <TTree.h>. #include <TTreeReader.h>. #include <iostream>. #include ""xy_t.h"". void write_inputs() {. xy_t xy;. int i = 0;. {. TFile f(""in1.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 1;. xy.x = xy.y = 1;. t.Fill();. t.Write();. f.Close();. }. {. TFile f(""in2.root"", ""recreate"");. TTree t(""t"", ""t"");. t.Branch(""xy"", &xy);. t.Branch(""i"", &i);. i = 2;. xy.x = xy.y = 2;. t.Fill();. t.Write();. f.Close();. }. }. int main() {. write_inputs();. TChain c(""t"");. c.Add(""in1.root"");. c.Add(""in2.root"");. TTreeReader r(&c);. TTreeReaderValue<int> ri(r, ""i"");. TTreeReaderValue<double> rx(r, ""x"");. TTreeReaderValue<xy_t> rxy(r, ""xy"");. {. r.Next();. TFile f(""out.root"", ""recreate"");. TTree t(""t"", ""t"");. c.AddClone(&t);. t.Branch(""i"", &(*ri));. t.Branch(""x"", &(*rx));. t.Branch(""xy"", &(*rxy));. std::cout << ""x: "" << *rx << '\n';. t.Fill();. r.Next();. *ri;. *rx;. *rxy;. std::cout << ""x: "" << *rx << '\n';. t.Fill();. t.Write();. }. TFile f(""out.root"");. f.Get<TTree>(""t"")->Scan();. }. ```. Can be run with:. ```. $ root -l -b -q xy_t.h+; g++ -o main main.cpp xy_t_h.so $(root-config --libs --cflags) && env LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:."" ./main. ```. Reading and writing of the `xy` branch can be removed, in which case a warning is printed but wrong data is still written to file. Removing the `ClassDef` from `xy_t` removes the problem and the correct data is written out. ### Additional context",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295
https://github.com/root-project/root/issues/8297:326,availability,operat,operator,326,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:923,availability,operat,operator,923,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1664,availability,operat,operator,1664,"Safety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2406,availability,operat,operator,2406,":477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopD",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3136,availability,operat,operator,3136,"ead_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4846,availability,operat,operator,4846,"/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6556,availability,operat,operator,6556,"/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1359,deployability,build,build,1359,"lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1429,deployability,build,build,1429,"hread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned lo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2101,deployability,build,build,2101,"cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2171,deployability,build,build,2171,"C01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2843,deployability,build,build,2843,"xx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2913,deployability,build,build,2913,"01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4009,deployability,build,builds,4009,"locks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thre",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4016,deployability,build,build-,4016,"re definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4552,deployability,build,build,4552," TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metaclin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4623,deployability,build,build,4623,"/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5719,deployability,build,builds,5719,"locks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thre",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5726,deployability,build,build-,5726,"re definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6262,deployability,build,build,6262," TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metaclin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6333,deployability,build,build,6333,"/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7429,deployability,build,builds,7429,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7436,deployability,build,build-,7436,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7972,deployability,build,build,7972,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:8043,deployability,build,build,8043,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:463,energy efficiency,core,core,463,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:538,energy efficiency,core,core,538,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:615,energy efficiency,core,core,615,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:694,energy efficiency,core,core,694,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1080,energy efficiency,core,core,1080,"ning valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1306,energy efficiency,core,core,1306,"i/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss reco",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1821,energy efficiency,core,core,1821,"ecord 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2048,energy efficiency,core,core,2048,"const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss reco",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2563,energy efficiency,core,core,2563,"ord 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2790,energy efficiency,core,core,2790,"onst*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(Cal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3293,energy efficiency,core,core,3293," in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3608,energy efficiency,core,core,3608,"hreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3720,energy efficiency,core,core,3720,"q/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3832,energy efficiency,core,core,3832,"read in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3916,energy efficiency,core,core,3916,"/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4498,energy efficiency,core,core,4498,"user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5003,energy efficiency,core,core,5003,"ser/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5318,energy efficiency,core,core,5318,"dFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5430,energy efficiency,core,core,5430,"ui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5542,energy efficiency,core,core,5542,"ead in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5626,energy efficiency,core,core,5626,"/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6208,energy efficiency,core,core,6208,"user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6713,energy efficiency,core,core,6713,"ser/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7028,energy efficiency,core,core,7028,"dFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7140,energy efficiency,core,core,7140,"ui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7252,energy efficiency,core,core,7252,"ead in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they shou",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7336,energy efficiency,core,core,7336,"/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together wi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7918,energy efficiency,core,core,7918,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:8194,safety,prevent,prevent,8194,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:247,security,loss,loss,247,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:817,security,loss,loss,817,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1557,security,loss,loss,1557,"ad.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2299,security,loss,loss,2299,"_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3041,security,loss,loss,3041,"_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4751,security,loss,loss,4751,".cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6461,security,loss,loss,6461,".cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:8194,security,preven,prevent,8194,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:293,usability,user,user,293,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:740,usability,user,user,740,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:886,usability,user,user,886,"valgrind TThread Init Printf leak definitely lost bytes; ### Describe the bug. Running valgrind with a TApplication using TThreads leads to several 'definitely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:15",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1152,usability,user,user,1152,"itely lost' bytes. ```. 72 (16 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:4",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1227,usability,user,user,1227,"efinitely lost in loss record 9,521 of 22,023. in main in /home/user/zdt-daq/gui/main.cxx:26. 1: operator new(unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Init() in /opt/root_src/core/thread/src/TThread.cxx:342. 3: TThread::Initialize() in /opt/root_src/core/thread/src/TThread.cxx:302. 4: ROOT_TThread_Initialize in /opt/root_src/core/thread/src/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1626,usability,user,user,1626,"rc/TThread.cxx:67. 5: ROOT::EnableThreadSafety() in /opt/root_src/core/base/src/TROOT.cxx:498. 6: main in /home/user/zdt-daq/gui/main.cxx:26. 2,048 bytes in 1 blocks are definitely lost in loss record 20,895 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1893,usability,user,user,1893,"daq/gui/ThSFMC01.cpp:57. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:1969,usability,user,user,1969,"-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:57. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2368,usability,user,user,2368,"-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,896 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2635,usability,user,user,2635,"q/gui/ThSFMC01.cpp:193. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCall",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:2711,usability,user,user,2711,"linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:193. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3083,usability,Stop,Stop,3083,"tart_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3099,usability,user,user,3099,"build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,897 of 22,023. in ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3338,usability,Stop,Stop,3338,"::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3354,usability,user,user,3354,"() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3424,usability,user,user,3424,"ned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:3500,usability,user,user,3500,"ux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:206. 4: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 5: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 6: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 7: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4004,usability,user,user,4004,"in 1 blocks are definitely lost in loss record 20,898 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/cor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4124,usability,user,user,4124,"p:116. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4199,usability,user,user,4199,"nd/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4267,usability,user,user,4267,", ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TCl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4341,usability,user,user,4341,") in /home/user/zdt-daq/gui/RThread.cpp:116. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TCling",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4418,usability,user,user,4418,"ome/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4793,usability,Stop,Stop,4793,"nc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:4809,usability,user,user,4809,"nst in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5048,usability,Stop,Stop,5048,"de/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5064,usability,user,user,5064,"7. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5134,usability,user,user,5134,"/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5210,usability,user,user,5210,"gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5714,usability,user,user,5714,"in 1 blocks are definitely lost in loss record 20,899 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/cor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5834,usability,user,user,5834,"p:117. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5909,usability,user,user,5909,"nd/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:5977,usability,user,user,5977,", ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TCl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6051,usability,user,user,6051,") in /home/user/zdt-daq/gui/RThread.cpp:117. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TCling",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6128,usability,user,user,6128,"ome/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6503,usability,Stop,Stop,6503,"nc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6519,usability,user,user,6519,"nst in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6758,usability,Stop,Stop,6758,"de/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6774,usability,user,user,6774,"7. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6844,usability,user,user,6844,"/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:6920,usability,user,user,6920,"gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. 2,048 bytes in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7424,usability,user,user,7424,"in 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self buil",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7544,usability,user,user,7544,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7619,usability,user,user,7619,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7687,usability,user,user,7687,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7761,usability,user,user,7761,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:7838,usability,user,user,7838,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/issues/8297:8142,usability,behavi,behavior,8142,"n 1 blocks are definitely lost in loss record 20,900 of 22,023. in RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 1: operator new[](unsigned long) in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so. 2: TThread::Printf(char const*, ...) in /opt/root_src/core/thread/src/TThread.cxx:935. 3: RThread::Stop() in /home/user/zdt-daq/gui/RThread.cpp:118. 4: MainWindow::DoStopDAQ() in /home/user/zdt-daq/gui/MainWindow.cpp:1720. 5: MainWindow::SaveAndExit() in /home/user/zdt-daq/gui/MainWindow.cpp:1206. 6: 0x1e5de029. 7: TClingCallFunc::exec(void*, void*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:1843. 8: TClingCallFunc::Exec(void*, TInterpreterValue*) in /opt/root_src/core/metacling/src/TClingCallFunc.cxx:2102. 9: TCling::CallFunc_Exec(CallFunc_t*, void*) const in /opt/root_src/core/metacling/src/TCling.cxx:7788. 10: TQConnection::SendSignal() in /opt/root_src/core/base/inc/TQConnection.h:76. 11: void TQObject::EmitVA<>(char const*, int) in /home/user/builds/build-root_src-Desktop-Debug/include/TQObject.h:137. 12: void ThSFMC01::EmitVA<>(char const*, int) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 13: ThSFMC01::Emit(char const*) in /home/user/zdt-daq/gui/ThSFMC01.hpp:22. 14: ThSFMC01::Finished() in /home/user/zdt-daq/gui/ThSFMC01.cpp:47. 15: ThSFMC01::ThreadFunction() in /home/user/zdt-daq/gui/ThSFMC01.cpp:212. 16: RThread::ThreadHandle(void*) in /home/user/zdt-daq/gui/RThread.cpp:156. 17: TThread::Function(void*) in /opt/root_src/core/thread/src/TThread.cxx:828. 18: start_thread in /build/glibc-eX1tMB/glibc-2.31/nptl/pthread_create.c:477. 19: clone in /build/glibc-eX1tMB/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:95. ```. ### Expected behavior. The valgrind-ROOT suppression file should prevent these warnings. Or if they are real leaks, they should be fixed. ### To Reproduce. Use TThread::Init() and TThread::Printf() together with valgrind --leak-check=full. ### Setup. 1. ROOT git master. 2. Ubuntu 20. 3. self built",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8297
https://github.com/root-project/root/pull/8299:138,modifiability,deco,decodeObjOnTheFly,138,"[RF] Make Conditional/ProjectedObservables store RooArgSet as object; This is to make the RooArgSet payload accessible via. RooCmdConfig::decodeObjOnTheFly, which is used [in one of the RooNLLVar. constructors](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooNLLVar.cxx#L97). This fixes Jira issue [ROOT-6895](https://sft.its.cern.ch/jira/browse/ROOT-6895).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8299
https://github.com/root-project/root/pull/8299:108,security,access,accessible,108,"[RF] Make Conditional/ProjectedObservables store RooArgSet as object; This is to make the RooArgSet payload accessible via. RooCmdConfig::decodeObjOnTheFly, which is used [in one of the RooNLLVar. constructors](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooNLLVar.cxx#L97). This fixes Jira issue [ROOT-6895](https://sft.its.cern.ch/jira/browse/ROOT-6895).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8299
https://github.com/root-project/root/issues/8300:1054,availability,Operat,Operating,1054,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1129,availability,down,download,1129,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:978,deployability,build,build,978,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1042,deployability,version,version,1042,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1111,deployability,instal,install,1111,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1042,integrability,version,version,1042,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:633,interoperability,share,share,633,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:60,modifiability,paramet,parameter,60,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:336,modifiability,paramet,parameter,336,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1042,modifiability,version,version,1042,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:940,safety,input,input,940,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1183,testability,context,context,1183,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:1212,testability,context,context,1212,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:445,usability,user,user,445,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:795,usability,behavi,behavior,795,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/issues/8300:940,usability,input,input,940,"TTree::GetEntry should not take the entry number as default parameter; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. In:. https://root.cern.ch/doc/master/classTTree.html#a9fc48df5560fce1a2d63ecd1ac5b40cb. the entry number is zero by default, that should not be a default parameter. If I wanted to get the zeroth entry, I would just get the zeroth entry. On the other hand, If the user forgets to put the entry there, the compiler will be fine with it and we won't find the mistake until we check the outputs that will all correspond to the zeroth entry. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8300
https://github.com/root-project/root/pull/8301:183,interoperability,bind,binds,183,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:95,modifiability,variab,variable,95,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:183,modifiability,bind,binds,183,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:331,reliability,doe,does,331,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:43,safety,test,test,43,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:43,testability,test,test,43,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8301:302,testability,understand,understand,302,"[DF] Fix gcc 11 warning; ../tree/dataframe/test/dataframe_interface.cxx:451:28: warning: loop. variable ‘col’ of type ‘const string&’ {aka ‘const. std::__cxx11::basic_string<char>&’} binds to a temporary constructed. from type ‘const char* const’ [-Wrange-loop-construct]. @Axel-Naumann I don't really understand why the const ref does not increase the lifetime of the temporary as usual in this case, but this is the warning: https://godbolt.org/z/ss4zz8v3M",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301
https://github.com/root-project/root/pull/8302:30,deployability,version,versions,30,Fix Makefile.win32 for latest versions of Visual Studio; Cleanup and remove obsolete options and compiler flags,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8302
https://github.com/root-project/root/pull/8302:30,integrability,version,versions,30,Fix Makefile.win32 for latest versions of Visual Studio; Cleanup and remove obsolete options and compiler flags,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8302
https://github.com/root-project/root/pull/8302:30,modifiability,version,versions,30,Fix Makefile.win32 for latest versions of Visual Studio; Cleanup and remove obsolete options and compiler flags,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8302
https://github.com/root-project/root/pull/8302:42,usability,Visual,Visual,42,Fix Makefile.win32 for latest versions of Visual Studio; Cleanup and remove obsolete options and compiler flags,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8302
https://github.com/root-project/root/issues/8304:419,usability,clear,clear,419,"Casts broken in ROOT prompt; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Weird/wrong results printed when converting different entities to `bool`:. 1. ```. root [0] int foo = 42. (int) 42. root [1] (bool)foo. (bool) true. root [2] bool(foo). (bool) false. ```. 2. ```. root [0] const char *foo = ""asda"". (const char *) ""asda"". root [1] !foo. (bool) false. root [2] bool(foo). (bool) false. root [3] bool(foo[0]). (bool ([0]) @0x55c4ba66f180. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8304
https://github.com/root-project/root/issues/8304:467,usability,behavi,behavior,467,"Casts broken in ROOT prompt; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Weird/wrong results printed when converting different entities to `bool`:. 1. ```. root [0] int foo = 42. (int) 42. root [1] (bool)foo. (bool) true. root [2] bool(foo). (bool) false. ```. 2. ```. root [0] const char *foo = ""asda"". (const char *) ""asda"". root [1] !foo. (bool) false. root [2] bool(foo). (bool) false. root [3] bool(foo[0]). (bool ([0]) @0x55c4ba66f180. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8304
https://github.com/root-project/root/pull/8306:124,testability,simpl,simple,124,Use string(FIND) instead of regex for matching directory names; Fixes #8305 . 5 places in RootMacros.cmake use regex when a simple string(FIND) suffices,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8306
https://github.com/root-project/root/pull/8306:124,usability,simpl,simple,124,Use string(FIND) instead of regex for matching directory names; Fixes #8305 . 5 places in RootMacros.cmake use regex when a simple string(FIND) suffices,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8306
https://github.com/root-project/root/issues/8307:907,availability,error,error,907,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:2045,availability,Operat,Operating,2045,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:778,deployability,contain,contains,778,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1195,deployability,fail,fails,1195,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1223,deployability,version,versions,1223,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1663,deployability,fail,fails,1663,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1964,deployability,Log,Log,1964,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:2026,deployability,version,version,2026,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:117,energy efficiency,model,model,117,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:256,energy efficiency,model,model,256,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1849,energy efficiency,load,load,1849,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:913,integrability,messag,messages,913,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1223,integrability,version,versions,1223,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1738,integrability,pub,public,1738,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:2026,integrability,version,version,2026,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:312,interoperability,distribut,distribution,312,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:913,interoperability,messag,messages,913,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:360,modifiability,paramet,parameters,360,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:397,modifiability,paramet,parameter,397,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:415,modifiability,paramet,parameter,415,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1223,modifiability,version,versions,1223,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:2026,modifiability,version,version,2026,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:907,performance,error,error,907,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1145,performance,time,time,1145,"pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1849,performance,load,load,1849,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1195,reliability,fail,fails,1195,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1288,reliability,doe,does,1288,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1663,reliability,fail,fails,1663,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:907,safety,error,error,907,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1796,safety,test,testWSsimulvsprod,1796,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1856,safety,test,testWSsimulvsprod,1856,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1964,safety,Log,Log,1964,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:117,security,model,model,117,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:256,security,model,model,256,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:559,security,sign,signal,559,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:748,security,sign,signal,748,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1964,security,Log,Log,1964,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1796,testability,test,testWSsimulvsprod,1796,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1856,testability,test,testWSsimulvsprod,1856,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1964,testability,Log,Log,1964,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:850,usability,close,close,850,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:907,usability,error,error,907,"[RF] Issue with RooSimultaneous in 6.24.00 ?; Hello. I noticed a weird feature in root 6.24.00, when trying to fit a model using a RooSimultaneous pdf. . Am I doing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1462,usability,behavi,behavior,1462,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8307:1723,usability,user,user,1723,"ing something forbidden in root 6.24.00 ? Best,. Jean-Baptiste. ### Describe the bug. I have a model with a single category, describing the shape of a distribution, with three unconstrained nuisance parameters, one constrained nuisance parameter and one parameter of interest. The three unconstrained NP describe the shape of the background and the background yield. The poi is proportional to the signal yield. The dataset is a background only dataset. . I can do the fit with as pdf : model_had1A = RooProdPdf (fsb_had1A, constbias_had1A) where. fsb = ns x fs + nb x fb, fs and fb are signal and background pdf, ns contains the poi, nb is free floating. It runs. smoothly even if we are close to the unphysical region (poi < 0). (Probably many error messages from the exploration of the unphysical region have been removed from the output.). I can also try a fit with the pdf : simPdf = RooSimultaneous (indexCat=had1A, had1A=model_had1A) : this is virtually the same pdf, but this time embeded in a RooSimultaneous object. The fit fails. Between the two root versions, one things that appeared weird to me is that fsb_had1A does not seem to be. normalized when embeded in the RooSimultaneous in root 6.24.00. Maybe that is fine, but this is different from. what I see in root 6.22.02. ### Expected behavior. I would expect exactly the same results in both fits, with a best fit poi = 0 and a reasonable uncertainty. This is what I see in root-6.22.02. In root 6.24.00 the fit with a RooSimultaneous fails. . ### To Reproduce. I put the code here /afs/cern.ch/user/j/jdevivi/public/ISSUEROOFIT. In root-6.24.00, I just do . root.exe testWSsimulvsprod.C. In root-6.22.02, I do. root.exe load.C testWSsimulvsprod.C. since I use a RooCrystalBall from root-6.24 and did not put the code in the workspace. Log files can be found in the same directory. ### Setup. ROOT version : 6.24.00. Operating system : macos 10.15.7 clang-12. I built root myself. But I also tried via a docker image built for ATLAS.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8307
https://github.com/root-project/root/issues/8308:2552,availability,Error,Error,2552,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1636,deployability,VERSION,VERSION,1636,"Ints::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2062,deployability,build,builds,2062,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2365,deployability,automat,automatically,2365,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2515,energy efficiency,current,currently,2515,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:282,integrability,pub,public,282,"ROOT_GENERATE_DICTIONARY is difficult to use correctly; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Consider the following source directory:. ```cpp. // TwoInts.hpp. #pragma once. class TwoInts {. int _a;. int _b;. public:. TwoInts() {}. TwoInts(int a, int b) : _a(a), _b(b) {}. int GetA() const;. int GetB() const;. TwoInts& SetA(int a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1636,integrability,VERSION,VERSION,1636,"Ints::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1710,integrability,COMPON,COMPONENTS,1710,"nts.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1710,interoperability,COMPON,COMPONENTS,1710,"nts.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2617,interoperability,specif,specify,2617,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1636,modifiability,VERSION,VERSION,1636,"Ints::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1710,modifiability,COMPON,COMPONENTS,1710,"nts.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2552,performance,Error,Error,2552,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:234,reliability,pra,pragma,234,"ROOT_GENERATE_DICTIONARY is difficult to use correctly; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. Consider the following source directory:. ```cpp. // TwoInts.hpp. #pragma once. class TwoInts {. int _a;. int _b;. public:. TwoInts() {}. TwoInts(int a, int b) : _a(a), _b(b) {}. int GetA() const;. int GetB() const;. TwoInts& SetA(int a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1399,reliability,pra,pragma,1399,"a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1430,reliability,pra,pragma,1430," ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to ad",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1461,reliability,pra,pragma,1461,"include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_inclu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1494,reliability,pra,pragma,1494,"s::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1527,reliability,pra,pragma,1527,"nt TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2525,reliability,doe,does,2525,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2552,safety,Error,Error,2552,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2365,testability,automat,automatically,2365,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1237,usability,tip,tiptr,1237," once. class TwoInts {. int _a;. int _b;. public:. TwoInts() {}. TwoInts(int a, int b) : _a(a), _b(b) {}. int GetA() const;. int GetB() const;. TwoInts& SetA(int a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1303,usability,tip,tiptr,1303,"woInts(int a, int b) : _a(a), _b(b) {}. int GetA() const;. int GetB() const;. TwoInts& SetA(int a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:1328,usability,tip,tiptr,1328,"(a), _b(b) {}. int GetA() const;. int GetB() const;. TwoInts& SetA(int a);. TwoInts& SetB(int b);. };. ```. ```cpp. // TwoInts.cpp. #include ""twoints.hpp"". int TwoInts::GetA() const { return _a; }. int TwoInts::GetB() const { return _b; }. TwoInts& TwoInts::SetA(int a) { _a = a; return *this; }. TwoInts& TwoInts::SetB(int b) { _b = b; return *this; }. ```. ```cpp. // readwrite_twoints.cpp. // compile with e.g.:. // g++ -o readwrite_twoints readwrite_twoints.cpp $(root-config --libs --cflags) twoints.cpp twoints_dict.cpp. #include ""TFile.h"". #include ""twoints.hpp"". #include <iostream>. int main() {. {. // write the `ti` object to an output file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source dir",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2552,usability,Error,Error,2552,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/issues/8308:2834,usability,document,document,2834,"tput file. TwoInts ti(1, 2);. TFile out_f(""f.root"", ""recreate"");. out_f.WriteObjectAny(&ti, ""TwoInts"", ""ti"");. std::cout << ""Written TwoInts("" << ti.GetA() << "", "" << ti.GetB() << "")\n"";. }. // read back the `ti` object from the file. TFile in_f(""f.root"");. auto *tiptr = in_f.Get<TwoInts>(""ti"");. std::cout << ""Read TwoInts("" << tiptr->GetA() << "", "" << tiptr->GetB() << "")\n"";. return 0;. }. ```. ```cpp. #ifdef __CLING__. #pragma link off all globals;. #pragma link off all classes;. #pragma link off all functions;. #pragma link C++ nestedclasses;. #pragma link C++ class TwoInts;. #endif // __CLING__. ```. ```cmake. # CMakeLists.txt. cmake_minimum_required(VERSION 3.9). project (readwrite_twoints CXX). find_package(ROOT REQUIRED COMPONENTS RIO). ROOT_GENERATE_DICTIONARY(twoints_dict twoints.hpp LINKDEF LinkDef.h). add_executable(readwrite_twoints readwrite_twoints.cpp twoints.cpp twoints_dict.cxx). target_link_libraries(readwrite_twoints ROOT::RIO). # These lines should not be necessary:. configure_file(twoints.hpp twoints.hpp COPYONLY) # This is necessary for out-of-source builds. add_dependencies(readwrite_twoints twoints_dict) # This ensures that the dictionary is generated before the executable. ```. The last two lines, especially the `configure_file`, should not be needed, ideally. `ROOT_GENERATE_DICTIONARY` should add the source directory to the include directories automatically, or at the very least it should make it possible to add it manually via `target_include_directories(twoints_dict.cxx PRIVATE .)`, which currently does not work:. ```. CMake Error at CMakeLists.txt:12 (target_include_directories):. Cannot specify include directories for target ""twoints_dict.cxx"" which is. not built by this project. ```. The end result is that `ROOT_GENERATE_DICTIONARY` is unnecessarily tricky to use correctly (in fact I don't think we document the correct usage anywhere). . More discussion can be found at https://mattermost.web.cern.ch/root/pl/ofzcxfxh3pfxdp4bzda319ftke .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308
https://github.com/root-project/root/pull/8309:348,availability,cluster,cluster,348,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:348,deployability,cluster,cluster,348,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:162,energy efficiency,load,load,162,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:297,energy efficiency,Load,LoadSealedPage,297,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:186,interoperability,Specif,Specifically,186,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:162,performance,load,load,162,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:297,performance,Load,LoadSealedPage,297,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:66,usability,support,support,66,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:422,usability,support,support,422,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8309:468,usability,Close,Closes,468,"[rntuple] Factor out common code in the sealed pages path and add support for sealed pages to DAOS; First, this PR factors out common parts of the code in commit/load of (sealed) pages. Specifically, this affects:. - `CommitPageImpl` and `CommitSealedPageImpl`. - `PopulatePageFromCluster()` and `LoadSealedPage()`. Locating the RPageInfo from the cluster index is now a member function of RPageRange. Second, it provides support for sealed pages in the DAOS backend. Closes issue #8079.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8309
https://github.com/root-project/root/pull/8310:40,interoperability,specif,specific,40,[skip-ci] \anchor names need to be more specific ...; … as they are not relative to a page.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8310
https://github.com/root-project/root/pull/8314:13,availability,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:508,deployability,patch,patch,508,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:261,energy efficiency,current,currently,261,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:42,interoperability,mismatch,mismatch,42,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:13,performance,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:13,safety,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:130,safety,input,input,130,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:412,safety,input,input,412,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:508,safety,patch,patch,508,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:517,safety,detect,detect,517,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:538,safety,compl,complain,538,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:508,security,patch,patch,508,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:517,security,detect,detect,517,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:538,security,compl,complain,538,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:387,testability,simpl,simple,387,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:13,usability,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:130,usability,input,input,130,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:387,usability,simpl,simple,387,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8314:412,usability,input,input,412,"[tree] Print error in case of branch kind mismatch in CopyAddresses; TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8314
https://github.com/root-project/root/pull/8315:48,modifiability,variab,variable,48,Fix gcc11 warning in TF2 - use of uninitialized variable;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8315
https://github.com/root-project/root/pull/8316:128,reliability,doe,does,128,"Fix gcc11 warning in TGeoManager destructor; Warning like:. ```. geom/geom/src/TGeoManager.cxx:521:4: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]. 521 | if (fHashVolumes) fHashVolumes->Clear(""nodelete""); SafeDelete(fHashVolumes);. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8316
https://github.com/root-project/root/pull/8316:231,safety,Safe,SafeDelete,231,"Fix gcc11 warning in TGeoManager destructor; Warning like:. ```. geom/geom/src/TGeoManager.cxx:521:4: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]. 521 | if (fHashVolumes) fHashVolumes->Clear(""nodelete""); SafeDelete(fHashVolumes);. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8316
https://github.com/root-project/root/pull/8316:212,usability,Clear,Clear,212,"Fix gcc11 warning in TGeoManager destructor; Warning like:. ```. geom/geom/src/TGeoManager.cxx:521:4: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]. 521 | if (fHashVolumes) fHashVolumes->Clear(""nodelete""); SafeDelete(fHashVolumes);. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8316
https://github.com/root-project/root/issues/8317:17,availability,failur,failure,17,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:17,deployability,fail,failure,17,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:307,deployability,build,build,307,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:530,deployability,fail,fails,530,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:515,energy efficiency,Current,Currently,515,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:17,performance,failur,failure,17,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:17,reliability,fail,failure,17,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:530,reliability,fail,fails,530,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:261,safety,input,input,261,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:116,usability,behavi,behavior,116,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:261,usability,input,input,261,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/issues/8317:559,usability,help,helper,559,"[DF] Compilation failure when a mutable lambda is passed to Foreach; ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. int i = 0;. ROOT::RDataFrame(10).Foreach([&](ULong64_t e) mutable { ++i; }, {""rdfentry_""});. return i;. }. ```. Currently this fails to compile because the helper type `AddSlotParameter` expects a const functor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8317
https://github.com/root-project/root/pull/8319:217,integrability,Discover,Discovered,217,"Fix bug in TText::Copy method; `fWcsTitle` accessed wrongly, following macro crashes:. ```. void bug(). {. TText txt1(0,0, L""Any text 1"");. TText txt2(0,0, L""Any text 2"");. . txt2 = txt1; // this is crashing. }. ```. Discovered in gcc11 warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8319
https://github.com/root-project/root/pull/8319:217,interoperability,Discover,Discovered,217,"Fix bug in TText::Copy method; `fWcsTitle` accessed wrongly, following macro crashes:. ```. void bug(). {. TText txt1(0,0, L""Any text 1"");. TText txt2(0,0, L""Any text 2"");. . txt2 = txt1; // this is crashing. }. ```. Discovered in gcc11 warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8319
https://github.com/root-project/root/pull/8319:43,security,access,accessed,43,"Fix bug in TText::Copy method; `fWcsTitle` accessed wrongly, following macro crashes:. ```. void bug(). {. TText txt1(0,0, L""Any text 1"");. TText txt2(0,0, L""Any text 2"");. . txt2 = txt1; // this is crashing. }. ```. Discovered in gcc11 warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8319
https://github.com/root-project/root/pull/8319:217,usability,Discov,Discovered,217,"Fix bug in TText::Copy method; `fWcsTitle` accessed wrongly, following macro crashes:. ```. void bug(). {. TText txt1(0,0, L""Any text 1"");. TText txt2(0,0, L""Any text 2"");. . txt2 = txt1; // this is crashing. }. ```. Discovered in gcc11 warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8319
https://github.com/root-project/root/pull/8321:1290,energy efficiency,Draw,DrawFillArea,1290,"pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:29: warning: ‘ET.EdgeTable::ymax’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~~^~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx: In member function ‘virtual void TASImage::DrawFillArea(UInt_t, TPoint*, const char*, const char*, UInt_t, UInt_t)’:. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5492:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5492 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5472:14: note: ‘ET’ declared here. 5472 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5494:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5494 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5472:14: note: ‘ET’ declared here. 5472 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5494:29: warning: ‘ET.EdgeTable::ymax’ may be used uninitialized [-Wmaybe-uninitialized]. 5494 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~~^~~~. /hom",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8321
https://github.com/root-project/root/pull/8321:70,modifiability,variab,variable,70,"Fix gcc11 warnings in TASImage; gcc11 complains about non-initialized variable, just make it happy. Warnings are:. ```. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5592:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5592 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:29: warning: ‘ET.EdgeTable::ymax’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~~^~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx: In member function ‘virtual void TASImage::DrawFillArea(UInt_t, TPoint*, const char*, const char*, UInt_t, UInt_t)’:. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5492:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5492 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5472:14: note: ‘ET’ declared here. 5472 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5494:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5494 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8321
https://github.com/root-project/root/pull/8321:38,safety,compl,complains,38,"Fix gcc11 warnings in TASImage; gcc11 complains about non-initialized variable, just make it happy. Warnings are:. ```. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5592:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5592 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:29: warning: ‘ET.EdgeTable::ymax’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~~^~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx: In member function ‘virtual void TASImage::DrawFillArea(UInt_t, TPoint*, const char*, const char*, UInt_t, UInt_t)’:. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5492:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5492 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5472:14: note: ‘ET’ declared here. 5472 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5494:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5494 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8321
https://github.com/root-project/root/pull/8321:38,security,compl,complains,38,"Fix gcc11 warnings in TASImage; gcc11 complains about non-initialized variable, just make it happy. Warnings are:. ```. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5592:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5592 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5594:29: warning: ‘ET.EdgeTable::ymax’ may be used uninitialized [-Wmaybe-uninitialized]. 5594 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~~^~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5582:14: note: ‘ET’ declared here. 5582 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx: In member function ‘virtual void TASImage::DrawFillArea(UInt_t, TPoint*, const char*, const char*, UInt_t, UInt_t)’:. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5492:9: warning: ‘ET.EdgeTable::scanlines._ScanLineList::next’ may be used uninitialized [-Wmaybe-uninitialized]. 5492 | pSLL = ET.scanlines.next;. | ~~~~~^~~~~~~~~~~~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5472:14: note: ‘ET’ declared here. 5472 | EdgeTable ET; // Edge Table header node. | ^~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx:5494:11: warning: ‘ET.EdgeTable::ymin’ may be used uninitialized [-Wmaybe-uninitialized]. 5494 | for (y = ET.ymin; y < ET.ymax; y++) {. | ~~^~~~~~~~~. /home/linev/git/webgui/graf2d/asimage/src/TASImage.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8321
https://github.com/root-project/root/issues/8323:75,availability,stead,steady,75,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1901,availability,operat,operator,1901," startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1932,availability,operat,operator,1932,"esident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2287,availability,operat,operator,2287,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2464,availability,operat,operator,2464,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2506,availability,operat,operator,2506,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2538,availability,operat,operator,2538,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2079,energy efficiency,alloc,allocating,2079,",RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the pr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2436,energy efficiency,alloc,allocate,2436,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3000,energy efficiency,alloc,allocator,3000,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3142,energy efficiency,alloc,allocated,3142,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1153,integrability,Batch,BatchMode,1153,"e forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooData",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2115,integrability,sub,substituting,2115,"),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2822,integrability,event,events,2822,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2859,integrability,event,events,2859,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:60,performance,memor,memory,60,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:82,performance,memor,memory,82,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:204,performance,memor,memory-increase-per-fitto-iteration,204,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1153,performance,Batch,BatchMode,1153,"e forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooData",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1293,performance,memor,memory,1293," #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1589,performance,Memor,Memory,1589,"t(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the me",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1758,performance,memor,memory,1758,". x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1812,performance,memor,memory,1812,"ervice::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1963,performance,memor,memory,1963," RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2340,performance,memor,memory,2340,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2590,performance,memor,memory,2590,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2685,performance,memor,memory,2685,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2708,performance,memor,memory,2708,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2729,performance,memor,memory,2729,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2873,performance,memor,memory,2873,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2917,performance,memor,memory,2917,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3059,performance,memor,memory,3059,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3152,performance,memor,memory,3152,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3204,performance,memor,memory,3204,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1831,reliability,doe,doesn,1831,"getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:500,safety,test,test,500,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:977,safety,input,input,977,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1213,safety,input,input,1213,"ase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1719,safety,compl,completely,1719,"rame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2609,safety,compl,completely,2609,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3188,safety,avoid,avoid,3188,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1719,security,compl,completely,1719,"rame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2609,security,compl,completely,2609,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:500,testability,test,test,500,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:60,usability,memor,memory,60,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:82,usability,memor,memory,82,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:204,usability,memor,memory-increase-per-fitto-iteration,204,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:867,usability,Minim,Minimization,867,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:977,usability,input,input,977,"[RF] Possible heap fragmentation because of RooDataSet with memory pool; A steady memory increase when iteratively calling RooAbsPdf::fitTo was reported in the forum:. https://root-forum.cern.ch/t/roofit-memory-increase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1213,usability,input,input,1213,"ase-per-fitto-iteration/44726. It can be reproduced with this C++ code:. ```C++. #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1293,usability,memor,memory,1293," #include ""RooFitResult.h"". #include ""RooDataSet.h"". #include ""RooRealVar.h"". #include ""RooGaussian.h"". #include ""RooPlot.h"". #include ""RooMsgService.h"". #include ""TRandom3.h"". #include ""TSystem.h"". void test() {. using namespace std;. RooRealVar x(""x"",""x"",-10,10);. RooDataSet d(""d"",""d"",RooArgSet(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1589,usability,Memor,Memory,1589,"t(x));. RooRealVar s(""s"",""s"",1,1,10);. RooRealVar m(""m"",""m"",0,-10,10);. RooGaussian g(""gauss"",""gauss(x,m,s)"",x,m,s);. RooPlot *f=x.frame();. for (Int_t j=0; j<300; ++j){. x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the me",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1758,usability,memor,memory,1758,". x.setVal(gRandom->Gaus(0,1));. d.add(x);. }. RooMsgService::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1812,usability,memor,memory,1812,"ervice::instance().getStream(1).removeTopic(RooFit::Minimization);. ProcInfo_t pinfo;. int startMemResident;. int endMemResident;. int niters=1000000;. RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:1963,usability,memor,memory,1963," RooArgSet input=RooArgSet(x);. for (Int_t i=0; i<niters; i++) {. std::unique_ptr<RooFitResult> roo_result{. g.fitTo(d,RooFit::PrintLevel(-1),RooFit::Save(),. RooFit::Minos(true),RooFit::BatchMode(true),RooFit::Save()). };. x.setVal(0);. g.getVal(input);. gSystem->GetProcInfo(&pinfo);. if(i % 100 == 0) {. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2340,usability,memor,memory,2340,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2590,usability,memor,memory,2590,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2665,usability,clear,clear,2665,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2685,usability,memor,memory,2685,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2708,usability,memor,memory,2708,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2729,usability,memor,memory,2729,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2873,usability,memor,memory,2873,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:2917,usability,memor,memory,2917,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3059,usability,memor,memory,3059,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3152,usability,memor,memory,3152,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/issues/8323:3204,usability,memor,memory,3204,"{. std::cout << i << "" memory usage "" << pinfo.fMemResident. << "" "" << pinfo.fMemVirtual << std::endl;. }. if (i==0). startMemResident=pinfo.fMemResident;. if (i==(niters-1)). endMemResident=pinfo.fMemResident;. }. int deltaMem=endMemResident-startMemResident;. double avgMem=(double)deltaMem/niters;. cout << endl << ""Memory increase = "" << deltaMem << endl;. cout << ""Avg increase per iteration = "" << avgMem << endl;. }. ```. The increase can be completely eliminated by not using the memory pool for RooDataSet. It is remarkable that the memory pool itself doesn't seem to be the problem. In fact, one can replace `RooDataSet::operator new` and `RooDataSet::operator delete` such that the memory pool is still active, but we don't use the addresses it gives us and pretend to deallocate immediately after allocating. This can be achieved by substituting the following code in [RooDataSet.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooDataSet.cxx#L143):. ```C++. void* RooDataSet::operator new (size_t bytes) {. // pretend we use the memory pool to demonstrate the pool itself is not the problem. memPool()->deallocate(memPool()->allocate(bytes));. return ::operator new(bytes);. }. void RooDataSet::operator delete (void* ptr) { ::operator delete(ptr); }. ```. With this change, the memory increase is completely gone, at least for my setup. To me it is not clear why using the memory pool causes the memory increase. The memory increase happens about every 5000 iterations and is exactly 624 bytes. However, these events are uncorrelated with special events in the memory pool, i.e. adding a new arena to the memory pool. Could it be that without using the addresses suggested by the default allocator, we get some heap fragmentation which causes the memory reserved by the process to go up, while we don't have an actual increase of allocated memory? The solution is probably to avoid using the memory pool for RooDataSet. My setup is ROOT master on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8323
https://github.com/root-project/root/pull/8324:244,energy efficiency,alloc,allocated,244,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:61,performance,memor,memory,61,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:87,performance,memor,memory,87,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:282,performance,memor,memory,282,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:474,performance,cach,caching,474,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:61,usability,memor,memory,61,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:87,usability,memor,memory,87,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/pull/8324:282,usability,memor,memory,282,"[RF] Use UniqueId to replace pointer comparisons and disable memory pool; Disables the memory pool for RooArgSet and RooDataSet to fix https://github.com/root-project/root/issues/8323. This entails that we can't rely anymore on all RooDataSets allocated on the heap having a unique memory address, so a new `uniqueId` class member is introduced to replace the pointer comparisons. The RooArgSet already had such a `uniqueId` class member, which is already used as a key for caching as of PR https://github.com/root-project/root/pull/10333, instead of doing pointer comparisons. More details in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8324
https://github.com/root-project/root/issues/8326:1828,deployability,updat,update,1828,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1991,deployability,depend,dependent,1991,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1991,integrability,depend,dependent,1991,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1991,modifiability,depend,dependent,1991,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1714,reliability,doe,does,1714,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1828,safety,updat,update,1828,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1991,safety,depend,dependent,1991,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1828,security,updat,update,1828,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1991,testability,depend,dependent,1991,"roject/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://github.com/matplotlib/matplotlib/issues/8308)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:545,usability,user,user,545,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:550,usability,user,users,550,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:602,usability,user,user,602,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:607,usability,user,users,607,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:827,usability,user,user,827,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:985,usability,command,commands,985,"Jupyter + ROOT: too many open files; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/issues/8326:1080,usability,behavi,behavior,1080,"ch in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. On Linux, in a Juyter/ROOT Python notebook, every cell execution makes the `python` process open two ""files"":. . lrwx------ 1 user users 64 2 Jun 22.33 77 -> /dev/pts/7. lr-x------ 1 user users 64 2 Jun 22.33 78 -> 'pipe:[214404]'. . one to the terminal bound to the notebook server (`/dev/pts/7`), and another always a different pipe reading for nothing to write in it, e.g. from `lsof`:. . python3.8 16586 user 78r FIFO 0,10 0t0 214404 pipe. . These stay open, making the process reach the OS limit of open files sooner or later, at which point grief ensues. Some commands (e.g. `matplotlib` figures) may create additional pairs out of the void. ### Expected behavior. The open file descriptor count should be roughly stable and not proportional to the number of executed cells. ### To Reproduce. . jupyter --notebook # or root --notebook. . then execute _(empty lines mark cell boundaries)_:. ```.py. import os. def printFiles(): print(f""PID={os.getpid()} files={len(os.listdir(f'/proc/{os.getpid()}/fd'))}""). printFiles(). printFiles(). printFiles(). printFiles(). import ROOT. printFiles(). printFiles(). printFiles(). printFiles(). ```. I get a file count of `43` or `44` on each cell before importing ROOT, and from the _next_ cell, each cell increments by 4 (`48`, `52`, ...). The issue does not appear on plain `python`/`ipython`. ### Setup. Working with:. * Gentoo Linux, amd64, kernel 5.12.4 (last update a few days ago). * ROOT 6.24/00. * Python 3.8.10 (`dev-lang/python-3.8.10_p1` from Gentoo). * Jupyter 1.0.0. * ipython 7.24.0. I assume this issue is setup-dependent, or it would have been reported already... ([actually, it was in 2017](https://gith",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8326
https://github.com/root-project/root/pull/8327:20,availability,error,error,20,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:51,availability,error,error,51,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:136,availability,error,error,136,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:167,availability,error,error,167,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:259,availability,error,error,259,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:290,availability,error,error,290,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:356,availability,error,error-,356,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:386,availability,error,error,386,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:993,availability,error,error,993,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:64,deployability,updat,updating,64,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:99,deployability,version,version,99,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:712,deployability,build,build,712,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:99,integrability,version,version,99,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:99,modifiability,version,version,99,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:20,performance,error,error,20,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:51,performance,error,error,51,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:136,performance,error,error,136,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:167,performance,error,error,167,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:259,performance,error,error,259,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:290,performance,error,error,290,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:356,performance,error,error-,356,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:386,performance,error,error,386,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:993,performance,error,error,993,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:20,safety,error,error,20,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:51,safety,error,error,51,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:64,safety,updat,updating,64,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:136,safety,error,error,136,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:167,safety,error,error,167,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:259,safety,error,error,259,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:290,safety,error,error,290,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:356,safety,error,error-,356,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:386,safety,error,error,386,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:993,safety,error,error,993,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:64,security,updat,updating,64,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:20,usability,error,error,20,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:51,usability,error,error,51,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:73,usability,Visual,Visual,73,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:136,usability,error,error,136,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:167,usability,error,error,167,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:259,usability,error,error,259,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:290,usability,error,error,290,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:324,usability,visual,visualstudio,324,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:356,usability,error,error-,356,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:386,usability,error,error,386,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8327:993,usability,error,error,993,"[Windows] Fix fatal error C1001: Internal compiler error; After updating Visual Studio 2019 to the version `16.10.0`, there is a `fatal error C1001: Internal compiler error` when compiling `G__MathCore.cxx`. See the bug report at Microsoft: [[v16.10.0] Fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/v16100-fatal-error-c1001-internal-compiler-error/1437980?from=email&viewtype=all). And the proposed workaround:. 1. Remove the `auto` return type from `FunctorGradHandler::Clone()`. This function is the cause of the ICE and replacing `auto` with `ImplFunc*` will resolve the issue. 2. Only if fixing the source is not an option, add `/d1deducedReturnEncoding-` to your build. This will disable the recent compiler work around deduced return types. Keep in mind that this option should only be used as a last resort because it is not a permanent switch. Interestingly enough, the `auto` return type was introduced as a workaround for another compiler error with `VS 2019 (16.4.3)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8327
https://github.com/root-project/root/pull/8328:277,energy efficiency,Cpu,Cpu,277,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:291,energy efficiency,measur,measure,291,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:308,energy efficiency,clock,clock,308,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:314,energy efficiency,cpu,cpu,314,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:17,performance,perform,performance,17,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:98,performance,perform,performance,98,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:277,performance,Cpu,Cpu,277,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:314,performance,cpu,cpu,314,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:318,performance,time,time,318,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:384,performance,throughput,throughput,384,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:17,usability,perform,performance,17,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:98,usability,perform,performance,98,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8328:410,usability,Close,Closes,410,"[ntuple] Add new performance counters to `RPageSink{File,Daos}`; This pull-request adds new write performance counters to the file/DAOS backends:. - fSzWritePayload: that keeps track of the total volume written in committed pages. - fSzZip: volume before zipping. - fTime{Wall,Cpu}Zip: that measure the wall clock/cpu time spent compressing. This suffices to compute the actual write throughput, where needed. Closes issue #8283.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8328
https://github.com/root-project/root/pull/8329:149,availability,cluster,clusters,149,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:325,availability,cluster,clusters,325,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:545,availability,cluster,cluster,545,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1269,availability,cluster,cluster,1269,"attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid <",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:149,deployability,cluster,clusters,149,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:325,deployability,cluster,clusters,325,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:358,deployability,pipelin,pipeline,358,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:467,deployability,pipelin,pipeline,467,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:545,deployability,cluster,cluster,545,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1269,deployability,cluster,cluster,1269,"attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid <",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2368,deployability,log,logic,2368," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2378,deployability,automat,automatically,2378," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2613,deployability,log,logic,2613," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:801,energy efficiency,model,model,801,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:852,energy efficiency,model,model,852,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:915,energy efficiency,model,model,915,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1095,energy efficiency,model,model,1095,"`RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1638,energy efficiency,Load,LoadEntry,1638,"e. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching op",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1837,energy efficiency,model,model,1837," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1888,energy efficiency,model,model,1888," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1951,energy efficiency,model,model,1951," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2040,energy efficiency,model,model,2040," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2132,energy efficiency,Load,LoadEntry,2132," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:358,integrability,pipelin,pipeline,358,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:467,integrability,pipelin,pipeline,467,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2482,modifiability,variab,variable,2482," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:39,performance,cach,caching,39,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:90,performance,cach,caching,90,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:569,performance,memor,memory,569,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:630,performance,cach,cached,630,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1398,performance,cach,cachedntuple,1398,"To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1638,performance,Load,LoadEntry,1638,"e. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching op",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1695,performance,cach,cached,1695," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1810,performance,cach,cachedntuple,1810," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2132,performance,Load,LoadEntry,2132," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2414,performance,cach,cached,2414," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2633,performance,cach,caching,2633," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2368,safety,log,logic,2368," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2555,safety,avoid,avoided,2555," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2567,safety,Test,Tests,2567," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2583,safety,compl,complex,2583," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2613,safety,log,logic,2613," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:801,security,model,model,801,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:852,security,model,model,852,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:915,security,model,model,915,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1095,security,model,model,1095,"`RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1837,security,model,model,1837," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1888,security,model,model,1888," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:1951,security,model,model,1951," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2040,security,model,model,2040," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2368,security,log,logic,2368," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2583,security,compl,complex,2583," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2613,security,log,logic,2613," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2368,testability,log,logic,2368," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2378,testability,automat,automatically,2378," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2567,testability,Test,Tests,2567," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2613,testability,log,logic,2613," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:27,usability,support,support,27,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:569,usability,memor,memory,569,"[WIP][NTuple][skip-ci] Add support for caching of RNTuple; This is a very early draft for caching `RNTuple`s. The goal is to save only the portions (clusters) of the original RNTuple that are actually read during an analysis to a new RNTuple . In this draft it is shown an attempt at exercising the part where the compressed clusters are saved during the IO pipeline already implemented in RClusterPool. To this end, an `RPageSink` is created at the beginning of the pipeline with the same header as the RNTuple being read. After the compressed cluster is retrieved in memory, its columns and pages are traversed and saved to the cached RNTuple. For now this feature can be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8329:2661,usability,user,user,2661," be reproduced with a very limited example, divided in three pieces. ### 1. Write an RNTuple. ```cpp. void write_ntuple(). {. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleWriter::Recreate(std::move(model), ntuplename, filename);. constexpr int nentries = 10;. for (int i = 0; i < nentries; i++) {. *myintfield = i;. *myintfieldsquared = i*i;. ntuple->Fill();. // Create a cluster every 5 entries. if (i == 4 || i == 9) ntuple->CommitCluster();. }. }. ```. ### 2. Read the RNTuple (this will create a `cachedntuple.root` file). ```cpp. void read_ntuple(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""myntuple.root""};. auto ntuple = RNTupleReader::Open(ntuplename, filename);. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. }. }. ```. ### 3. Print info of the cached RNTuple. ```cpp. void read_cache(). {. std::string_view ntuplename{""myntuple""};. std::string_view filename{""cachedntuple.root""};. auto model = RNTupleModel::Create();. auto myintfield = model->MakeField<int>(""myintfield"");. auto myintfieldsquared = model->MakeField<int>(""myintfieldsquared"");. auto ntuple = RNTupleReader::Open(std::move(model), ntuplename, filename);. ntuple->PrintInfo();. for (auto entryid: *ntuple){. ntuple->LoadEntry(entryid);. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfield << ""\n"";. std::cout << ""Read entry "" << entryid << "" with value "" << *myintfieldsquared << ""\n"";. }. }. ```. ## TODOS. 1. Still missing all the logic for automatically switching to read the cached RNTuple rather than the original one. 2. That `entriessofar` variable needed to pass to the `CommitCluster` function hopefully can be avoided. 3. Tests with more complex data schemes. 4. Some logic to enable the caching optionally from the user side",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8329
https://github.com/root-project/root/pull/8331:5,usability,Prefer,Prefer,5,[DF] Prefer GetEntriesUnsafe when we know there are no races;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8331
https://github.com/root-project/root/pull/8333:42,deployability,Log,Log,42,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:129,integrability,filter,filter,129,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:42,safety,Log,Log,42,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:107,safety,valid,validity,107,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:42,security,Log,Log,42,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:42,testability,Log,Log,42,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8333:151,usability,Clear,Clear,151,Eve7 Handle RFileDialog response ; Change Log:. - Enable RFileDialog through REveManager. - Add checks for validity of table and filter expressions. - Clear unnecessary REveManager printouts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8333
https://github.com/root-project/root/pull/8334:229,safety,avoid,avoid,229,"[ntuple] Add explicit EnableMT methods to RNTupleReader, Writer; Allow users to request multithreaded (de)compression even if IMT is not enabled globally with `ROOT::EnableImplicitMT()`. This required a change to `TTaskGroup` to avoid checking if IMT was enabled -- as I understand it, we can use TBB even if IMT isn't turned on because we don't use `RTaskArena`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334
https://github.com/root-project/root/pull/8334:271,testability,understand,understand,271,"[ntuple] Add explicit EnableMT methods to RNTupleReader, Writer; Allow users to request multithreaded (de)compression even if IMT is not enabled globally with `ROOT::EnableImplicitMT()`. This required a change to `TTaskGroup` to avoid checking if IMT was enabled -- as I understand it, we can use TBB even if IMT isn't turned on because we don't use `RTaskArena`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334
https://github.com/root-project/root/pull/8334:71,usability,user,users,71,"[ntuple] Add explicit EnableMT methods to RNTupleReader, Writer; Allow users to request multithreaded (de)compression even if IMT is not enabled globally with `ROOT::EnableImplicitMT()`. This required a change to `TTaskGroup` to avoid checking if IMT was enabled -- as I understand it, we can use TBB even if IMT isn't turned on because we don't use `RTaskArena`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334
https://github.com/root-project/root/pull/8335:501,integrability,pub,public,501,Better fix for Windows; See the bug report at Microsoft: [Problem with how the compiler generates covariant virtual functions](https://developercommunity.visualstudio.com/t/Problem-with-how-the-compiler-generates/1441440). And the proposed workaround:. >It turns out to be a problem with how the compiler generates the covariant virtual function `Clone` in `FunctorGradHandler`. To address the issue just use the original return type of the virtual base:. >```. >template. >class FunctorGradHandler : public ParentFunctor::Impl {. >... > typename ParentFunctor::ImplBase* Clone() const { return Copy(); }. >... >};. >```. > This should avoid the need for the compiler to generate the problematic covariant function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8335
https://github.com/root-project/root/pull/8335:636,safety,avoid,avoid,636,Better fix for Windows; See the bug report at Microsoft: [Problem with how the compiler generates covariant virtual functions](https://developercommunity.visualstudio.com/t/Problem-with-how-the-compiler-generates/1441440). And the proposed workaround:. >It turns out to be a problem with how the compiler generates the covariant virtual function `Clone` in `FunctorGradHandler`. To address the issue just use the original return type of the virtual base:. >```. >template. >class FunctorGradHandler : public ParentFunctor::Impl {. >... > typename ParentFunctor::ImplBase* Clone() const { return Copy(); }. >... >};. >```. > This should avoid the need for the compiler to generate the problematic covariant function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8335
https://github.com/root-project/root/pull/8335:154,usability,visual,visualstudio,154,Better fix for Windows; See the bug report at Microsoft: [Problem with how the compiler generates covariant virtual functions](https://developercommunity.visualstudio.com/t/Problem-with-how-the-compiler-generates/1441440). And the proposed workaround:. >It turns out to be a problem with how the compiler generates the covariant virtual function `Clone` in `FunctorGradHandler`. To address the issue just use the original return type of the virtual base:. >```. >template. >class FunctorGradHandler : public ParentFunctor::Impl {. >... > typename ParentFunctor::ImplBase* Clone() const { return Copy(); }. >... >};. >```. > This should avoid the need for the compiler to generate the problematic covariant function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8335
https://github.com/root-project/root/pull/8336:0,deployability,Updat,Update,0,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:21,deployability,version,version,21,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:206,deployability,build,build,206,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:221,deployability,Updat,Update,221,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:21,integrability,version,version,21,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:21,modifiability,version,version,21,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:304,modifiability,pac,packaged,304,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:0,safety,Updat,Update,0,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:221,safety,Updat,Update,221,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:0,security,Updat,Update,0,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:221,security,Updat,Update,221,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8336:7,usability,minim,minimal,7,Update minimal CMake version in favour of advances features it offers; Fixes as well https://github.com/root-project/root/issues/8280. (Thanks a lot to @amadio for pointing out the most reasonable for ROOT build system). Update: sadly we can't move directly to 3.16 because Debian 10 has only cmake 3.13 packaged https://pkgs.org/search/?q=cmake,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8336
https://github.com/root-project/root/pull/8337:176,availability,error,error,176,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:41,deployability,patch,patch,41,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:134,integrability,event,event,134,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:176,performance,error,error,176,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:41,safety,patch,patch,41,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:176,safety,error,error,176,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:41,security,patch,patch,41,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:85,usability,statu,status,85,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8337:176,usability,error,error,176,[DF] Always run CleanUpTask; Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8337
https://github.com/root-project/root/pull/8338:94,availability,error,error,94,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:125,availability,error,error,125,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:192,availability,error,error-,192,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:222,availability,error,error,222,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:94,performance,error,error,94,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:125,performance,error,error,125,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:192,performance,error,error-,192,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:222,performance,error,error,222,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:94,safety,error,error,94,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:125,safety,error,error,125,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:192,safety,error,error-,192,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:222,safety,error,error,222,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:94,usability,error,error,94,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:125,usability,error,error,125,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:159,usability,visual,visualstudio,159,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:192,usability,error,error-,192,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/pull/8338:222,usability,error,error,222,Workaround for MS compiler bug; This is a workaround for the issue reported as [Another fatal error C1001: Internal compiler error](https://developercommunity.visualstudio.com/t/another-fatal-error-c1001-internal-compiler-error/1441527),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8338
https://github.com/root-project/root/issues/8340:35,availability,error,errors,35,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:367,availability,error,error,367,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:451,availability,error,errors,451,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:530,availability,error,errors,530,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:769,availability,error,errors,769,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:797,availability,error,error,797,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:550,deployability,log,logic,550,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:35,performance,error,errors,35,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:367,performance,error,error,367,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:451,performance,error,errors,451,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:530,performance,error,errors,530,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:769,performance,error,errors,769,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:797,performance,error,error,797,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:35,safety,error,errors,35,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:367,safety,error,error,367,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:451,safety,error,errors,451,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:530,safety,error,errors,530,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:550,safety,log,logic,550,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:769,safety,error,errors,769,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:797,safety,error,error,797,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:550,security,log,logic,550,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:550,testability,log,logic,550,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:976,testability,context,context,976,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:1005,testability,context,context,1005,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:35,usability,error,errors,35,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:118,usability,clear,clear,118,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:367,usability,error,error,367,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:451,usability,error,errors,451,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:530,usability,error,errors,530,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:678,usability,clear,clear,678,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:769,usability,error,errors,769,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/issues/8340:797,usability,error,error,797,"TH2PolyBin should be able to store errors; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Here:. https://root.cern.ch/doc/master/TH2Poly_8h_source.html#l00033. The code suggests that we cannot store in these bins neither the bin error nor the sum of the squares of the weights. Thus in order to keep track of the errors we need two TH2Poly instances, one for the values and the other for the errors. What is the logic behind this design? I do not think this makes sense. Can this be changed? . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. Add setters and getters for errors, add members for the error and a member for the sum of squares of weights. . ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8340
https://github.com/root-project/root/pull/8341:24,integrability,messag,message,24,Remove not needed fatal message (fixing #8280); Fixes: #8280. @vgvassilev soon this workaround introduced by you will not be needed (see https://github.com/root-project/root/pull/8336),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8341
https://github.com/root-project/root/pull/8341:24,interoperability,messag,message,24,Remove not needed fatal message (fixing #8280); Fixes: #8280. @vgvassilev soon this workaround introduced by you will not be needed (see https://github.com/root-project/root/pull/8336),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8341
https://github.com/root-project/root/issues/8342:338,security,control,control,338,"Tutorials order in the reference guide; Find a way to better order the tutorials in: https://root.cern/doc/master/group__Tutorials.html. ""Cocoa"" really isn't the main entry point for most users . Very likely they are alphabetically ordered by the group names. Calling the groups with names starting with a number might be the solution to control the order. But that will imply changing the name of the groups. That might be problematic as external pages are already pointing to some tutorials' groups.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8342
https://github.com/root-project/root/issues/8342:338,testability,control,control,338,"Tutorials order in the reference guide; Find a way to better order the tutorials in: https://root.cern/doc/master/group__Tutorials.html. ""Cocoa"" really isn't the main entry point for most users . Very likely they are alphabetically ordered by the group names. Calling the groups with names starting with a number might be the solution to control the order. But that will imply changing the name of the groups. That might be problematic as external pages are already pointing to some tutorials' groups.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8342
https://github.com/root-project/root/issues/8342:33,usability,guid,guide,33,"Tutorials order in the reference guide; Find a way to better order the tutorials in: https://root.cern/doc/master/group__Tutorials.html. ""Cocoa"" really isn't the main entry point for most users . Very likely they are alphabetically ordered by the group names. Calling the groups with names starting with a number might be the solution to control the order. But that will imply changing the name of the groups. That might be problematic as external pages are already pointing to some tutorials' groups.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8342
https://github.com/root-project/root/issues/8342:188,usability,user,users,188,"Tutorials order in the reference guide; Find a way to better order the tutorials in: https://root.cern/doc/master/group__Tutorials.html. ""Cocoa"" really isn't the main entry point for most users . Very likely they are alphabetically ordered by the group names. Calling the groups with names starting with a number might be the solution to control the order. But that will imply changing the name of the groups. That might be problematic as external pages are already pointing to some tutorials' groups.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8342
https://github.com/root-project/root/pull/8343:24,reliability,doe,does,24,External nlohmann::json does not have json_fwd.hpp;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8343
https://github.com/root-project/root/pull/8344:155,safety,test,test,155,"Properly handle UTF-8 coding in TBufferJSON; Suppose by default that string coded as utf-8, providing correct representation in JSON. Adding correspondent test. Solves: #6681",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8344
https://github.com/root-project/root/pull/8344:155,testability,test,test,155,"Properly handle UTF-8 coding in TBufferJSON; Suppose by default that string coded as utf-8, providing correct representation in JSON. Adding correspondent test. Solves: #6681",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8344
https://github.com/root-project/root/pull/8345:74,deployability,instal,installed,74,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:133,deployability,version,version,133,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:306,deployability,version,version,306,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:133,integrability,version,version,133,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:306,integrability,version,version,306,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:37,interoperability,platform,platforms,37,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:133,modifiability,version,version,133,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:306,modifiability,version,version,306,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:0,safety,Test,Test,0,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:0,testability,Test,Test,0,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8345:204,usability,indicat,indicates,204,Test if json_fwd.hpp exists; On some platforms external nlohmann/json.hpp installed without. such special include. In this case full version has to be used. Provide special define when compile EVE7 which indicates if. json_fwd.hpp can be used. In the macros such define is not. exported and therefore full version of nlohmann/json.hpp. will be used. Better solution then https://github.com/root-project/root/pull/8343,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8345
https://github.com/root-project/root/pull/8348:24,integrability,messag,message,24,Remove not needed fatal message (fixing ##8280);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8348
https://github.com/root-project/root/pull/8348:24,interoperability,messag,message,24,Remove not needed fatal message (fixing ##8280);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8348
https://github.com/root-project/root/pull/8349:218,availability,error,error,218,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:83,deployability,patch,patch,83,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:176,integrability,event,event,176,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:218,performance,error,error,218,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:83,safety,patch,patch,83,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:218,safety,error,error,218,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:83,security,patch,patch,83,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:127,usability,statu,status,127,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8349:218,usability,error,error,218,[DF] Use a RAII object to make sure to always run CleanUpTask (v6.24); Before this patch we skipped running CleanUpTask if the status. of the TTreeReader after a single-thread event loop over ROOT data. encountered an error.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8349
https://github.com/root-project/root/pull/8350:13,availability,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:516,deployability,patch,patch,516,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:269,energy efficiency,current,currently,269,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:42,interoperability,mismatch,mismatch,42,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:13,performance,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:13,safety,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:138,safety,input,input,138,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:420,safety,input,input,420,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:516,safety,patch,patch,516,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:525,safety,detect,detect,525,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:546,safety,compl,complain,546,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:516,security,patch,patch,516,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:525,security,detect,detect,525,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:546,security,compl,complain,546,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:395,testability,simpl,simple,395,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:13,usability,error,error,13,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:138,usability,input,input,138,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:395,usability,simpl,simple,395,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8350:420,usability,input,input,420,"[tree] Print error in case of branch kind mismatch in CopyAddresses (v6.24); TTree::CopyAddresses has the built-in pre-condition that the input and. output branches are of the same kind. Clones might be added, however,. for which the pre-condition is violated. This is currently the case,. for example, with certain usages of RDataFrame::Snapshot, which might. create an output branch that is a simple TBranch while the input branch. is e.g. a TBranchElement. This results in wrong data being written out. With this patch we detect this case and complain. A proper fix will be proposed soon. The issue is tracked as #8295.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8350
https://github.com/root-project/root/pull/8351:5,safety,Avoid,Avoid,5,[io] Avoid nullptr deref when printing warning in TStreamerInfo;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8351
https://github.com/root-project/root/pull/8352:152,availability,failur,failures,152,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:70,deployability,upgrad,upgrade,70,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:117,deployability,log,logic,117,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:152,deployability,fail,failures,152,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:70,modifiability,upgrad,upgrade,70,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:152,performance,failur,failures,152,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:152,reliability,fail,failures,152,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:117,safety,log,logic,117,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:117,security,log,logic,117,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:117,testability,log,logic,117,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8352:220,usability,help,help,220,"[DF] Add RJittedAction to LinkDef file (v6.24); After the latest LLVM upgrade, changes in cling's symbol resolution. logic cause some unresolved symbol failures in RDF jitting. Adding RJittedAction to the rootmap should help cling autoloading. and work around the problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8352
https://github.com/root-project/root/pull/8353:291,deployability,patch,patch,291,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:253,reliability,doe,does,253,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:291,safety,patch,patch,291,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:291,security,patch,patch,291,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:19,usability,help,helper,19,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:76,usability,support,support,76,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:149,usability,help,helper,149,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:184,usability,Help,Helper,184,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8353:378,usability,help,helper,378,"[DF] Fix Book with helper that takes no columns ; Recent changes that added support for jitted Book actions broke the. edge case in which the action helper takes no columns:. `df.Book(Helper{}, {})` now means ""jit this action"" rather than ""this. action does not take any columns"". With this patch, we resolve this ambiguity at runtime by looking at. the list of column names. A helper type is used to make sure that. compilation is fine in all cases. cc: @bendavid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8353
https://github.com/root-project/root/pull/8354:269,integrability,abstract,abstract,269,Fix bug in [R/T]EveRefCnt::OnZeroRefCount() method; One cannot simply call `delete this` in base class - . especially when derived class uses multiple inheritance. Therefore provide OnZeroRefCount implementation in all derived classes. In REve also mark this method as abstract to ensure that such problem. not appear in the future,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8354
https://github.com/root-project/root/pull/8354:151,modifiability,inherit,inheritance,151,Fix bug in [R/T]EveRefCnt::OnZeroRefCount() method; One cannot simply call `delete this` in base class - . especially when derived class uses multiple inheritance. Therefore provide OnZeroRefCount implementation in all derived classes. In REve also mark this method as abstract to ensure that such problem. not appear in the future,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8354
https://github.com/root-project/root/pull/8354:269,modifiability,abstract,abstract,269,Fix bug in [R/T]EveRefCnt::OnZeroRefCount() method; One cannot simply call `delete this` in base class - . especially when derived class uses multiple inheritance. Therefore provide OnZeroRefCount implementation in all derived classes. In REve also mark this method as abstract to ensure that such problem. not appear in the future,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8354
https://github.com/root-project/root/pull/8354:63,testability,simpl,simply,63,Fix bug in [R/T]EveRefCnt::OnZeroRefCount() method; One cannot simply call `delete this` in base class - . especially when derived class uses multiple inheritance. Therefore provide OnZeroRefCount implementation in all derived classes. In REve also mark this method as abstract to ensure that such problem. not appear in the future,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8354
https://github.com/root-project/root/pull/8354:63,usability,simpl,simply,63,Fix bug in [R/T]EveRefCnt::OnZeroRefCount() method; One cannot simply call `delete this` in base class - . especially when derived class uses multiple inheritance. Therefore provide OnZeroRefCount implementation in all derived classes. In REve also mark this method as abstract to ensure that such problem. not appear in the future,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8354
https://github.com/root-project/root/issues/8357:168,availability,avail,available,168,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:142,deployability,patch,patch,142,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:254,deployability,patch,patch,254,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:8,energy efficiency,core,corefonts,8,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:48,energy efficiency,core,corefonts,48,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:120,energy efficiency,core,corefonts,120,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:168,reliability,availab,available,168,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:78,safety,compl,completely,78,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:142,safety,patch,patch,142,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:168,safety,avail,available,168,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:254,safety,patch,patch,254,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:78,security,compl,completely,78,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:142,security,patch,patch,142,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:168,security,availab,available,168,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/issues/8357:254,security,patch,patch,254,"make MS corefonts optional; With the bundled MS corefonts, root license isn't completely free. What I ask is to make MS corefonts optional. A patch from Fedora is also available here https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357
https://github.com/root-project/root/pull/8358:63,interoperability,format,format,63,[asimage] Port to Win64 (replace Long_t by Longptr_t + pointer format…; …ting),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8358
https://github.com/root-project/root/issues/8360:196,integrability,sub,subclasses,196,"[ntuple] Move common performance counters to `RPage{Sink,Source}` base class; ### Explain what you would like to see improved. Some performance counters are expected to be common among different. subclasses of `RPage{Sink,Source}`. These should be handled by the base. class instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8360
https://github.com/root-project/root/issues/8360:21,performance,perform,performance,21,"[ntuple] Move common performance counters to `RPage{Sink,Source}` base class; ### Explain what you would like to see improved. Some performance counters are expected to be common among different. subclasses of `RPage{Sink,Source}`. These should be handled by the base. class instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8360
https://github.com/root-project/root/issues/8360:132,performance,perform,performance,132,"[ntuple] Move common performance counters to `RPage{Sink,Source}` base class; ### Explain what you would like to see improved. Some performance counters are expected to be common among different. subclasses of `RPage{Sink,Source}`. These should be handled by the base. class instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8360
https://github.com/root-project/root/issues/8360:21,usability,perform,performance,21,"[ntuple] Move common performance counters to `RPage{Sink,Source}` base class; ### Explain what you would like to see improved. Some performance counters are expected to be common among different. subclasses of `RPage{Sink,Source}`. These should be handled by the base. class instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8360
https://github.com/root-project/root/issues/8360:132,usability,perform,performance,132,"[ntuple] Move common performance counters to `RPage{Sink,Source}` base class; ### Explain what you would like to see improved. Some performance counters are expected to be common among different. subclasses of `RPage{Sink,Source}`. These should be handled by the base. class instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8360
https://github.com/root-project/root/issues/8361:409,availability,avail,available,409,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:383,deployability,continu,continue,383,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:206,interoperability,format,format,206,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:333,interoperability,platform,platform-independent,333,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:550,interoperability,share,share,550,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:187,performance,content,contents-in-a-tree-format,187,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:409,reliability,availab,available,409,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:409,safety,avail,available,409,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:409,security,availab,available,409,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:363,usability,interact,interaction,363,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/issues/8361:432,usability,command,command,432,"`rootls` improvements; ### Explain what you would like to see improved. We have [a proposal for an improved `rootls`](https://root-forum.cern.ch/t/terminal-program-for-printing-root-file-contents-in-a-tree-format/44185/12. ). After discussion we decided to implement missing features in `rootls` - for instance to keep it in Python (platform-independent terminal interaction) and to continue to make the code available to the other command line utilities. In our usage of `rootls`, what's missing? Let's collect this in comments below. ### Optional: share how it could be improved. See comments below. ### To Reproduce. See comments below. ### Setup. ROOT master, please - there are some +/- recent changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8361
https://github.com/root-project/root/pull/8362:95,deployability,updat,updateNormVars,95,[RF] Set plot norm variables in RooAbsPdf::plotOn before using them; The first call to `frame->updateNormVars(*frame->getPlotVar())` should. be made before the first call to `frame->getNormVars()` in the. `RooAbsPdf::plotOn` function. This fixes the Jira issue [ROOT-5529](https://sft.its.cern.ch/jira/browse/ROOT-5529).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8362
https://github.com/root-project/root/pull/8362:19,modifiability,variab,variables,19,[RF] Set plot norm variables in RooAbsPdf::plotOn before using them; The first call to `frame->updateNormVars(*frame->getPlotVar())` should. be made before the first call to `frame->getNormVars()` in the. `RooAbsPdf::plotOn` function. This fixes the Jira issue [ROOT-5529](https://sft.its.cern.ch/jira/browse/ROOT-5529).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8362
https://github.com/root-project/root/pull/8362:95,safety,updat,updateNormVars,95,[RF] Set plot norm variables in RooAbsPdf::plotOn before using them; The first call to `frame->updateNormVars(*frame->getPlotVar())` should. be made before the first call to `frame->getNormVars()` in the. `RooAbsPdf::plotOn` function. This fixes the Jira issue [ROOT-5529](https://sft.its.cern.ch/jira/browse/ROOT-5529).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8362
https://github.com/root-project/root/pull/8362:95,security,updat,updateNormVars,95,[RF] Set plot norm variables in RooAbsPdf::plotOn before using them; The first call to `frame->updateNormVars(*frame->getPlotVar())` should. be made before the first call to `frame->getNormVars()` in the. `RooAbsPdf::plotOn` function. This fixes the Jira issue [ROOT-5529](https://sft.its.cern.ch/jira/browse/ROOT-5529).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8362
https://github.com/root-project/root/pull/8364:76,availability,down,downsteam,76,"[RF] Handle nullptr or empty norm set ambiguity in RooAbsReal::getVal ; The downsteam code, -- like RooAddPdf::getValV for example -- assume. that a nullptr is passed when no normalization is requested. The case of. an empty norm set is not handled correctly in RooAddPdf::getValV,. leading to wrong results. However, some calling code passes an empty norm set to. RooAbsReal::getVal instead of a `nullptr` in an attempt to disable. normalization. This commit suggests to solve this ambiguity at the highest possible. level: right at the beginning of RooAbsReal::getVal. If the. normalization set is empty, the pointer pointing to it will be set to. `nullptr`. This fixes issue #8307. To give some context: the code in RooAddPdf that doesn't handle the ambiguity correctly was introduced in f6d1543, which was also backported to 6.24. Hence, a backport to 6.24 is necessary also for this PR. The backport PR to 6.24 is https://github.com/root-project/root/pull/8372, which first go included in 6.24.02",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8364
https://github.com/root-project/root/pull/8364:734,reliability,doe,doesn,734,"[RF] Handle nullptr or empty norm set ambiguity in RooAbsReal::getVal ; The downsteam code, -- like RooAddPdf::getValV for example -- assume. that a nullptr is passed when no normalization is requested. The case of. an empty norm set is not handled correctly in RooAddPdf::getValV,. leading to wrong results. However, some calling code passes an empty norm set to. RooAbsReal::getVal instead of a `nullptr` in an attempt to disable. normalization. This commit suggests to solve this ambiguity at the highest possible. level: right at the beginning of RooAbsReal::getVal. If the. normalization set is empty, the pointer pointing to it will be set to. `nullptr`. This fixes issue #8307. To give some context: the code in RooAddPdf that doesn't handle the ambiguity correctly was introduced in f6d1543, which was also backported to 6.24. Hence, a backport to 6.24 is necessary also for this PR. The backport PR to 6.24 is https://github.com/root-project/root/pull/8372, which first go included in 6.24.02",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8364
https://github.com/root-project/root/pull/8364:698,testability,context,context,698,"[RF] Handle nullptr or empty norm set ambiguity in RooAbsReal::getVal ; The downsteam code, -- like RooAddPdf::getValV for example -- assume. that a nullptr is passed when no normalization is requested. The case of. an empty norm set is not handled correctly in RooAddPdf::getValV,. leading to wrong results. However, some calling code passes an empty norm set to. RooAbsReal::getVal instead of a `nullptr` in an attempt to disable. normalization. This commit suggests to solve this ambiguity at the highest possible. level: right at the beginning of RooAbsReal::getVal. If the. normalization set is empty, the pointer pointing to it will be set to. `nullptr`. This fixes issue #8307. To give some context: the code in RooAddPdf that doesn't handle the ambiguity correctly was introduced in f6d1543, which was also backported to 6.24. Hence, a backport to 6.24 is necessary also for this PR. The backport PR to 6.24 is https://github.com/root-project/root/pull/8372, which first go included in 6.24.02",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8364
https://github.com/root-project/root/issues/8365:3005,availability,operat,operator,3005,"-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:4537,availability,operat,operator,4537,"lection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5889,availability,Down,Download,5889,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5396,deployability,log,log,5396,"lingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6010,deployability,build,build,6010,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6022,deployability,build,build,6022,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6050,deployability,build,build-debug-mode-ROOT,6050,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6230,deployability,log,log-file,6230,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6248,deployability,log,log,6248,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:4528,energy efficiency,alloc,alloc,4528,"). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:1148,interoperability,conflict,conflicts,1148,"rted by helgrind, and I also see sometimes dead-locks, see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XAReques",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2409,interoperability,conflict,conflicts,2409,"ection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:3338,interoperability,conflict,conflicts,3338,"ARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5434,interoperability,xml,xml,5434,"Value*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5463,interoperability,xml,xml,5463,"102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-pr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5532,interoperability,xml,xml,5532,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5559,interoperability,XML,XML,5559,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6125,interoperability,xml,xml,6125,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6135,interoperability,xml,xml-file,6135,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6153,interoperability,xml,xml,6153,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:201,performance,lock,locks,201,"Data races TThread TTimer TApplication; - [x] Checked for duplicates. ### Describe the bug. I encounter some data races when using TThread. They are reported by helgrind, and I also see sometimes dead-locks, see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:283,performance,lock,lock-program-freezes,283,"Data races TThread TTimer TApplication; - [x] Checked for duplicates. ### Describe the bug. I encounter some data races when using TThread. They are reported by helgrind, and I also see sometimes dead-locks, see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:1204,performance,Lock,Locks,1204," see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2137,performance,time,time,2137,"7). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2822,performance,Lock,Locks,2822,"ead::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:3394,performance,Lock,Locks,3394,"1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:3851,performance,Lock,Locks,3851,"9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6408,performance,lock,lock-program-freezes,6408,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5396,safety,log,log,5396,"lingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6230,safety,log,log-file,6230,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6248,safety,log,log,6248,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:201,security,lock,locks,201,"Data races TThread TTimer TApplication; - [x] Checked for duplicates. ### Describe the bug. I encounter some data races when using TThread. They are reported by helgrind, and I also see sometimes dead-locks, see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:283,security,lock,lock-program-freezes,283,"Data races TThread TTimer TApplication; - [x] Checked for duplicates. ### Describe the bug. I encounter some data races when using TThread. They are reported by helgrind, and I also see sometimes dead-locks, see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:1204,security,Lock,Locks,1204," see full discussion on https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. 0). ```. at 0x5201F09: TOrdCollection::PhysIndex(int) const (TOrdCollection.h:135). by 0x5200D7E: TOrdCollection::IndexOf(TObject const*) const (TOrdCollection.cxx:258). by 0x5201355: TOrdCollection::Remove(TObject*) (TOrdCollection.cxx:369). by 0x519E6E4: TSystem::RemoveTimer(TTimer*) (TSystem.cxx:486). by 0x52CDD63: TUnixSystem::RemoveTimer(TTimer*) (TUnixSystem.cxx:2987). by 0x51B4903: TTimer::TurnOff() (TTimer.cxx:232). by 0x1C9E0029: ??? by 0x8D6D5A9: TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). by 0x8D6E882: TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). by 0x8C164CB: TCling::CallFunc_Exec(CallFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2076,security,access,accessed,2076,"B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2822,security,Lock,Locks,2822,"ead::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:3394,security,Lock,Locks,3394,"1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:3851,security,Lock,Locks,3851,"9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). ```. 4). ```. Possible data race during write of size 8 at 0x1B96F790 by thread #3. Locks held: none. TOrdCollection::MoveGapTo(int) (TOrdCollection.cxx:309). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:78). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TTimer::Start(long, bool) (TTimer.cxx:216). MainWindow::SaveAndExit() (MainWindow.cpp:1216). ??? TClingCallFunc::exec(void*, void*) (TClingCallFunc.cxx:1843). TClingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5396,security,log,log,5396,"lingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6230,security,log,log-file,6230,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6248,security,log,log,6248,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6408,security,lock,lock-program-freezes,6408,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5396,testability,log,log,5396,"lingCallFunc::Exec(void*, TInterpreterValue*) (TClingCallFunc.cxx:2102). Address 0x1b96f790 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6230,testability,log,log-file,6230,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6248,testability,log,log,6248,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6347,testability,context,context,6347,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:1957,usability,user,user-images,1957,"allFunc_t*, void*) const (TCling.cxx:7788). by 0x517DC35: TQConnection::SendSignal() (TQConnection.h:76). by 0x487CC2B: void TQObject::EmitVA<>(char const*, int) (TQObject.h:137). This conflicts with a previous write of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2174,usability,user,user-images,2174,"of size 4 by thread #3. Locks held: 1, at address 0x167C9B50. at 0x52005E4: TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:70). by 0x5200785: TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). by 0x5201C2D: TSeqCollection::Add(TObject*) (TSeqCollection.h:38). by 0x519E68B: TSystem::AddTimer(TTimer*) (TSystem.cxx:476). by 0x52CDC32: TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2536,usability,user,user-images,2536,"em::AddTimer(TTimer*) (TUnixSystem.cxx:2974). by 0x64AC1E3: TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqColl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:2649,usability,user,user-images,2649,"by 0x64AB943: TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). by 0x64AB448: TThread::Printf(char const*, ...) (TThread.cxx:950). ```. 1). ```. TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1058). TThreadTimer::Notify() (TThread.cxx:1208). ```. ![image](https://user-images.githubusercontent.com/10653970/121098991-0584b500-c7c5-11eb-8a4a-2c07f74d1486.png). --> TThread::fgXact is accessed unprotected, it could have been changed at the same time by XARequest:. ![image](https://user-images.githubusercontent.com/10653970/121099097-3664ea00-c7c5-11eb-86e7-41daed97a959.png). 2). ```. TApplication::IsRunning() const (TApplication.h:148). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1029). This conflicts with a previous write of size 1 by thread #1. TApplication::Run(bool) (TApplication.cxx:1622). ```. ![image](https://user-images.githubusercontent.com/10653970/121100197-4f6e9a80-c7c7-11eb-883b-0f7aec2059d2.png). ![image](https://user-images.githubusercontent.com/10653970/121100214-58f80280-c7c7-11eb-80b8-cdbc68dd1efe.png). 3). ```. Possible data race during read of size 4 at 0x7F25098 by thread #3. Locks held: 1, at address 0x167C9B50. TCollection::GetSize() const (TCollection.h:182). TOrdCollectionIter::Next() (TOrdCollection.cxx:506). TIter::Next() (TCollection.h:249). TIter::operator()() (TCollection.h:248). TCollection::FindObject(TObject const*) const (TCollection.cxx:342). TSystem::AddTimer(TTimer*) (TSystem.cxx:475). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TThreadTimer::TThreadTimer(long) (TThread.cxx:1200). TThread::XARequest(char const*, int, void**, int*) (TThread.cxx:1037). This conflicts with a previous write of size 4 by thread #1. Locks held: none. TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:85). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5623,usability,user,user-images,5623,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:5732,usability,behavi,behavior,5732,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/issues/8365:6159,usability,tool,tool,6159,"90 is 64 bytes inside a block of size 72 alloc'd. operator new[](unsigned long) (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_helgrind-amd64-linux.so). TStorage::ReAlloc(void*, unsigned long, unsigned long) (TStorage.cxx:238). TOrdCollection::SetCapacity(int) (TOrdCollection.cxx:387). TOrdCollection::AddAt(TObject*, int) (TOrdCollection.cxx:66). TOrdCollection::AddLast(TObject*) (TOrdCollection.cxx:102). TSeqCollection::Add(TObject*) (TSeqCollection.h:38). TSystem::AddTimer(TTimer*) (TSystem.cxx:476). TUnixSystem::AddTimer(TTimer*) (TUnixSystem.cxx:2974). TTimer::TurnOn() (TTimer.cxx:247). TGCommandPlugin::TGCommandPlugin(TGWindow const*, unsigned int, unsigned int) (TGCommandPlugin.cxx:110). MainWindow::MainWindow(TGWindow const*, unsigned int, unsigned int, PulseSurfer*, unsigned int, unsigned int, bool) (MainWindow.cpp:616). main (main.cxx:86). ```. and several more can be seen in helgrind.log in the forum post, or in helgrind.xml attached here. [helgrind.xml.zip](https://github.com/root-project/root/files/6612569/helgrind.xml.zip). When opening the XML with QtCreator, they are rendered nicely:. ![image](https://user-images.githubusercontent.com/10653970/121102408-7e870b00-c7cb-11eb-8436-816dd434bdf3.png). ### Expected behavior. No data races are found. Or they are added to helgrind-root.supp. ### To Reproduce. 0. cd /opt/ && git clone https://github.com/CLIUtils/CLI11. 1. Download https://root-forum.cern.ch/uploads/short-url/z59x8uBIVMEE5S46EWUUHyyO3df.zip and unzip it, cd into it. 2. mkdir build && cd build. 3. cmake -DROOT_DIR=/build-debug-mode-ROOT -DCMAKE_BUILD_TYPE=Debug ../. 4. make. 5. valgrind --xml=yes --xml-file=helgrind.xml --tool=helgrind --suppressions=/pathtoDebugROOT/etc/helgrind-root.supp --log-file=helgrind.log gui/runGUI --prbs 3 -q. ### Setup. 1. ROOT master. 2. Ubuntu 18. 3. Self-built. ### Additional context. https://root-forum.cern.ch/t/trentrantrwlock-thread-lock-program-freezes/45116/14. https://github.com/root-project/root/issues/8297",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8365
https://github.com/root-project/root/pull/8366:49,availability,failur,failure,49,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:868,availability,Error,Error,868,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:973,availability,error,error,973,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:49,deployability,fail,failure,49,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:156,deployability,Fail,Failed,156,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:185,deployability,build,builddir,185,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:194,deployability,build,build,194,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:200,deployability,BUILD,BUILD,200,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:878,deployability,build,builddir,878,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:887,deployability,build,build,887,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:893,deployability,BUILD,BUILD,893,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:526,energy efficiency,load,load,526,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:823,energy efficiency,load,load,823,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:388,integrability,interfac,interface,388,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:694,integrability,interfac,interface,694,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:962,integrability,messag,message,962,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:388,interoperability,interfac,interface,388,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:549,interoperability,share,shared,549,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:694,interoperability,interfac,interface,694,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:846,interoperability,share,shared,846,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:962,interoperability,messag,message,962,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:388,modifiability,interfac,interface,388,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:694,modifiability,interfac,interface,694,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:49,performance,failur,failure,49,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:526,performance,load,load,526,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:823,performance,load,load,823,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:868,performance,Error,Error,868,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:973,performance,error,error,973,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:49,reliability,fail,failure,49,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:156,reliability,Fail,Failed,156,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:44,safety,test,test,44,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:73,safety,Test,Test,73,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:868,safety,Error,Error,868,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:973,safety,error,error,973,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:44,testability,test,test,44,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:73,testability,Test,Test,73,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:868,usability,Error,Error,868,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/pull/8366:973,usability,error,error,973,Add TTreeProcessorMP to LinkDef; This fixes test failure:. ```. 745/1157 Test #729: tutorial-multicore-mp102_readNtuplesFillHistosAndFit ................***Failed 1.55 sec. Processing /builddir/build/BUILD/root-6.25.01/tutorials/multicore/mp102_readNtuplesFillHistosAndFit.C... IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMPC1Ej' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::TTreeProcessorMP(unsigned int). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZN4ROOT16TTreeProcessorMP11ReplyToIdleEP7TSocket' unresolved while linking [cling interface function]! You are probably missing the definition of ROOT::TTreeProcessorMP::ReplyToIdle(TSocket*). Maybe you need to load the corresponding shared library? CMake Error at /builddir/build/BUILD/root-6.25.01/x86_64-redhat-linux-gnu/RootTestDriver.cmake:237 (message):. error code: 1. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8366
https://github.com/root-project/root/issues/8367:60,availability,error,errors,60,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6089,availability,Operat,Operating,6089,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6154,availability,down,download,6154,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:228,deployability,stack,stack,228,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:778,deployability,Stack,StackTrace,778,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6069,deployability,version,version,6069,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:548,energy efficiency,optim,optimized,548,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:690,energy efficiency,optim,optimized,690,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:3831,energy efficiency,alloc,allocator,3831,"Decl) () from /home/sakib/root/lib/libCling.so. #17 0x00007ff62bca1c07 in clang::CodeGen::CodeGenModule::EmitTopLevelDecl(clang::Decl*) [clone .part.0] () from /home/sakib/root/lib/libCling.so. #18 0x00007ff62bba7b11 in clang::CodeGeneratorImpl::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #19 0x00007ff62c02d764 in clang::MultiplexConsumer::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #20 0x00007ff62bb0d6be in cling::DeclCollector::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #21 0x00007ff62bacb731 in cling::IncrementalParser::ParseInternal(llvm::StringRef) () from /home/sakib/root/lib/libCling.so. #22 0x00007ff62bacc451 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/sakib/root/lib/libCling.so. #23 0x00007ff62ba2eaef in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/sakib/root/lib/libCling.so. #24 0x00007ff62ba2ef4a in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/sakib/root/lib/libCling.so. #25 0x00007ff62bb1c06c in cling::MetaProcessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:4094,energy efficiency,alloc,allocator,4094,"l(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #19 0x00007ff62c02d764 in clang::MultiplexConsumer::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #20 0x00007ff62bb0d6be in cling::DeclCollector::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #21 0x00007ff62bacb731 in cling::IncrementalParser::ParseInternal(llvm::StringRef) () from /home/sakib/root/lib/libCling.so. #22 0x00007ff62bacc451 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/sakib/root/lib/libCling.so. #23 0x00007ff62ba2eaef in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/sakib/root/lib/libCling.so. #24 0x00007ff62ba2ef4a in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/sakib/root/lib/libCling.so. #25 0x00007ff62bb1c06c in cling::MetaProcessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6012,energy efficiency,Draw,Draw,6012,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6069,integrability,version,version,6069,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:1023,modifiability,Scal,ScalarExprEmitter,1023,"tion in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clang::CompoundStmt const&, bool, cl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:1157,modifiability,Scal,ScalarExprEmitter,1157,"======================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clang::CompoundStmt const&, bool, clang::CodeGen::AggValueSlot) () from /home/sakib/root/lib/libCling.so. #12 0x00007ff62bc4c93e in clang::CodeGen::CodeGenFunction::EmitF",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:1176,modifiability,Scal,ScalarConversionOpts,1176,"==. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clang::CompoundStmt const&, bool, clang::CodeGen::AggValueSlot) () from /home/sakib/root/lib/libCling.so. #12 0x00007ff62bc4c93e in clang::CodeGen::CodeGenFunction::EmitFunctionBody(clang::S",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6069,modifiability,version,version,6069,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:60,performance,error,errors,60,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:548,performance,optimiz,optimized,548,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:690,performance,optimiz,optimized,690,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:3197,performance,Multiplex,MultiplexConsumer,3197,"/home/sakib/root/lib/libCling.so. #13 0x00007ff62bc55fde in clang::CodeGen::CodeGenFunction::GenerateCode(clang::GlobalDecl, llvm::Function*, clang::CodeGen::CGFunctionInfo const&) () from /home/sakib/root/lib/libCling.so. #14 0x00007ff62bc9ec3a in clang::CodeGen::CodeGenModule::EmitGlobalFunctionDefinition(clang::GlobalDecl, llvm::GlobalValue*) () from /home/sakib/root/lib/libCling.so. #15 0x00007ff62bc9c685 in clang::CodeGen::CodeGenModule::EmitGlobalDefinition(clang::GlobalDecl, llvm::GlobalValue*) () from /home/sakib/root/lib/libCling.so. #16 0x00007ff62bc9cb73 in clang::CodeGen::CodeGenModule::EmitGlobal(clang::GlobalDecl) () from /home/sakib/root/lib/libCling.so. #17 0x00007ff62bca1c07 in clang::CodeGen::CodeGenModule::EmitTopLevelDecl(clang::Decl*) [clone .part.0] () from /home/sakib/root/lib/libCling.so. #18 0x00007ff62bba7b11 in clang::CodeGeneratorImpl::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #19 0x00007ff62c02d764 in clang::MultiplexConsumer::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #20 0x00007ff62bb0d6be in cling::DeclCollector::HandleTopLevelDecl(clang::DeclGroupRef) () from /home/sakib/root/lib/libCling.so. #21 0x00007ff62bacb731 in cling::IncrementalParser::ParseInternal(llvm::StringRef) () from /home/sakib/root/lib/libCling.so. #22 0x00007ff62bacc451 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/sakib/root/lib/libCling.so. #23 0x00007ff62ba2eaef in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/sakib/root/lib/libCling.so. #24 0x00007ff62ba2ef4a in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/sakib/root/lib/libCling.so. #",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:60,safety,error,errors,60,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:951,security,sign,signal,951,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:234,testability,trace,trace,234,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6180,testability,context,context,6180,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:6209,testability,context,context,6209,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:60,usability,error,errors,60,"*** Break *** segmentation violation in case of compilation errors in unnamed macros; ```. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007ff62fe1bdba in __GI___wait4 (pid=227643, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:27. #1 0x00007ff62fe1bd7b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffe314e7e68, options=options. entry=0) at waitpid.c:38. #2 0x00007ff62fd8b0e7 in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:172. #3 0x00007ff630445bfe in TUnixSystem::StackTrace() () from /home/sakib/root/lib/libCore.so.6.24. #4 0x00007ff630442a85 in TUnixSystem::DispatchSignals(ESignals) () from /home/sakib/root/lib/libCore.so.6.24. #5 <signal handler called>. #6 0x00007ff62be79d78 in (anonymous namespace)::ScalarExprEmitter::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation, (anonymous namespace)::ScalarExprEmitter::ScalarConversionOpts) () from /home/sakib/root/lib/libCling.so. #7 0x00007ff62be7c77b in clang::CodeGen::CodeGenFunction::EmitScalarConversion(llvm::Value*, clang::QualType, clang::QualType, clang::SourceLocation) () from /home/sakib/root/lib/libCling.so. #8 0x00007ff62be2dfcf in clang::CodeGen::CodeGenFunction::EvaluateExprAsBool(clang::Expr const*) () from /home/sakib/root/lib/libCling.so. #9 0x00007ff62bc077f5 in clang::CodeGen::CodeGenFunction::EmitForStmt(clang::ForStmt const&, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #10 0x00007ff62bc05848 in clang::CodeGen::CodeGenFunction::EmitStmt(clang::Stmt const*, llvm::ArrayRef<clang::Attr const*>) () from /home/sakib/root/lib/libCling.so. #11 0x00007ff62bc05979 in clang::CodeGen::CodeGenFunction::EmitCompoundStmtWithoutScope(clan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:5749,usability,behavi,behavior,5749,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:5767,usability,clear,clear,5767,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/issues/8367:5875,usability,behavi,behavior,5875,"cessor::readInputFromFile(llvm::StringRef, cling::Value*, unsigned long, bool) () from /home/sakib/root/lib/libCling.so. #26 0x00007ff62b940b4e in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #27 0x00007ff62b9417da in TCling::ProcessLineSynch(char const*, TInterpreter::EErrorCode*) () from /home/sakib/root/lib/libCling.so. #28 0x00007ff6302ed70a in TApplication::ExecuteFile(char const*, int*, bool) () from /home/sakib/root/lib/libCore.so.6.24. #29 0x00007ff6302ee443 in TApplication::ProcessLine(char const*, bool, int*) () from /home/sakib/root/lib/libCore.so.6.24. #30 0x00007ff630666166 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/sakib/root/lib/libRint.so.6.24. #31 0x00007ff63066656a in TRint::HandleTermInput() () from /home/sakib/root/lib/libRint.so.6.24. #32 0x00007ff630441b62 in TUnixSystem::CheckDescriptors() () from /home/sakib/root/lib/libCore.so.6.24. #33 0x00007ff630443828 in TUnixSystem::DispatchOneEvent(bool) () from /home/sakib/root/lib/libCore.so.6.24. #34 0x00007ff630353669 in TSystem::Run() () from /home/sakib/root/lib/libCore.so.6.24. #35 0x00007ff6302eb443 in TApplication::Run(bool) () from /home/sakib/root/lib/libCore.so.6.24. #36 0x00007ff630667c0e in TRint::Run(bool) () from /home/sakib/root/lib/libRint.so.6.24. #37 0x000055b5825ea180 in main (). ===========================================================. ```. ### Describe the bug. tried to execute a code, crashes. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Steps to reproduce the behavior:. 1. . ```. {. g = new TGraph();. . for(i=0; i<12; i++) {. g->SetPoint(i, i, i*i + 4*i + 7);. }. . g->SetMarkerStyle(49);. . g->Draw(""ALP"");. }. ```. 2. .x graph2.C. ### Setup. 1. ROOT version 6.24.00. 2. Operating system ubuntu 20.04. 3. How you obtained ROOT-> binary download . ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8367
https://github.com/root-project/root/pull/8368:365,availability,ERROR,ERROR,365,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:756,availability,error,error,756,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1085,energy efficiency,alloc,allocator,1085,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1072,integrability,Event,Event,1072,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1101,integrability,Event,Event,1101,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1288,integrability,event,event,1288,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1716,integrability,Event,Event,1716,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1791,integrability,Event,Event,1791,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:840,interoperability,Architectur,Architectures,840,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1180,interoperability,Architectur,Architectures,1180,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1591,interoperability,Architectur,Architectures,1591,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1649,interoperability,Architectur,Architectures,1649,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:1384,modifiability,Variab,VariableTransformBase,1384,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
https://github.com/root-project/root/pull/8368:365,performance,ERROR,ERROR,365,"Fix 'this' pointer is null warnings; ```. .../roofit/roofitcore/src/RooDataHist.cxx: In member function 'void RooDataHist::_adjustBinning(RooRealVar&, const TAxis&, RooRealVar*, Int_t*)':. .../roofit/roofitcore/src/RooDataHist.cxx:595:122: warning: 'this' pointer is null [-Wnonnull]. 595 | coutE(InputArguments) << ""RooDataHist::adjustBinning("" << GetName() << "") ERROR: dimension "" << ourVar->GetName() << "" must be real"" << endl ;. | ^~~~~~~~~~~~~~~. .../roofit/roofitcore/src/RooRealSumFunc.cxx: In constructor 'RooRealSumFunc::RooRealSumFunc(const char*, const char*, const RooArgList&, const RooArgList&)':. .../roofit/roofitcore/src/RooRealSumFunc.cxx:156:35: warning: 'this' pointer is null [-Wnonnull]. 156 | << "" is not of type RooAbsReal, fatal error"" << endl;. | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx: In member function 'void TMVA::DNN::TDataLoader<AData, TMVA::DNN::TReference<AReal> >::CopyInput(TMatrixT<AReal>&, TMVA::DNN::IndexIterator_t) [with AData = std::tuple<const std::vector<TMVA::Event*, std::allocator<TMVA::Event*> >&, const TMVA::DataSetInfo&>; AReal = float]':. .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:131:34: warning: 'this' pointer is null [-Wnonnull]. 131 | Int_t n = event->GetNVariables();. | ~~~~~~~~~~~~~~~~~~~~^~. In file included from .../tmva/tmva/inc/TMVA/VariableTransformBase.h:48,. from .../tmva/tmva/inc/TMVA/Tools.h:58,. from .../tmva/tmva/inc/TMVA/DNN/GeneralLayer.h:36,. from .../tmva/tmva/inc/TMVA/DNN/CNN/ConvLayer.h:32,. from .../tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:24,. from .../tmva/tmva/src/DNN/Architectures/Reference/DataLoader.cxx:17:. .../tmva/tmva/inc/TMVA/Event.h:88:16: note: in a call to non-static member function 'UInt_t TMVA::Event::GetNVariables() const'. 88 | UInt_t GetNVariables() const;. | ^~~~~~~~~~~~~. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8368
