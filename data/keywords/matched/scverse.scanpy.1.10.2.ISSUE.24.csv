id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2144:1402,security,network,networkx,1402,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:1016,testability,depend,dependencies,1016,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:126,usability,confirm,confirmed,126,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:209,usability,confirm,confirmed,209,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:480,usability,Minim,Minimal,480,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:670,usability,error,error,670,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:1352,usability,learn,learn,1352,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:1462,usability,learn,learn,1462,"Development install via conda does not work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:. https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install beni. beni pyproject.toml > environment.yml. conda env create -f environment.yml. ```. this is the error I get. ```. Collecting package metadata (repodata.json): done. Solving environment: failed. ResolvePackageNotFound:. - seaborn-split. ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni? <details>. ```. channels:. - conda-forge. dependencies:. - pip:. - flit. - bbknn. - scanpydoc>=0.7.4. - harmonypy. - magic-impute>=2.0. - cudf>=0.9. - cuml>=0.9. - cugraph>=0.9. - scanorama. - scrublet. - python>=3.7. - pip. - anndata>=0.7.4. - numpy>=1.17.0. - matplotlib-base>=3.1.2. - pandas>=0.21. - scipy>=1.4. - seaborn-split. - h5py>=2.10.0. - pytables. - tqdm. - scikit-learn>=0.22. - statsmodels>=0.10.0rc2. - patsy. - networkx>=2.3. - natsort. - joblib. - numba>=0.41.0. - umap-learn>=0.3.10. - packaging. - sinfo. - setuptools-scm. - black>=20.8b1. - docutils. - sphinx<4.2,>=4.1. - sphinx_rtd_theme>=0.3.1. - python-igraph. - leidenalg. - louvain!=0.6.2,>=0.6. - scikit-misc>=0.1.3. - pytest>=4.4. - pytest-nunit. - dask-core!=2.17.0. - fsspec. - zappy. - - zarr. - profimp. - flit-core. name: scanpy. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/pull/2145:2539,availability,cluster,cluster,2539,". 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24. 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17. 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11. 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11. 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09. ```. This also extends to enrichment queries (this is what I wanted originally):. ```python. sc.queries.enrich(adata, ""1"", n_top_genes=10). ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:302,deployability,log,logfc,302,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:696,deployability,log,logfoldchanges,696,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:984,deployability,log,logfoldchanges,984,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:2539,deployability,cluster,cluster,2539,". 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24. 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17. 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11. 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11. 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09. ```. This also extends to enrichment queries (this is what I wanted originally):. ```python. sc.queries.enrich(adata, ""1"", n_top_genes=10). ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:2628,deployability,releas,release-notes,2628,". 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24. 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17. 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11. 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11. 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09. ```. This also extends to enrichment queries (this is what I wanted originally):. ```python. sc.queries.enrich(adata, ""1"", n_top_genes=10). ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:199,integrability,interfac,interface,199,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:199,interoperability,interfac,interface,199,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:199,modifiability,interfac,interface,199,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:2272,modifiability,exten,extends,2272,". 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24. 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17. 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11. 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11. 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09. ```. This also extends to enrichment queries (this is what I wanted originally):. ```python. sc.queries.enrich(adata, ""1"", n_top_genes=10). ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:302,safety,log,logfc,302,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:696,safety,log,logfoldchanges,696,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:984,safety,log,logfoldchanges,984,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:302,security,log,logfc,302,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:696,security,log,logfoldchanges,696,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:984,security,log,logfoldchanges,984,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:192,testability,simpl,simple,192,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:302,testability,log,logfc,302,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:696,testability,log,logfoldchanges,696,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:984,testability,log,logfoldchanges,984,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:101,usability,workflow,workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich,101,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:192,usability,simpl,simple,192,"add n_top_genes argument to rank_genes_groups_df; This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)). ```. output is just the top 2 genes of the list. ```. names scores logfoldchanges pvals pvals_adj. 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. ```. it also works for multiple groups:. ```python. print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)). ```. ```. group names scores logfoldchanges pvals pvals_adj. 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73. 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66. 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139. 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205. 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169. 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147. 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53. 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38. 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82. 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49. 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72. 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78. 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103. 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81. 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133. 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98. 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45. 17 8 MZB1 33.305500 8.979518 7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/issues/2146:736,integrability,sub,sub-plots,736,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:124,modifiability,paramet,parameters,124,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:401,modifiability,pac,package,401,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:0,security,Rotat,Rotate,0,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:472,security,team,team,472,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:520,security,rotat,rotate,520,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:206,testability,simpl,simple,206,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:198,usability,tool,tool,198,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:206,usability,simpl,simple,206,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:222,usability,tool,tool,222,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:270,usability,tool,tools,270,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2146:370,usability,tool,tools,370,"Rotate genes in pl.rank_genes_groups? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2147:0,availability,Error,Error,0,"Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum'; After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2632,availability,error,error,2632,"save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2747,availability,error,error,2747,"ormalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3021,availability,error,error,3021,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3078,availability,error,error,3078,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3371,availability,down,downloaded,3371,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1471,deployability,modul,module,1471,")`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1659,deployability,log,log,1659,"le_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days int",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2177,deployability,log,logg,2177,"r this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. Attrib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2488,deployability,modul,module,2488,"pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3259,deployability,modul,module,3259,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3407,integrability,pub,published,3407,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2586,interoperability,format,format,2586,".py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1155,modifiability,layer,layers,1155,"s://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1471,modifiability,modul,module,1471,")`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1561,modifiability,pac,packages,1561,"t with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1890,modifiability,pac,packages,1890,"ay_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2027,modifiability,layer,layer,2027,"tient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. Wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2034,modifiability,layer,layers,2034,"d'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2488,modifiability,modul,module,2488,"pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2866,modifiability,layer,layer,2866,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2983,modifiability,layer,layers,2983,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3259,modifiability,modul,module,3259,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:0,performance,Error,Error,0,"Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum'; After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2632,performance,error,error,2632,"save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2747,performance,error,error,2747,"ormalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3021,performance,error,error,3021,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3078,performance,error,error,3078,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3435,performance,perform,perform,3435,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:0,safety,Error,Error,0,"Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum'; After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1444,safety,input,input-,1444,"ith_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1471,safety,modul,module,1471,")`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1659,safety,log,log,1659,"le_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days int",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2177,safety,log,logg,2177,"r this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. Attrib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2488,safety,modul,module,2488,"pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2535,safety,input,input,2535,"ata\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2632,safety,error,error,2632,"save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2747,safety,error,error,2747,"ormalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3021,safety,error,error,3021,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3078,safety,error,error,3078,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3232,safety,input,input-,3232,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3259,safety,modul,module,3259,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1659,security,log,log,1659,"le_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days int",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1814,security,ident,identify,1814,"Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2177,security,log,logg,2177,"r this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. Attrib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1400,testability,Trace,Traceback,1400,"orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1659,testability,log,log,1659,"le_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days int",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2177,testability,log,logg,2177,"r this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. Attrib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3188,testability,Trace,Traceback,3188,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:0,usability,Error,Error,0,"Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum'; After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:863,usability,Statu,Status,863,"Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum'; After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1212,usability,command,command,1212,"332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:. I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1444,usability,input,input-,1444,"ith_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```. AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'. obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'. var: 'feature_types'. uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'. obsm: 'X_pca', 'X_pca_harmony', 'X_umap'. layers: 'raw'. ```. After this, when I tried running the command:. `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2329,usability,command,command,2329,"--------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-c4ab6dadfa42> in <module>. ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' obje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2535,usability,input,input,2535,"ata\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2632,usability,error,error,2632,"save, ax, gene_symbols, log, **kwds). 65 . 66 # compute the percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2691,usability,help,help,2691,"e percentage of each gene per cell. ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmode",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2747,usability,error,error,2747,"ormalize_total(adata, target_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2771,usability,help,help,2771,"arget_sum=100, inplace=False). 68 . 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3021,usability,error,error,3021,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3078,usability,error,error,3078,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3232,usability,input,input-,3232,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3435,usability,perform,perform,3435,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3670,usability,learn,learn,3670,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy). 174 counts_per_cell = X[:, gene_subset].sum(1). 175 else:. --> 176 counts_per_cell = X.sum(1). 177 start = logg.info(msg). 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. And when I run the command:. `type(adata_orig.X)`. I get the output as:. `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : . ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-23-951a31c71c45> in <module>. ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'. ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:. `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2148:320,availability,cluster,clusters,320,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:519,availability,cluster,clusters,519,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:155,deployability,version,version,155,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:287,deployability,version,version,287,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:320,deployability,cluster,clusters,320,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:519,deployability,cluster,clusters,519,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:928,deployability,Version,Versions,928,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:155,integrability,version,version,155,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:287,integrability,version,version,287,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:928,integrability,Version,Versions,928,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:155,modifiability,version,version,155,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:287,modifiability,version,version,287,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:928,modifiability,Version,Versions,928,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:115,usability,confirm,confirmed,115,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:198,usability,confirm,confirmed,198,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:414,usability,user,user-images,414,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:637,usability,help,help,637,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2148:654,usability,Minim,Minimal,654,"UMAP goes wrong on scanpy v1.8.2; - [y] I have checked that this issue has not already been reported. - [y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am using scanpy version 1.8.2 and the umap shows clusters like this. <img width=""423"" alt=""Bildschirmfoto 2022-02-21 um 11 39 42"" src=""https://user-images.githubusercontent.com/59925710/154984424-6b54082b-b680-42af-b00b-9d931efcfbac.png"">. But the clusters should have more distance from each other. Do you have an idea how to solve this issue? Many thanks for your help! Büsra. ### Minimal code sample. ```python. import scanpy as sc. adata_mvi.obsm[""MultiVI_latent""] = mvi.get_latent_representation(). sc.pp.neighbors(adata_mvi, use_rep=""MultiVI_latent""). sc.tl.umap(adata_mvi) . sc.tl.leiden(adata_mvi). sc.pl.umap(adata_mvi, color='leiden') . ```. #### Versions. <details>. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148
https://github.com/scverse/scanpy/issues/2149:46,availability,Avail,Available,46,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:628,availability,error,error,628,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:833,availability,Avail,Available,833,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1183,availability,avail,available,1183," this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1219,availability,error,error,1219,"mics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3114,availability,Avail,Available,3114,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:15,deployability,contain,contains,15,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:386,deployability,resourc,resources,386,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:721,deployability,contain,contains,721,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1662,deployability,version,version,1662,"Gem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2243,deployability,modul,module,2243,"e, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2800,deployability,contain,contains,2800,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3002,deployability,contain,contains,3002,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3307,deployability,Version,Versions,3307,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:386,energy efficiency,resourc,resources,386,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:452,integrability,sub,subventricular-zone-nuclei-,452,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1225,integrability,messag,message,1225,"m/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1662,integrability,version,version,1662,"Gem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3307,integrability,Version,Versions,3307,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:483,interoperability,standard,standard-,483,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:785,interoperability,specif,specify,785,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1225,interoperability,messag,message,1225,"m/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2872,interoperability,specif,specify,2872,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3066,interoperability,specif,specify,3066,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1662,modifiability,version,version,1662,"Gem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2243,modifiability,modul,module,2243,"e, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2359,modifiability,pac,packages,2359,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2629,modifiability,pac,packages,2629,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3307,modifiability,Version,Versions,3307,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:386,performance,resourc,resources,386,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:628,performance,error,error,628,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1219,performance,error,error,1219,"mics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:46,reliability,Availab,Available,46,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:833,reliability,Availab,Available,833,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1183,reliability,availab,available,1183," this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1372,reliability,doe,does,1372,"enomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3114,reliability,Availab,Available,3114,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:46,safety,Avail,Available,46,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:386,safety,resourc,resources,386,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:628,safety,error,error,628,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:833,safety,Avail,Available,833,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1183,safety,avail,available,1183," this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1219,safety,error,error,1219,"mics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2216,safety,input,input-,2216,"error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2243,safety,modul,module,2243,"e, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3114,safety,Avail,Available,3114,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:46,security,Availab,Available,46,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:833,security,Availab,Available,833,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1183,security,availab,available,1183," this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3114,security,Availab,Available,3114,"ct 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. #### Versions. <details>. 1.8.2. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:386,testability,resourc,resources,386,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2172,testability,Trace,Traceback,2172," The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcode",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:409,usability,mous,mouse-e-,409,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:628,usability,error,error,628,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1080,usability,mous,mouse,1080,"h5; Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1219,usability,error,error,1219,"mics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```. scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None). ```. I get the following error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1622,usability,confirm,confirmed,1622," error, . ```. ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1705,usability,confirm,confirmed,1705,"e_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1772,usability,Minim,Minimal,1772,"you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']. ```. and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueErr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:2216,usability,input,input-,2216,"error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```. h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'). ```. ```. TypeError: node ``/umi_type`` is not a group. ```. - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-15-2e1cefb9ad47> in <module>. ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url). 194 adata = adata.copy(). 195 else:. --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start). 197 return adata. 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start). 207 if not genome:. 208 if len(children) > 1:. --> 209 raise ValueError(. 210 f""'{filename}' contains more than one genome. For legacy 10x h5 "". 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/pull/2150:14,availability,state,state,14,Remove global state changes in plotting tests; 🤞,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2150
https://github.com/scverse/scanpy/pull/2150:14,integrability,state,state,14,Remove global state changes in plotting tests; 🤞,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2150
https://github.com/scverse/scanpy/pull/2150:40,safety,test,tests,40,Remove global state changes in plotting tests; 🤞,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2150
https://github.com/scverse/scanpy/pull/2150:40,testability,test,tests,40,Remove global state changes in plotting tests; 🤞,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2150
https://github.com/scverse/scanpy/issues/2151:1067,deployability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:41,integrability,batch,batches,41,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:531,integrability,batch,batches,531,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1061,integrability,batch,batch,1061,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,integrability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1281,integrability,batch,batch,1281,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1312,integrability,batch,batches,1312,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1400,integrability,batch,batch,1400,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1431,integrability,batch,batches,1431,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,interoperability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:0,modifiability,exten,extend,0,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,modifiability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:41,performance,batch,batches,41,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:531,performance,batch,batches,531,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1061,performance,batch,batch,1061,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1281,performance,batch,batch,1281,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1312,performance,batch,batches,1312,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1400,performance,batch,batch,1400,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1431,performance,batch,batches,1431,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,reliability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1125,safety,reme,remember,1125,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:292,security,expos,expose,292,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:860,security,expos,exposing,860,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,security,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1067,testability,integr,integration,1067,"extend options to aggregate ranks across batches for HVG selection; I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:. I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default? I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/pull/2152:49,availability,state,state,49,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:116,availability,state,state,116,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:49,integrability,state,state,49,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:116,integrability,state,state,116,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:75,safety,test,tests,75,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:142,safety,test,tests,142,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:75,testability,test,tests,75,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/pull/2152:142,testability,test,tests,142,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests); Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/issues/2153:172,deployability,version,version,172,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:616,deployability,modul,module,616,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:172,integrability,version,version,172,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:1554,integrability,wrap,wrapper,1554,"x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays used as indices must be of integer (or boolean) type. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:43,interoperability,format,format,43,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:339,interoperability,specif,specific,339,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:1554,interoperability,wrapper,wrapper,1554,"x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays used as indices must be of integer (or boolean) type. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:172,modifiability,version,version,172,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:616,modifiability,modul,module,616,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:779,modifiability,pac,packages,779,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:1193,modifiability,pac,packages,1193,"x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays used as indices must be of integer (or boolean) type. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:1783,modifiability,pac,packages,1783,"x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays used as indices must be of integer (or boolean) type. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:317,reliability,doe,does,317,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:596,safety,Input,Input,596,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:616,safety,modul,module,616,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:14,security,control,control,14,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:14,testability,control,control,14,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:561,testability,Trace,Traceback,561,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:132,usability,confirm,confirmed,132,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:215,usability,confirm,confirmed,215,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:596,usability,Input,Input,596,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2153:795,usability,tool,tools,795,"Score genes - control genes index of wrong format; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb. genes=['INS']. score_name='ins'. 'INS' in adata_rawnorm.var_names. True. IndexError Traceback (most recent call last). Input In [109], in <module>. ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 164 else:. 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'). --> 167 X_control = _adata[:, control_genes].X. 168 if issparse(X_control):. 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self). 622 X = _subset(X, (self._oidx, self._vidx)). 623 elif self.is_view:. 624 X = as_view(. --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),. 626 ElementRef(self, ""X""),. 627 ). 628 else:. 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw). 871 if not args:. 872 raise TypeError(f'{funcname} requires at least '. 873 '1 positional argument'). --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx). 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):. 126 subset_idx = np.ix_(*subset_idx). --> 127 return a[subset_idx]. IndexError: arrays use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2154:755,energy efficiency,GPU,GPU,755,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:946,integrability,wrap,wrapper,946,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:946,interoperability,wrapper,wrapper,946,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:107,modifiability,paramet,parameters,107,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:384,modifiability,pac,package,384,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:755,performance,GPU,GPU,755,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:189,testability,simpl,simple,189,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:181,usability,tool,tool,181,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:189,usability,simpl,simple,189,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:205,usability,tool,tool,205,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:253,usability,tool,tools,253,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:353,usability,tool,tools,353,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:503,usability,visual,visualization,503,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:544,usability,effectiv,effectively,544,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:1055,usability,user,user-images,1055,"Implement `sc.tl.mde`; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2155:480,availability,down,downsampling,480,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:521,availability,robust,robustness,521,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:29,modifiability,variab,variability,29,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:179,modifiability,design decis,design decisions,179,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:326,modifiability,variab,variability,326,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:521,reliability,robust,robustness,521,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:521,safety,robust,robustness,521,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:532,safety,test,test,532,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:7,security,control,control,7,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:314,security,control,control,314,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:7,testability,control,control,7,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:314,testability,control,control,314,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:532,testability,test,test,532,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:77,usability,help,help,77,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:554,usability,feedback,feedback,554,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:615,usability,user,user-images,615,"How to control/normalize for variability among samples?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi . if samples contribute a different number of cells to my object, how to control for variability among samples? . How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2156:0,availability,Error,Error,0,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:206,availability,error,error,206,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:287,availability,error,error,287,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1305,deployability,modul,module,1305,"Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2788,deployability,Version,Versions,2788,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2837,deployability,log,logging,2837,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1895,energy efficiency,core,core,1895,"s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2200,energy efficiency,core,core,2200,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2485,energy efficiency,core,core,2485,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2350,integrability,sub,subarr,2350,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2613,integrability,sub,subarr,2613,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2658,integrability,sub,subarr,2658,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2788,integrability,Version,Versions,2788,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1305,modifiability,modul,module,1305,"Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1609,modifiability,pac,packages,1609,"esktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1879,modifiability,pac,packages,1879,") for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2184,modifiability,pac,packages,2184,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2469,modifiability,pac,packages,2469,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2788,modifiability,Version,Versions,2788,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:0,performance,Error,Error,0,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:206,performance,error,error,206,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:287,performance,error,error,287,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:0,safety,Error,Error,0,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:206,safety,error,error,206,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:287,safety,error,error,287,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1305,safety,modul,module,1305,"Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2837,safety,log,logging,2837,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2837,security,log,logging,2837,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1232,testability,Trace,Traceback,1232,"h this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_arra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2837,testability,log,logging,2837,"m = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.empty(length, dtype=dtype). 1462 subarr.fill(value). 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:0,usability,Error,Error,0,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:206,usability,error,error,206,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:226,usability,help,help,226,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:287,usability,error,error,287,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:334,usability,guid,guide,334,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:389,usability,minim,minimal-bug-reports,389,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:495,usability,Minim,Minimal,495,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:579,usability,Mous,Mouse,579,"Error in cell cycle score calculation; Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error? Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## Mouse. folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:1625,usability,tool,tools,1625,"acosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. Traceback (most recent call last). /tmp/ipykernel_2938/2560507023.py in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 255 . 256 # default phase is S. --> 257 phase = pd.Series('S', index=scores.index). 258 . 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 463 value = maybe_cast_to_datetime(value, dtype). 464 . --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype). 466 . 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype). 1459 value = ensure_str(value). 1460 . -> 1461 subarr = np.emp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2157:364,deployability,modul,module,364,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:497,deployability,API,API,497,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:130,energy efficiency,Current,Currently,130,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:497,integrability,API,API,497,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:497,interoperability,API,API,497,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:364,modifiability,modul,module,364,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:364,safety,modul,module,364,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2157:156,usability,support,support,156,"Compute UMAP from pre-existing distance matrix; It should be easier to compute a UMAP layout from a pre-existing distance matrix. Currently, we only really support this for pre-existing connectivity matrices. The missing step here is computing the umap weighted graph from a distance matrix. The functionality for this largely already exists in the `sc.neighbors` module in private functions (example: https://github.com/theislab/scanpy/issues/2139#issuecomment-1050914072). We would just need an API. Previously discussed in: #1561",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2157
https://github.com/scverse/scanpy/issues/2158:230,deployability,instal,install,230,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:265,deployability,instal,install,265,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:320,deployability,fail,fails,320,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:330,deployability,fail,fail,330,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:257,reliability,doe,doesn,257,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:320,reliability,fail,fails,320,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:330,reliability,fail,fail,330,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:142,safety,test,tests,142,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:194,safety,test,tests,194,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:315,safety,test,test,315,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:142,testability,test,tests,142,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:194,testability,test,tests,194,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:315,testability,test,test,315,"`test_plotting.py` imports scrublet, shall be moved?; https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/pull/2159:57,availability,error,error,57,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:127,availability,error,error,127,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:57,performance,error,error,57,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:127,performance,error,error,127,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:57,safety,error,error,57,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:127,safety,error,error,127,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:57,usability,error,error,57,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/pull/2159:127,usability,error,error,127,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib); Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/issues/2160:509,availability,error,error,509,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:693,availability,error,errors,693,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2224,availability,state,state,2224,"e ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5615,availability,state,state,5615,"(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5940,availability,state,state,5940," 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7511,availability,error,errors,7511,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7599,availability,error,errors,7599,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1724,deployability,build,builder,1724,"context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1907,deployability,build,builder,1907,"RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2938,deployability,modul,module,2938,". File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3662,deployability,modul,module,3662,"tamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppDa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3789,deployability,modul,module,3789,"other exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3921,deployability,modul,module,3921," line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4974,deployability,pipelin,pipeline,4974,"ocal\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7621,deployability,Fail,Failed,7621,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7645,deployability,pipelin,pipeline,7645,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:688,energy efficiency,core,core,688,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:828,energy efficiency,core,core,828,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:980,energy efficiency,core,core,980,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1143,energy efficiency,core,core,1143,"an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1308,energy efficiency,core,core,1308,"ix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1473,energy efficiency,core,core,1473,"ceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1655,energy efficiency,core,core,1655,"thon39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1837,energy efficiency,core,core,1837,"ng.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most rece",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2027,energy efficiency,core,core,2027," self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2327,energy efficiency,core,core,2327,"ne 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connect",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2512,energy efficiency,core,core,2512,"l. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivitie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2658,energy efficiency,core,core,2658,"lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2673,energy efficiency,model,models,2673,"ne 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4032,energy efficiency,core,core,4032,"rams\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4178,energy efficiency,core,core,4178,"ppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4355,energy efficiency,core,core,4355,"ities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4540,energy efficiency,core,core,4540,"rt fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4723,energy efficiency,core,core,4723,"Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_mach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4920,energy efficiency,core,core,4920,"odule>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5088,energy efficiency,core,core,5088,"g). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5252,energy efficiency,core,core,5252,"s, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5416,energy efficiency,core,core,5416,"f._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5556,energy efficiency,core,core,5556,""", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5707,energy efficiency,core,core,5707,"ackages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lower",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5863,energy efficiency,core,core,5863,"Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6032,energy efficiency,core,core,6032,"ocal\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6205,energy efficiency,core,core,6205,"rams\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6389,energy efficiency,core,core,6389,"\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6554,energy efficiency,core,core,6554,"core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6699,energy efficiency,core,core,6699,"numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6863,energy efficiency,core,core,6863,"re\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7049,energy efficiency,core,core,7049,"py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_gl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7211,energy efficiency,core,core,7211,"piler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7506,energy efficiency,core,core,7506,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7594,energy efficiency,core,core,7594,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7717,energy efficiency,core,core,7717,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7732,energy efficiency,model,models,7732,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2056,integrability,wrap,wrapper,2056,"ile ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2224,integrability,state,state,2224,"e ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4066,integrability,wrap,wrapper,4066,"es\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4974,integrability,pipelin,pipeline,4974,"ocal\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5615,integrability,state,state,5615,"(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5940,integrability,state,state,5940," 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7645,integrability,pipelin,pipeline,7645,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2056,interoperability,wrapper,wrapper,2056,"ile ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4066,interoperability,wrapper,wrapper,4066,"es\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:673,modifiability,pac,packages,673,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:813,modifiability,pac,packages,813,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:965,modifiability,pac,packages,965,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1128,modifiability,pac,packages,1128,". Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Prog",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1293,modifiability,pac,packages,1293,"pression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1458,modifiability,pac,packages,1458,"<summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1640,modifiability,pac,packages,1640,"ams\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1822,modifiability,pac,packages,1822,"a\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2012,modifiability,pac,packages,2012,"r_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2162,modifiability,pac,packages,2162," 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2312,modifiability,pac,packages,2312,"ering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2497,modifiability,pac,packages,2497," in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2938,modifiability,modul,module,2938,". File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3064,modifiability,pac,packages,3064,"urn fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3227,modifiability,pac,packages,3227,"top = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3439,modifiability,pac,packages,3439,"RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3662,modifiability,modul,module,3662,"tamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppDa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3789,modifiability,modul,module,3789,"other exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3921,modifiability,modul,module,3921," line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4017,modifiability,pac,packages,4017,"ta\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4037,modifiability,deco,decorators,4037,"hon\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4163,modifiability,pac,packages,4163,"Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4340,modifiability,pac,packages,4340,"ute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4525,modifiability,pac,packages,4525,"ap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4708,modifiability,pac,packages,4708,"UTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4905,modifiability,pac,packages,4905,"ine 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5073,modifiability,pac,packages,5073,"sp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5237,modifiability,pac,packages,5237,"r.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 29",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5401,modifiability,pac,packages,5401," retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5541,modifiability,pac,packages,5541,"dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5692,modifiability,pac,packages,5692,"39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5848,modifiability,pac,packages,5848,"UTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6017,modifiability,pac,packages,6017,"TBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Pytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6190,modifiability,pac,packages,6190,"ta\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6374,modifiability,pac,packages,6374,"thon\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6539,modifiability,pac,packages,6539,"ckages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_err",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6684,modifiability,pac,packages,6684,"ite-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6848,modifiability,pac,packages,6848,"ages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7034,modifiability,pac,packages,7034,"ompiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, fu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7196,modifiability,pac,packages,7196,"umba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7491,modifiability,pac,packages,7491,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:509,performance,error,error,509,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:693,performance,error,errors,693,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7511,performance,error,errors,7511,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7599,performance,error,errors,7599,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7621,reliability,Fail,Failed,7621,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:509,safety,error,error,509,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:693,safety,error,errors,693,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2779,safety,except,exception,2779,"cal\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2798,safety,except,exception,2798,"\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2938,safety,modul,module,2938,". File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3662,safety,modul,module,3662,"tamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppDa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3789,safety,modul,module,3789,"other exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3921,safety,modul,module,3921," line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7511,safety,error,errors,7511,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7599,safety,error,errors,7599,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1559,security,sign,signature,1559,"------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise Ty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2673,security,model,models,2673,"ne 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7732,security,model,models,7732,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:472,testability,trace,traceback,472,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2819,testability,Trace,Traceback,2819,"ckages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7343,testability,context,contextlib,7343,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7410,testability,trace,traceback,7410,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:170,usability,Minim,Minimal,170,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:264,usability,User,Users,264,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:509,usability,error,error,509,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:613,usability,User,Users,613,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:693,usability,error,errors,693,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:753,usability,User,Users,753,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:905,usability,User,Users,905,"Bug on scanpy, sc.pp.neighbors function; > Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1068,usability,User,Users,1068,"dataset and I run into a problem when computing the neigbours. Find below an small example:. . ### Minimal code sample. ```python. import scanpy. import numpy. > . tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1233,usability,User,Users,1233,"ab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'). sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1398,usability,User,Users,1398,"pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>. <summary> traceback </summary>. ```pytb. > The error I get:. > ---------------------------------------------------------------------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1580,usability,User,Users,1580,"-----------------. > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context. yield. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1762,usability,User,Users,1762,"AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:1952,usability,User,Users,1952,"\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst. val = self.lower_assign(ty, inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2102,usability,User,Users,2102,"thon\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign. return self.lower_expr(ty, value). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2230,usability,stop,stop,2230,"\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2237,usability,stop,stop,2237,"RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2252,usability,User,Users,2252,"cal\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr. res = self.lower_call(resty, expr). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2437,usability,User,Users,2437,"Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call. res = self._lower_call_normal(fnty, expr, signature). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal. res = impl(self.builder, argvals, self.loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2864,usability,User,Users,2864,"_call__. res = self._imp(self._context, builder, self._sig, args, loc=loc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Progra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3004,usability,User,Users,3004,"site-packages\numba\core\base.py"", line 1231, in wrapper. return fn(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3167,usability,User,Users,3167,"\numba\cpython\rangeobj.py"", line 40, in range1_impl. state.stop = stop. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__. self[self._datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3379,usability,User,Users,3379,"datamodel.get_field_position(field)] = value. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__. raise TypeError(""Invalid store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3576,usability,User,Users,3576,"d store of {value.type} to "". TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3705,usability,User,Users,3705,"15592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3835,usability,User,Users,3835,"ent call last):. File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>. sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:3957,usability,User,Users,3957,"rs(tab, n_neighbors=10, n_pcs=40). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4103,usability,User,Users,4103,"ne 139, in neighbors. neighbors.compute_neighbors(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"",",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4280,usability,User,Users,4280,"pute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4398,usability,statu,status,4398,"cal\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4465,usability,User,Users,4465,"nit__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4648,usability,User,Users,4648,"ine 2, in <module>. from .umap_ import UMAP. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>. from umap.layouts import (. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4845,usability,User,Users,4845,"ppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>. def rdist(x, y):. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5013,usability,User,Users,5013,"-packages\numba\core\decorators.py"", line 219, in wrapper. disp.compile(sig). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5177,usability,User,Users,5177,"re\dispatcher.py"", line 965, in compile. cres = self._compiler.compile(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5341,usability,User,Users,5341,"ages\numba\core\dispatcher.py"", line 125, in compile. status, retval = self._compile_cached(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Prog",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5481,usability,User,Users,5481,"\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached. retval = self._compile_core(args, return_type). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5632,usability,User,Users,5632,"e). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core. cres = compiler.compile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5788,usability,User,Users,5788,"pile_extra(self.targetdescr.typing_context,. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:5957,usability,User,Users,5957,"extra. return pipeline.compile_extra(func). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra. return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_bod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6130,usability,User,Users,6130,". return self._compile_bytecode(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode. return self._compile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6314,usability,User,Users,6314,"ompile_core(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core. raise e. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6479,usability,User,Users,6479,"sers\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core. pm.run(self.state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6624,usability,User,Users,6624," ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run. raise patched_exception. File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6788,usability,User,Users,6788,"rs\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run. self._runPass(idx, pass_inst, state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:6974,usability,User,Users,6974,"Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_lock.py"", line 35, in _acquire_compile_lock. return func(*args, **kwargs). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7136,usability,User,Users,7136,"BO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 296, in _runPass. mutated |= check(pss.run_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7288,usability,User,Users,7288,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7431,usability,User,Users,7431,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7511,usability,error,errors,7511,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7599,usability,error,errors,7599,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:8132,usability,User,Users,8132,"_pass, internal_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check. mangled = func(compiler_state). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass. lower.lower(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower. self.lower_normal_function(self.fndesc). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function. entry_block_tail = self.lower_function_body(). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body. self.lower_block(block). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block. self.lower_inst(inst). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__. self.gen.throw(type, value, traceback). File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context. raise newerr.with_traceback(tb). numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering). Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:. def rdist(x, y):. <source elided>. dim = x.shape[0]. for i in range(dim):. ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2161:328,availability,down,download,328,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:226,deployability,contain,containing,226,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:426,deployability,manag,manage,426,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:426,energy efficiency,manag,manage,426,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:949,modifiability,paramet,parameters,949,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:426,safety,manag,manage,426,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2161:373,testability,plan,plan,373,"read_10x_mtx with different prefixes for the barcodes, features and matrix files; Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side. Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz. > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2162:16,deployability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,deployability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,deployability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,integrability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,integrability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,integrability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:495,integrability,transform,transformation,495,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,interoperability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,interoperability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,interoperability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:495,interoperability,transform,transformation,495,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,modifiability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,modifiability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,modifiability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,reliability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,reliability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,reliability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:367,safety,test,test,367,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:413,safety,test,test,413,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:517,safety,test,test,517,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,security,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,security,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,security,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:16,testability,integr,integration,16,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:112,testability,integr,integrating,112,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:367,testability,test,test,367,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:413,testability,test,test,413,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:441,testability,integr,integration,441,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:517,testability,test,test,517,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:606,usability,help,help,606,"Tansfering data integration fom scanorama to a new dataset; Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers. Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2163:75,availability,cluster,cluster,75,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:128,availability,cluster,clusters,128,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:242,availability,error,error,242,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:369,availability,error,error,369,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:75,deployability,cluster,cluster,75,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:128,deployability,cluster,clusters,128,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:173,deployability,scale,scale,173,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:269,deployability,contain,contains,269,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:350,deployability,scale,scale,350,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:173,energy efficiency,scale,scale,173,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:350,energy efficiency,scale,scale,350,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:83,integrability,sub,subset,83,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:439,integrability,sub,subset,439,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:28,modifiability,scal,scaling,28,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:173,modifiability,scal,scale,173,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:350,modifiability,scal,scale,350,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:173,performance,scale,scale,173,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:242,performance,error,error,242,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:350,performance,scale,scale,350,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:369,performance,error,error,369,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:375,reliability,doe,doe,375,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:242,safety,error,error,242,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:263,safety,Input,Input,263,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:369,safety,error,error,369,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:242,usability,error,error,242,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:263,usability,Input,Input,263,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:369,usability,error,error,369,"Issue with tl.pca following scaling; scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python . B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(). sc.pp.scale(B). sc.tl.pca(B, svd_solver='arpack'). ```. Yet I encounter an error:. `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2164:22,deployability,scale,scale,22,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:113,deployability,scale,scale,113,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,deployability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:484,deployability,scale,scale,484,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:22,energy efficiency,scale,scale,22,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:113,energy efficiency,scale,scale,113,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:484,energy efficiency,scale,scale,484,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,integrability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,interoperability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:22,modifiability,scal,scale,22,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:113,modifiability,scal,scale,113,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,modifiability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:484,modifiability,scal,scale,484,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:22,performance,scale,scale,22,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:113,performance,scale,scale,113,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:484,performance,scale,scale,484,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:94,reliability,doe,does,94,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,reliability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,security,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:187,testability,integr,integrating-data-using-ingest,187,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:78,usability,document,documents,78,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:236,usability,document,documents,236,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:357,usability,tool,tools,357,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:398,usability,tool,tools,398,"Questions about sc.pp.scale and sc.tl.pca; Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2165:105,availability,error,error,105,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:256,availability,error,error,256,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:415,availability,error,error,415,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:189,deployability,instal,installed,189,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:572,deployability,modul,module,572,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:679,deployability,modul,module,679,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:818,deployability,modul,module,818,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:971,deployability,modul,module,971,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1163,deployability,modul,module,1163,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1334,deployability,modul,module,1334,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:572,modifiability,modul,module,572,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:636,modifiability,pac,packages,636,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:679,modifiability,modul,module,679,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:770,modifiability,pac,packages,770,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:818,modifiability,modul,module,818,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:915,modifiability,pac,packages,915,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:971,modifiability,modul,module,971,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1106,modifiability,pac,packages,1106,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1163,modifiability,modul,module,1163,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1272,modifiability,pac,packages,1272,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1334,modifiability,modul,module,1334,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:105,performance,error,error,105,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:256,performance,error,error,256,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:415,performance,error,error,415,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:105,safety,error,error,105,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:256,safety,error,error,256,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:415,safety,error,error,415,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:572,safety,modul,module,572,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:679,safety,modul,module,679,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:818,safety,modul,module,818,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:971,safety,modul,module,971,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1163,safety,modul,module,1163,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:1334,safety,modul,module,1334,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:508,testability,Trace,Traceback,508,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:105,usability,error,error,105,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:256,usability,error,error,256,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:415,usability,error,error,415,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:702,usability,tool,tools,702,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:786,usability,tool,tools,786,"ImportError: cannot import name 'sparsefuncs'; Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`. `>>> import sklearn`. `>>> import scanpy`. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>. from . import tools as tl. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>. from ..preprocessing import pca. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>. from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>. from ._normalization import normalize_total. File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>. from sklearn.utils import sparsefuncs. ImportError: cannot import name 'sparsefuncs'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/pull/2166:0,deployability,Updat,Update,0,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2166:26,deployability,Updat,Updating,26,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2166:0,safety,Updat,Update,0,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2166:26,safety,Updat,Updating,26,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2166:0,security,Updat,Update,0,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2166:26,security,Updat,Updating,26,Update intersphinx links; Updating a bunch of inter sphinx links. Thx for figuring out why the matplotlib one broke stuff @grst,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2166
https://github.com/scverse/scanpy/pull/2167:35,deployability,Updat,Update,35,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2167:81,deployability,Updat,Update,81,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2167:35,safety,Updat,Update,35,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2167:81,safety,Updat,Update,81,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2167:35,security,Updat,Update,35,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2167:81,security,Updat,Update,81,Backport PR #2166 on branch 1.8.x (Update intersphinx links); Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/pull/2168:58,deployability,fail,fails,58,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/pull/2168:108,deployability,fail,fails,108,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/pull/2168:58,reliability,fail,fails,58,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/pull/2168:108,reliability,fail,fails,108,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/pull/2168:39,security,certif,certifi,39,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/pull/2168:89,security,certif,certifi,89,Backport PR #2119 on branch 1.8.x (Use certifi if urlopen fails); Backport PR #2119: Use certifi if urlopen fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2168
https://github.com/scverse/scanpy/issues/2169:4448,availability,error,error,4448,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:39,deployability,instal,installation,39,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:191,deployability,version,version,191,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:363,deployability,contain,containing,363,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:736,deployability,modul,module,736,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2014,deployability,instal,installed,2014,"cs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2244,deployability,modul,module,2244,"n=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2484,deployability,modul,module,2484,"s). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2825,deployability,modul,module,2825,"e_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2954,deployability,version,version,2954,"nings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3366,deployability,modul,moduleOrReq,3366,"rnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3429,deployability,modul,module,3429,"to3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3473,deployability,modul,moduleOrReq,3473," in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3533,deployability,modul,moduleOrReq,3533,"escent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3561,deployability,modul,moduleOrReq,3561,"distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3593,deployability,modul,module,3593,"ces as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3606,deployability,modul,modules,3606,"med_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3614,deployability,modul,moduleOrReq,3614,"ces. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4003,deployability,instal,installer,4003,"sources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4330,deployability,Version,Versions,4330,"ces/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4347,deployability,version,version,4347,"n get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4428,deployability,version,versions,4428,"ule or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4642,deployability,modul,module,4642,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4668,deployability,log,logging,4668,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4785,deployability,log,logging,4785,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4889,deployability,depend,dependencies,4889,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5053,deployability,depend,dependencies,5053,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5219,deployability,modul,modules,5219,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5250,deployability,modul,modules,5250,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5297,deployability,version,version,5297,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5427,deployability,version,version,5427,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5039,energy efficiency,cpu,cpu,5039,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:191,integrability,version,version,191,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1964,integrability,filter,filterwarnings,1964,"__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1989,integrability,messag,message,1989,"rs(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2954,integrability,version,version,2954,"nings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4330,integrability,Version,Versions,4330,"ces/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4347,integrability,version,version,4347,"n get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4428,integrability,version,versions,4428,"ule or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4889,integrability,depend,dependencies,4889,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5053,integrability,depend,dependencies,5053,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5297,integrability,version,version,5297,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5427,integrability,version,version,5427,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:628,interoperability,Distribut,DistributionNotFound,628,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1989,interoperability,messag,message,1989,"rs(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3193,interoperability,Distribut,Distribution,3193,"python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3263,interoperability,Distribut,Distribution,3263,"import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4124,interoperability,Distribut,DistributionNotFound,4124,"466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4217,interoperability,Distribut,DistributionNotFound,4217,"r(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4257,interoperability,distribut,distribution,4257,"Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:191,modifiability,version,version,191,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:736,modifiability,modul,module,736,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:945,modifiability,pac,packages,945,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1329,modifiability,pac,packages,1329,"ndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1780,modifiability,pac,packages,1780,"mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2214,modifiability,pac,packages,2214,"eighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2244,modifiability,modul,module,2244,"n=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2457,modifiability,pac,packages,2457,"ndices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2484,modifiability,modul,module,2484,"s). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2788,modifiability,pac,packages,2788,"npy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2825,modifiability,modul,module,2825,"e_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2954,modifiability,version,version,2954,"nings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2993,modifiability,pac,packages,2993,"r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3315,modifiability,pac,packages,3315," from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3366,modifiability,modul,moduleOrReq,3366,"rnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3429,modifiability,modul,module,3429,"to3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3473,modifiability,modul,moduleOrReq,3473," in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3533,modifiability,modul,moduleOrReq,3533,"escent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3561,modifiability,modul,moduleOrReq,3561,"distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3593,modifiability,modul,module,3593,"ces as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3606,modifiability,modul,modules,3606,"med_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3614,modifiability,modul,moduleOrReq,3614,"ces. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3658,modifiability,pac,packages,3658,"rse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 pri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3932,modifiability,pac,packages,3932,"on(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4330,modifiability,Version,Versions,4330,"ces/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4347,modifiability,version,version,4347,"n get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4428,modifiability,version,versions,4428,"ule or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4642,modifiability,modul,module,4642,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4769,modifiability,pac,packages,4769,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4889,modifiability,depend,dependencies,4889,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4999,modifiability,pac,packages,4999,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5053,modifiability,depend,dependencies,5053,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5219,modifiability,modul,modules,5219,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5250,modifiability,modul,modules,5250,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5297,modifiability,version,version,5297,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5427,modifiability,version,version,5427,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4448,performance,error,error,4448,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5039,performance,cpu,cpu,5039,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:736,safety,modul,module,736,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2244,safety,modul,module,2244,"n=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2484,safety,modul,module,2484,"s). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2825,safety,modul,module,2825,"e_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3366,safety,modul,moduleOrReq,3366,"rnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3429,safety,modul,module,3429,"to3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3473,safety,modul,moduleOrReq,3473," in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3533,safety,modul,moduleOrReq,3533,"escent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ----------------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3561,safety,modul,moduleOrReq,3561,"distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3593,safety,modul,module,3593,"ces as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3606,safety,modul,modules,3606,"med_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3614,safety,modul,moduleOrReq,3614,"ces. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq). 340 """"""Return an IResourceProvider for the named module or requirement"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4448,safety,error,error,4448,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4642,safety,modul,module,4642,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4668,safety,log,logging,4668,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4785,safety,log,logging,4785,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4889,safety,depend,dependencies,4889,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5053,safety,depend,dependencies,5053,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5219,safety,modul,modules,5219,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5250,safety,modul,modules,5250,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4668,security,log,logging,4668,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4785,security,log,logging,4785,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:649,testability,Trace,Traceback,649,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2298,testability,simpl,simplefilter,2298,"to3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4555,testability,Trace,Traceback,4555,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4668,testability,log,logging,4668,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4785,testability,log,logging,4785,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4889,testability,depend,dependencies,4889,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5053,testability,depend,dependencies,5053,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:151,usability,confirm,confirmed,151,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:234,usability,confirm,confirmed,234,"scanpy.pp.neighbors won't recognize an installation of 'pynndescent'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ""mat"" is an object of the type <class 'anndata._core.anndata.AnnData'> containing cell data. I am trying to create a force map for mat. Its shape is (1804, 11688). ```python. sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(mat). ```. ```pytb. ---------------------------------------------------------------------------. DistributionNotFound Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/1044039429.py in <module>. 4 # Force-directed graph. 5 print(type(mat)). ----> 6 sc.pp.neighbors(mat, n_neighbors=4, n_pcs=20). 7 sc.tl.draw_graph(mat). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2298,usability,simpl,simplefilter,2298,"to3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>. 1 from warnings import warn, catch_warnings, simplefilter. ----> 2 from .umap_ import UMAP. 3 . 4 try:. 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>. 45 ). 46 . ---> 47 from pynndescent import NNDescent. 48 from pynndescent.distances import named_distances as pynn_named_distances. 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>. 13 numba.config.THREADING_LAYER = ""workqueue"". 14 . ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist). 464 dist = Requirement.parse(dist). 465 if isinstance(dist, Requirement):. --> 466 dist = get_provider(dist). 467 if not isinstance(dist, Distribution):. 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4448,usability,error,error,4448,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5443,usability,learn,learn,5443,"t"""""". 341 if isinstance(moduleOrReq, Requirement):. --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]. 343 try:. 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements). 884 included, even if they were already activated in this working set. 885 """""". --> 886 needed = self.resolve(parse_requirements(requirements)). 887 . 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras). 770 if dist is None:. 771 requirers = required_by.get(req, None). --> 772 raise DistributionNotFound(req, requirers). 773 to_activate.append(dist). 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application. ```. #### Versions. latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>. ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file). 167 try:. 168 buf = sys.stdout = io.StringIO(). --> 169 sinfo(. 170 dependencies=True,. 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 208 for mod_name in clean_modules:. 209 mod_names.append(mod_name). --> 210 mod = sys.modules[mod_name]. 211 # Since modules use different attribute names to store version info,. 212 # try the most common ones. KeyError: 'umap'. ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/pull/2170:34,safety,test,test,34,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:280,safety,review,review,280,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:361,safety,test,test,361,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:0,security,modif,modify,0,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:34,testability,test,test,34,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:280,testability,review,review,280,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:361,testability,test,test,361,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:131,usability,guid,guidelines,131,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:162,usability,guid,guide,162,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:258,usability,workflow,workflow,258,modify test_read_visium_counts to test read_visium function; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/issues/2171:732,availability,error,error,732,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:213,deployability,version,version,213,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:789,deployability,Version,Versions,789,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:838,deployability,log,logging,838,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:213,integrability,version,version,213,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:789,integrability,Version,Versions,789,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:213,modifiability,version,version,213,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:789,modifiability,Version,Versions,789,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:732,performance,error,error,732,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:732,safety,error,error,732,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:838,safety,log,logging,838,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:838,security,log,logging,838,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:838,testability,log,logging,838,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:173,usability,confirm,confirmed,173,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:256,usability,confirm,confirmed,256,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:447,usability,guid,guide,447,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:502,usability,minim,minimal-bug-reports,502,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:608,usability,Minim,Minimal,608,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:732,usability,error,error,732,"How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？. thanks. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2172:6,deployability,instal,install,6,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:183,deployability,version,version,183,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:436,deployability,instal,install,436,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:470,deployability,instal,install,470,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:636,deployability,modul,module,636,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:773,deployability,modul,module,773,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:922,deployability,modul,module,922,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1063,deployability,modul,module,1063,"] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1106,deployability,log,logging,1106,"eady been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1117,deployability,log,logg,1117," reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1231,deployability,modul,module,1231,"d this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1362,deployability,modul,module,1362,"`bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1520,deployability,modul,module,1520,"py as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1803,deployability,Instal,Installing,1803," File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1824,deployability,instal,install,1824,"er/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1869,deployability,Version,Versions,1869,"packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3671,deployability,log,logical,3671,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3725,deployability,updat,updated,3725,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:2198,energy efficiency,cloud,cloudpickle,2198,"eadwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3679,energy efficiency,CPU,CPU,3679,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3683,energy efficiency,core,cores,3683,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:183,integrability,version,version,183,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1869,integrability,Version,Versions,1869,"packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:183,modifiability,version,version,183,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:636,modifiability,modul,module,636,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:730,modifiability,pac,packages,730,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:773,modifiability,modul,module,773,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:873,modifiability,pac,packages,873,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:922,modifiability,modul,module,922,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1018,modifiability,pac,packages,1018,"nda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1063,modifiability,modul,module,1063,"] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1187,modifiability,pac,packages,1187,"of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1231,modifiability,modul,module,1231,"d this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1319,modifiability,pac,packages,1319,"an copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1362,modifiability,modul,module,1362,"`bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1481,modifiability,pac,packages,1481,"onda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1520,modifiability,modul,module,1520,"py as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1629,modifiability,pac,packages,1629,"n <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1869,modifiability,Version,Versions,1869,"packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:2330,modifiability,deco,decorator,2330,"__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:2764,modifiability,pac,packaging,2764,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:2152,performance,bottleneck,bottleneck,2152,"nvs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3679,performance,CPU,CPU,3679,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:636,safety,modul,module,636,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:773,safety,modul,module,773,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:922,safety,modul,module,922,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1063,safety,modul,module,1063,"] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1106,safety,log,logging,1106,"eady been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1117,safety,log,logg,1117," reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1231,safety,modul,module,1231,"d this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1362,safety,modul,module,1362,"`bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1520,safety,modul,module,1520,"py as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1844,safety,prevent,prevents,1844,"canpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3671,safety,log,logical,3671,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3725,safety,updat,updated,3725,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1106,security,log,logging,1106,"eady been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1117,security,log,logg,1117," reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1844,security,preven,prevents,1844,"canpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3671,security,log,logical,3671,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3705,security,Session,Session,3705,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3725,security,updat,updated,3725,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:547,testability,Trace,Traceback,547,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1106,testability,log,logging,1106,"eady been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1117,testability,log,logg,1117," reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3214,testability,spy,spyder,3214,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3250,testability,spy,spydercustomize,3250,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3671,testability,log,logical,3671,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:143,usability,confirm,confirmed,143,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:226,usability,confirm,confirmed,226,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:293,usability,Minim,Minimal,293,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:796,usability,tool,tools,796,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:889,usability,tool,tools,889,"conda install -c bioconda anndata2ri breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1034,usability,tool,tools,1034,"breaks import of scanpy; - [x] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda create -n Scanpy python=3.7. conda activate Scanpy. conda install -c bioconda scanpy. conda install -c bioconda anndata2ri. ```. ```. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>. import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>. from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>. from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>. import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>. from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>. from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct. ```. Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3349,usability,tool,toolz,3349,"a remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions. After fixing the issue. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.7.8. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. fsspec 2022.01.0. get_version 3.5.4. h5py 2.10.0. igraph 0.9.9. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. leidenalg 0.8.9. llvmlite 0.37.0. markupsafe 1.1.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.54.1. numexpr 2.8.1. numpy 1.20.3. packaging 21.3. pandas 1.3.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.4. pytz 2021.3. scanpy 1.7.2. scipy 1.7.3. setuptools_scm NA. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. spyder 5.1.5. spyder_kernels 2.1.3. spydercustomize NA. storemagic NA. tables 3.6.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.31.1. jupyter_client 6.1.12. jupyter_core 4.9.1. -----. Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]. Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-03-09 15:40. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2173:246,deployability,modul,module,246,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:337,deployability,modul,module,337,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:584,deployability,modul,module,584,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:851,deployability,modul,module,851,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:939,deployability,log,logging,939,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:950,deployability,log,logg,950,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1081,deployability,modul,module,1081,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1273,deployability,modul,module,1273,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1327,deployability,modul,modules,1327,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1525,deployability,modul,module,1525,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1683,deployability,fail,failed,1683,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1678,energy efficiency,load,load,1678,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1695,interoperability,specif,specified,1695,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:246,modifiability,modul,module,246,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:305,modifiability,pac,packages,305,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:337,modifiability,modul,module,337,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:546,modifiability,pac,packages,546,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:584,modifiability,modul,module,584,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:817,modifiability,pac,packages,817,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:851,modifiability,modul,module,851,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1048,modifiability,pac,packages,1048,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1081,modifiability,modul,module,1081,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1241,modifiability,pac,packages,1241,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1273,modifiability,modul,module,1273,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1327,modifiability,modul,modules,1327,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1497,modifiability,pac,packages,1497,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1525,modifiability,modul,module,1525,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1649,modifiability,paramet,parameters,1649,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1678,performance,load,load,1678,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1683,reliability,fail,failed,1683,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:246,safety,modul,module,246,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:337,safety,modul,module,337,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:584,safety,modul,module,584,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:851,safety,modul,module,851,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:939,safety,log,logging,939,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:950,safety,log,logg,950,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1081,safety,modul,module,1081,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1273,safety,modul,module,1273,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1327,safety,modul,modules,1327,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1345,safety,except,exceptions,1345,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1525,safety,modul,module,1525,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:939,security,log,logging,939,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:950,security,log,logg,950,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:157,testability,Trace,Traceback,157,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:939,testability,log,logging,939,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:950,testability,log,logg,950,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:399,usability,tool,tools,399,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:441,usability,tool,tools,441,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:562,usability,tool,tools,562,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:833,usability,tool,tools,833,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:1298,usability,user,user,1298,"Cannot import Scanpy; ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. ImportError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>. ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>. 13 Verbosity,. 14 ) # start with settings as several tools are using it. ---> 15 from . import tools as tl. 16 from . import preprocessing as pp. 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>. 15 from ._leiden import leiden. 16 from ._louvain import louvain. ---> 17 from ._sim import sim. 18 from ._score_genes import score_genes, score_genes_cell_cycle. 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>. 21 from anndata import AnnData. 22 . ---> 23 from .. import _utils, readwrite, logging as logg. 24 from .._settings import settings. 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>. 8 import pandas as pd. 9 from matplotlib.image import imread. ---> 10 import tables. 11 import anndata. 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>. 40 # Import the user classes from the proper modules. 41 from .exceptions import *. ---> 42 from .file import File, open_file, copy_file. 43 from .node import Node. 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>. 21 import numpy as np. 22 . ---> 23 from . import hdf5extension. 24 from . import utilsextension. 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/pull/2175:110,modifiability,pac,package,110,"Add CIARA algorithm to ecosystem page; As discussed with Isaac today, here's a pull request to list our CIARA package (working with AnnData objects) for rare cell type identification from scRNA-Seq data to the scanpy ecosystem page.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2175
https://github.com/scverse/scanpy/pull/2175:168,security,ident,identification,168,"Add CIARA algorithm to ecosystem page; As discussed with Isaac today, here's a pull request to list our CIARA package (working with AnnData objects) for rare cell type identification from scRNA-Seq data to the scanpy ecosystem page.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2175
https://github.com/scverse/scanpy/pull/2176:433,energy efficiency,model,model,433,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:233,integrability,wrap,wraps,233,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:335,safety,sanit,sanity,335,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:335,security,sanit,sanity,335,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:433,security,model,model,433,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1261,security,modif,modify,1261,"oduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:2178,security,modif,modify,2178,"ure to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](https://user-images.githubusercontent.com/34481813/158408927-c9015300-e4d5-4a62-8653-e608e19969bf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:560,usability,aesthet,aesthetics,560,"Gene selection plot for Pearson Residuals; Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1159,usability,user,user-images,1159,"ll/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1273,usability,aesthet,aesthetics,1273,"e selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1399,usability,user,user-images,1399," used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](http",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1725,usability,user,user-images,1725,"ure to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](https://user-images.githubusercontent.com/34481813/158408927-c9015300-e4d5-4a62-8653-e608e19969bf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:1831,usability,custom,custom,1831,"ure to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](https://user-images.githubusercontent.com/34481813/158408927-c9015300-e4d5-4a62-8653-e608e19969bf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:2076,usability,user,user-images,2076,"ure to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](https://user-images.githubusercontent.com/34481813/158408927-c9015300-e4d5-4a62-8653-e608e19969bf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:2409,usability,user,user-images,2409,"ure to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :). Best,. Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation! ```. import scanpy as sc. sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection. adata=sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells=1). sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot. sc.experimental.pl.pearson_residuals_hvg_scatter(adata). ```. ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```. #modify some aesthetics. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```. #highlight some marker genes. markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]. sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)). ```. ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```. #use custom fields in `adata` for x and y. #(there is also a similar option to use a different field for where HVG flag is stored). sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return_ax=True). ```. ![image](https://user-images.githubusercontent.com/34481813/158408868-c78e8306-bb7c-42d0-8012-ee0700861d7c.png). ```. #modify axis object after `sc.pl.scatter()` ran. ax = sc.experimental.pl.pearson_residuals_hvg_scatter(adata,return_ax=True). ax.set_title('my title'). ax.set_xlabel('my x label'). ax.set_ylabel('my y label'). ```. ![image](https://user-images.githubusercontent.com/34481813/158408927-c9015300-e4d5-4a62-8653-e608e19969bf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2177:97,availability,Ping,Ping,97,Point discourse links to scverse discourse; Updating scanpy discourse links to point at scverse. Ping @adamgayoso .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177
https://github.com/scverse/scanpy/pull/2177:44,deployability,Updat,Updating,44,Point discourse links to scverse discourse; Updating scanpy discourse links to point at scverse. Ping @adamgayoso .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177
https://github.com/scverse/scanpy/pull/2177:44,safety,Updat,Updating,44,Point discourse links to scverse discourse; Updating scanpy discourse links to point at scverse. Ping @adamgayoso .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177
https://github.com/scverse/scanpy/pull/2177:44,security,Updat,Updating,44,Point discourse links to scverse discourse; Updating scanpy discourse links to point at scverse. Ping @adamgayoso .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177
https://github.com/scverse/scanpy/issues/2178:655,availability,down,downloaded,655,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:891,availability,error,errors,891,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:182,deployability,version,version,182,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:941,deployability,log,logging,941,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2398,deployability,scale,scale,2398,"in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2529,deployability,log,log,2529,"ata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3258,deployability,instal,installed,3258,"a). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3306,deployability,instal,install,3306,"ar.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eva",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3344,deployability,Version,Versions,3344,"(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5109,deployability,log,logical,5109,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5163,deployability,updat,updated,5163,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2398,energy efficiency,scale,scale,2398,"in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5117,energy efficiency,CPU,CPU,5117,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5121,energy efficiency,core,cores,5121,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:182,integrability,version,version,182,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3344,integrability,Version,Versions,3344,"(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:182,modifiability,version,version,182,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1264,modifiability,variab,variable,1264,"nch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1280,modifiability,variab,variables-axis,1280," **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2398,modifiability,scal,scale,2398,"in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3344,modifiability,Version,Versions,3344,"(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3676,modifiability,deco,decorator,3676,"P']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:4139,modifiability,pac,packaging,4139,"966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:4987,modifiability,pac,packaged,4987,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:891,performance,error,errors,891,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1303,performance,cach,cache,1303,"ead [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2398,performance,scale,scale,2398,"in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5117,performance,CPU,CPU,5117,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:702,reliability,doe,does,702,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:891,safety,error,errors,891,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:941,safety,log,logging,941,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2529,safety,log,log,2529,"ata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5109,safety,log,logical,5109,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5163,safety,updat,updated,5163,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:941,security,log,logging,941,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2529,security,log,log,2529,"ata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5109,security,log,logical,5109,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5143,security,Session,Session,5143,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5163,security,updat,updated,5163,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:941,testability,log,logging,941,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2529,testability,log,log,2529,"ata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5109,testability,log,logical,5109,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. scanpy 1.7.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.9.3. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.23.2. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. torch 1.11.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-104-generic-x86_64-with-glibc2.10. 24 logical CPU cores, x86_64. -----. Session information updated at 2022-03-15 16:53. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:142,usability,confirm,confirmed,142,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:225,usability,confirm,confirmed,225,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:316,usability,guid,guide,316,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:371,usability,minim,minimal-bug-reports,371,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:477,usability,Minim,Minimal,477,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:891,usability,error,errors,891,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:927,usability,hint,hints,927,"UMAP not producing sensible results on tutorial example. ; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(. 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file. var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index). cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2779,usability,user,user-images,2779,"by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2946,usability,user,user-images,2946,"counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]. adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3106,usability,user,user-images,3106,"a, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:. ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:. ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:. ```sh. conda install -c bioconda scanpy. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.7.8. annoy NA. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. deepMNN NA. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. executing 0.8.3. fbpca NA. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. intervaltree NA. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.3.2. legacy_api_wrap 0.0.0. llvmlite 0.38.0. matplotlib 3.3.2. matplotlib_inline NA. metrics NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/pull/2179:363,energy efficiency,reduc,reductions,363,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:390,energy efficiency,current,current,390,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:529,energy efficiency,optim,optimal,529,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:882,energy efficiency,adapt,adapt,882,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:409,integrability,sub,subsetting,409,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:882,integrability,adapt,adapt,882,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:882,interoperability,adapt,adapt,882,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:822,modifiability,paramet,parameter,822,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:882,modifiability,adapt,adapt,882,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:1147,safety,review,review,1147,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:81,security,team,team,81,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:1147,testability,review,review,1147,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:174,usability,guid,guidelines,174,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:892,usability,document,documentation,892,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:998,usability,guid,guidelines,998,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:1029,usability,guid,guide,1029,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:1125,usability,workflow,workflow,1125,"n_pcs are no longer ignored for representations other than ""X_pca""; Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/issues/2180:16,availability,Cluster,Cluster,16,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:146,availability,cluster,clusters,146,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:16,deployability,Cluster,Cluster,16,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:146,deployability,cluster,clusters,146,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:405,deployability,log,log,405,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:189,energy efficiency,Current,Current,189,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:176,integrability,pub,publication,176,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:392,integrability,pub,publication,392,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:202,reliability,pra,practices,202,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:513,reliability,pra,practice,513,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:405,safety,log,log,405,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:45,security,Team,Team,45,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:405,security,log,log,405,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2180:405,testability,log,log,405,"Data to use for Cluster Markers; Dear scanpy Team,. I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? . Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2181:1029,availability,down,downstream,1029,"in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1809,availability,error,error,1809,"a.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:2629,availability,cluster,clusters,2629,"ithout having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3441,availability,error,error,3441,"']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:186,deployability,version,version,186,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:2629,deployability,cluster,clusters,2629,"ithout having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4335,deployability,log,logreg,4335,"s_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4349,deployability,log,logg,4349,"a, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hyper",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4442,deployability,log,logarithmize,4442,"```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4886,deployability,log,log,4886,"pby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4958,deployability,Version,Versions,4958,", method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6641,deployability,log,logical,6641,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6695,deployability,updat,updated,6695,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6649,energy efficiency,CPU,CPU,6649,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6653,energy efficiency,core,cores,6653,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:186,integrability,version,version,186,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4958,integrability,Version,Versions,4958,", method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:186,modifiability,version,version,186,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:2752,modifiability,layer,layers,2752,"xclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3807,modifiability,pac,packages,3807,"ze_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3998,modifiability,layer,layer,3998,"c.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4261,modifiability,layer,layer,4261,"roduces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4543,modifiability,pac,packages,4543," Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4664,modifiability,layer,layer,4664,"enes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4958,modifiability,Version,Versions,4958,", method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:5230,modifiability,deco,decorator,5230,"upby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:5705,modifiability,pac,packaging,5705,"84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1809,performance,error,error,1809,"a.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3441,performance,error,error,3441,"']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6649,performance,CPU,CPU,6649,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1809,safety,error,error,1809,"a.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1863,safety,test,test,1863,"the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3191,safety,test,test,3191,". sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3221,safety,test,test,3221,"ta_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, group",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3441,safety,error,error,3441,"']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3583,safety,Input,Input,3583,"CellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4335,safety,log,logreg,4335,"s_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4349,safety,log,logg,4349,"a, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hyper",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4442,safety,log,logarithmize,4442,"```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4886,safety,log,log,4886,"pby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6641,safety,log,logical,6641,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6695,safety,updat,updated,6695,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4335,security,log,logreg,4335,"s_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4349,security,log,logg,4349,"a, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hyper",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4442,security,log,logarithmize,4442,"```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4886,security,log,log,4886,"pby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6641,security,log,logical,6641,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6675,security,Session,Session,6675,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6695,security,updat,updated,6695,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1863,testability,test,test,1863,"the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3191,testability,test,test,3191,". sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3221,testability,test,test,3221,"ta_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, group",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3548,testability,Trace,Traceback,3548,"eFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4335,testability,log,logreg,4335,"s_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4349,testability,log,logg,4349,"a, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hyper",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4442,testability,log,logarithmize,4442,"```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4886,testability,log,log,4886,"pby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6641,testability,log,logical,6641,"_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.1.1. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.0. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.28. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scipy 1.8.0. scrublet NA. seaborn 0.11.2. sitecustomize NA. six 1.14.0. skimage 0.19.2. sklearn 1.0.2. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. jupyterlab 3.3.1. notebook 6.4.8. -----. Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]. Linux-5.10.76-linuxkit-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-17 17:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:146,usability,confirm,confirmed,146,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:229,usability,confirm,confirmed,229,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:476,usability,workflow,workflow,476,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:489,usability,confirm,confirmed,489,"Saving/reading .h5ad file results in altered adata.uns['log1p']; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1386,usability,help,help,1386,"ata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1427,usability,guid,guide,1427,"pty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1482,usability,minim,minimal-bug-reports,1482,"firmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1588,usability,Minim,Minimal,1588,"I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellEx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1809,usability,error,error,1809,"a.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice! **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_cells = 1). # scran normalization. adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp, n_comps = 15). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5). input_groups = adata_pp.obs['groups']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3441,usability,error,error,3441,"']. data_mat = adata.X.T. ```. ```python. %%R -i data_mat -i input_groups -o size_factors. size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3583,usability,Input,Input,3583,"CellExperiment(list(counts = data_mat)), . clusters = input_groups, . min.mean = 0.1)). ```. ```python. del adata_pp. adata.obs['size_factors'] = size_factors. adata.layers['counts'] = adata.X.copy(). adata.X /= adata.obs['size_factors'].values[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3823,usability,tool,tools,3823,"lues[:,None]. sc.pp.log1p(adata). adata.X = sp.sparse.csr_matrix(adata.X). adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000). sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). adata.uns['log1p'] # this produces: {'base': None}. adata.write('test.h5ad'). adata = sc.read('test.h5ad'). adata.uns['log1p'] # the now produces: {}. sc.tl.leiden(adata, key_added='leiden_r1.0'). sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error. ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4559,usability,tool,tools,4559,"t recent call last). Input In [13], in <cell line: 2>(). 1 # Calculate marker genes. ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 580 adata.uns[key_added] = {}. 581 adata.uns[key_added]['params'] = dict(. 582 groupby=groupby,. 583 reference=reference,. (...). 587 corr_method=corr_method,. 588 ). --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. 593 logg.warning(. 594 ""It seems you use rank_genes_groups on the raw count data. "". 595 ""Please logarithmize your data before calling rank_genes_groups."". 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 82 def __init__(. 83 self,. 84 adata,. (...). 90 comp_pts=False,. 91 ):. ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. -----. anndata 0.8.0rc1. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 9.0.1. anndata2ri 1.0.6. annoy NA. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.11.0. entrypoints 0.4. executing 0.8.3. get_version 3.5.4. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. markups",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/pull/2183:165,interoperability,specif,specific,165,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:0,modifiability,Inherit,Inherit,0,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:8,modifiability,layer,layer,8,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:174,modifiability,layer,layers,174,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:110,testability,simpl,simple,110,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:110,usability,simpl,simple,110,Inherit layer argument in _highly_variable_genes_single_batch when using sc.pp.highly_variable_genes; Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2184:0,deployability,Updat,Update,0,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:7,deployability,releas,release,7,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:22,deployability,Updat,Updating,22,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:31,deployability,releas,release,31,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:48,deployability,contain,contain,48,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:56,energy efficiency,current,current,56,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:64,reliability,pra,practices,64,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:0,safety,Updat,Update,0,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:22,safety,Updat,Updating,22,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:0,security,Updat,Update,0,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:22,security,Updat,Updating,22,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:15,usability,guid,guide,15,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:39,usability,guid,guide,39,Update release guide; Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2185:136,availability,state,state,136,"Rst to myst; Rst kinda sucks, let's try myst. 🤞. Will probably still need work after merging, but gets most of the docs in a much nicer state.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2185
https://github.com/scverse/scanpy/pull/2185:136,integrability,state,state,136,"Rst to myst; Rst kinda sucks, let's try myst. 🤞. Will probably still need work after merging, but gets most of the docs in a much nicer state.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2185
https://github.com/scverse/scanpy/pull/2186:187,deployability,contain,contains,187,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:217,deployability,resourc,resources,217,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,deployability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:271,deployability,resourc,resource,271,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:302,deployability,contain,contains,302,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:217,energy efficiency,resourc,resources,217,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:271,energy efficiency,resourc,resource,271,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,integrability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,interoperability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:37,modifiability,deco,decoupler,37,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:52,modifiability,pac,packages,52,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:131,modifiability,deco,decoupler,131,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:169,modifiability,deco,decoupler-py,169,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,modifiability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:217,performance,resourc,resources,217,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:271,performance,resourc,resource,271,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,reliability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:217,safety,resourc,resources,217,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:271,safety,resourc,resource,271,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,security,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:217,testability,resourc,resources,217,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:251,testability,integr,integrates,251,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:271,testability,resourc,resource,271,"Change dorothea-py and progeny-py to decoupler; The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2187:103,modifiability,maintain,maintains,103,Cast color vector back to categorical; Fixes #2133. Would be faster if we do the mapping in a may that maintains a categorical array.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2187
https://github.com/scverse/scanpy/pull/2187:103,safety,maintain,maintains,103,Cast color vector back to categorical; Fixes #2133. Would be faster if we do the mapping in a may that maintains a categorical array.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2187
https://github.com/scverse/scanpy/issues/2188:1160,availability,down,downgrade,1160,"on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1344,availability,sli,slightly,1344,"log/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:179,deployability,version,version,179,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:702,deployability,Version,Versions,702,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1139,deployability,instal,installs,1139,"irmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1276,deployability,instal,install,1276,"---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resourc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3029,deployability,log,logical,3029,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3083,deployability,updat,updated,3083,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3037,energy efficiency,CPU,CPU,3037,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3041,energy efficiency,core,cores,3041,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:35,integrability,sub,subsetting,35,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:179,integrability,version,version,179,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:702,integrability,Version,Versions,702,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1037,integrability,discover,discoverable,1037,"ng rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1221,integrability,messag,message,1221,"firmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1037,interoperability,discover,discoverable,1037,"ng rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1221,interoperability,messag,message,1221,"firmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:179,modifiability,version,version,179,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:702,modifiability,Version,Versions,702,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:964,modifiability,pac,package,964,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1089,modifiability,pac,package,1089,"as not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1714,modifiability,deco,decorator,1714,"=1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urll",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:2192,modifiability,pac,packaging,2192,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3037,performance,CPU,CPU,3037,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1344,reliability,sli,slightly,1344,"log/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1120,safety,avoid,avoid,1120,"- [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbforma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1364,safety,review,review,1364,"/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3029,safety,log,logical,3029,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3083,safety,updat,updated,3083,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1605,security,certif,certifi,1605,"aw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3029,security,log,logical,3029,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3063,security,Session,Session,3063,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3083,security,updat,updated,3083,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1364,testability,review,review,1364,"/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3029,testability,log,logical,3029,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-21 23:04]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:139,usability,confirm,confirmed,139,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:222,usability,confirm,confirmed,222,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:313,usability,guid,guide,313,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:368,usability,minim,minimal-bug-reports,368,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:474,usability,Minim,Minimal,474,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:801,usability,learn,learn,801,"Unable to assign .raw object after subsetting rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1037,usability,discov,discoverable,1037,"ng rows; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ncont = ncont[ncont.obs.pct_counts_mt < 5, :]. ncont.raw = ncont. ```. ```pytb. [TypeError: cannot unpack non-iterable NoneType object]. ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2189:221,availability,error,errors,221,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:399,deployability,version,version,399,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:913,deployability,Version,Versions,913,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:962,deployability,log,logging,962,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:399,integrability,version,version,399,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:913,integrability,Version,Versions,913,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:399,modifiability,version,version,399,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:913,modifiability,Version,Versions,913,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:221,performance,error,errors,221,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:221,safety,error,errors,221,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:962,safety,log,logging,962,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:962,security,log,logging,962,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:962,testability,log,logging,962,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:221,usability,error,errors,221,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:253,usability,command,command,253,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:359,usability,confirm,confirmed,359,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:442,usability,confirm,confirmed,442,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:509,usability,Minim,Minimal,509,"Jupyter Notebook vs Python/PyCharm; Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ```python. adata.var['mt'] = adata.var_names.str.startswith('MT-'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ```. ```pytb. TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/pull/2190:189,integrability,repositor,repository,189,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:189,interoperability,repositor,repository,189,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:1332,interoperability,format,formatting,1332,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:1030,safety,valid,valid,1030,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:1036,safety,input,input,1036,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:43,security,hash,hashsolo,43,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:284,security,hash,hashsolo,284,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:1005,security,modif,modified,1005,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/pull/2190:1036,usability,input,input,1036,"Fix default `number_of_noise_barcodes` for hashsolo; It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:. ```python. number_of_non_noise_barcodes = (. num_of_barcodes - number_of_noise_barcodes. if number_of_noise_barcodes is not None. else 2. ). ```. to . ```python. number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes. ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python. if number_of_noise_barcodes >= len(cell_hashing_columns):. ```. changed to. ```python. if (number_of_noise_barcodes is not None) and (. number_of_noise_barcodes >= len(cell_hashing_columns). ):. ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/issues/2191:355,availability,Down,Downgrading,355,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3738,availability,error,errors,3738,"py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _Func",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4302,availability,error,errors,4302,"). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4883,availability,error,errors,4883,"rst, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5439,availability,error,error,5439,"125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6100,availability,state,state,6100,"elf._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6128,availability,state,state,6128," 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6405,availability,state,state,6405,"ine_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6596,availability,state,state,6596,"a/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6710,availability,avail,available,6710,"line_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6911,availability,state,state,6911,"s). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6931,availability,state,state,6931,"ipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7085,availability,state,state,7085,"). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7389,availability,state,state,7389," assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7531,availability,state,state,7531,"ompiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8804,availability,state,state,8804,"pile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8823,availability,state,state,8823,"kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8875,availability,state,state,8875,"**kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8895,availability,state,state,8895,"niconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8915,availability,state,state,8915,"ib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8944,availability,state,state,8944,"umba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look lik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8965,availability,state,state,8965,"chinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10006,availability,operat,operators,10006,".run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10075,availability,operat,operator,10075,"9 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:167,deployability,version,version,167,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,deployability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,deployability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,deployability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5798,deployability,pipelin,pipeline,5798,"ss. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5821,deployability,pipelin,pipeline,5821,"etval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:46",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5933,deployability,pipelin,pipeline,5933,"= e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6351,deployability,pipelin,pipeline,6351,"s, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6720,deployability,pipelin,pipelines,6720,"). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acq",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7104,deployability,Fail,Failed,7104,"ifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 29",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7122,deployability,pipelin,pipeline,7122,"f.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11860,deployability,Fail,Failed,11860,"else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11884,deployability,pipelin,pipeline,11884,"a3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11995,deployability,Version,Versions,11995,", varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13569,deployability,log,logical,13569,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13623,deployability,updat,updated,13623,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3226,energy efficiency,core,core,3226,"NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3560,energy efficiency,core,core,3560,". 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4103,energy efficiency,core,core,4103," ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4423,energy efficiency,core,core,4423,"rting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4709,energy efficiency,core,core,4709,"ple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5005,energy efficiency,core,core,5005,"stance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5601,energy efficiency,core,core,5601,"_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6026,energy efficiency,core,core,6026," in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6258,energy efficiency,core,core,6258,"targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6528,energy efficiency,core,core,6528,"bject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6806,energy efficiency,core,core,6806,"690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7028,energy efficiency,core,core,7028,"/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, inte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7332,energy efficiency,core,core,7332,"Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7660,energy efficiency,core,core,7660,"aise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass wit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7952,energy efficiency,core,core,7952,"465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.meta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8361,energy efficiency,core,core,8361," in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8749,energy efficiency,core,core,8749,"*kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9229,energy efficiency,reduc,reduction,9229,"time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/minicond",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9557,energy efficiency,reduc,reductions,9557,"False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9957,energy efficiency,reduc,reductions,9957,"05 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9996,energy efficiency,reduc,reduction,9996,"arfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10065,energy efficiency,reduc,reduction,10065,"idn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10173,energy efficiency,reduc,reduction,10173,".py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13577,energy efficiency,CPU,CPU,13577,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13581,energy efficiency,core,cores,13581,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:167,integrability,version,version,167,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,integrability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,integrability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,integrability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5798,integrability,pipelin,pipeline,5798,"ss. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5821,integrability,pipelin,pipeline,5821,"etval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:46",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5933,integrability,pipelin,pipeline,5933,"= e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6100,integrability,state,state,6100,"elf._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6128,integrability,state,state,6128," 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6351,integrability,pipelin,pipeline,6351,"s, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6405,integrability,state,state,6405,"ine_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6596,integrability,state,state,6596,"a/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6720,integrability,pipelin,pipelines,6720,"). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acq",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6911,integrability,state,state,6911,"s). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6931,integrability,state,state,6931,"ipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7085,integrability,state,state,7085,"). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7122,integrability,pipelin,pipeline,7122,"f.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7389,integrability,state,state,7389," assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7531,integrability,state,state,7531,"ompiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7775,integrability,wrap,wraps,7775,"hon3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8804,integrability,state,state,8804,"pile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8823,integrability,state,state,8823,"kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8875,integrability,state,state,8875,"**kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8895,integrability,state,state,8895,"niconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8915,integrability,state,state,8915,"ib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8944,integrability,state,state,8944,"umba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look lik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8965,integrability,state,state,8965,"chinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11884,integrability,pipelin,pipeline,11884,"a3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11995,integrability,Version,Versions,11995,", varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,interoperability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,interoperability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,interoperability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2072,interoperability,Standard,Standard,2072,"bs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2629,interoperability,format,format,2629," else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3133,interoperability,format,format,3133,"ile ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13530,interoperability,standard,standard-,13530,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:167,modifiability,version,version,167,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,modifiability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,modifiability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,modifiability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1009,modifiability,pac,packages,1009,"does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1367,modifiability,pac,packages,1367,"ython 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1728,modifiability,pac,packages,1728,"). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1900,modifiability,Paramet,Parameters,1900," ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2183,modifiability,pac,packages,2183," obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2707,modifiability,pac,packages,2707,"/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3211,modifiability,pac,packages,3211,"_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3545,modifiability,pac,packages,3545,"forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4088,modifiability,pac,packages,4088,"2 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4408,modifiability,pac,packages,4408,"is needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4694,modifiability,pac,packages,4694,"lf.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, loca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4990,modifiability,pac,packages,4990,". 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5586,modifiability,pac,packages,5586,"(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5767,modifiability,Paramet,Parameter,5767,"lf, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6011,modifiability,pac,packages,6011,"tcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6243,modifiability,pac,packages,6243,"t,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 rai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6513,modifiability,pac,packages,6513,"gs.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(id",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6791,modifiability,pac,packages,6791,"er pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7013,modifiability,pac,packages,7013,"es/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, ind",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7317,modifiability,pac,packages,7317,"493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7645,modifiability,pac,packages,7645,"e:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7937,modifiability,pac,packages,7937,"s not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8346,modifiability,pac,packages,8346,"inery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8734,modifiability,pac,packages,8734,"lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 35",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9149,modifiability,pac,packages,9149,"tated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9365,modifiability,paramet,parameters,9365,"iler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9450,modifiability,pac,packages,9450," 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9888,modifiability,variab,variables,9888,"7 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10159,modifiability,variab,variable,10159,"/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10267,modifiability,pac,packages,10267,"s:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10618,modifiability,pac,packages,10618,"m). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10921,modifiability,pac,packages,10921,"n make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maxi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11315,modifiability,pac,packages,11315,"_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11618,modifiability,pac,packages,11618,"ages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11995,modifiability,Version,Versions,11995,", varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:12253,modifiability,deco,decorator,12253,"times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:12638,modifiability,pac,packaging,12638,"rfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13433,modifiability,pac,packaged,13433,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3738,performance,error,errors,3738,"py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _Func",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4302,performance,error,errors,4302,"). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4883,performance,error,errors,4883,"rst, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5439,performance,error,error,5439,"125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11258,performance,time,times,11258,"/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorato",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13577,performance,CPU,CPU,13577,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13,reliability,doe,does,13,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,reliability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,reliability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,reliability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6710,reliability,availab,available,6710,"line_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7104,reliability,Fail,Failed,7104,"ifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 29",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11860,reliability,Fail,Failed,11860,"else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:871,safety,Input,Input,871,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:984,safety,test,test,984,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1342,safety,test,test,1342,"thon 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1610,safety,test,test,1610," tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1703,safety,test,test,1703,"-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2158,safety,test,test,2158,"p_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2682,safety,test,test,2682," ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3186,safety,test,test,3186,"ges/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3520,safety,test,test,3520,". 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3731,safety,except,except,3731,"scent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3738,safety,error,errors,3738,"py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _Func",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4063,safety,test,test,4063,"]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4295,safety,except,except,4295,", **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4302,safety,error,errors,4302,"). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4383,safety,test,test,4383," FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4669,safety,test,test,4669,"y:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4876,safety,except,except,4876,"24 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4883,safety,error,errors,4883,"rst, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4965,safety,test,test,4965,"i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5439,safety,error,error,5439,"125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5561,safety,test,test,5561,"tval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5986,safety,test,test,5986,"e-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6218,safety,test,test,6218,"f.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6373,safety,input,input,6373,",. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6488,safety,test,test,6488,"ror is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6710,safety,avail,available,6710,"line_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6766,safety,test,test,6766,"arameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6988,safety,test,test,6988,"/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in Pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7292,safety,test,test,7292,"e._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_stat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7620,safety,test,test,7620," e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should ret",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7912,safety,test,test,7912,"te). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8321,safety,test,test,8321,"es/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8709,safety,test,test,8709,".<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9124,safety,test,test,9124,") as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9220,safety,Valid,Validate,9220," finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9356,safety,Valid,Validate,9356,"/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9425,safety,test,test,9425,"heck(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9968,safety,except,except,9968,"parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_redu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10242,safety,test,test,10242,"rfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10593,safety,test,test,10593,"s, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10896,safety,test,test,10896," in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11290,safety,test,test,11290,"rfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11593,safety,test,test,11593,"st/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13569,safety,log,logical,13569,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13623,safety,updat,updated,13623,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,security,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,security,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,security,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6710,security,availab,available,6710,"line_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9220,security,Validat,Validate,9220," finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9356,security,Validat,Validate,9356,"/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13569,security,log,logical,13569,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13603,security,Session,Session,13603,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13623,security,updat,updated,13623,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:446,testability,Integr,Integrating,446,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:537,testability,integr,integrating-data-using-ingest,537,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:572,testability,Integr,Integrating-data-using-ingest-and-BBKNN,572,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:836,testability,Trace,Traceback,836,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:984,testability,test,test,984,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1342,testability,test,test,1342,"thon 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1610,testability,test,test,1610," tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1703,testability,test,test,1703,"-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2158,testability,test,test,2158,"p_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2682,testability,test,test,2682," ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3186,testability,test,test,3186,"ges/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. --> 967 tree_scores = [. 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3520,testability,test,test,3520,". 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4063,testability,test,test,4063,"]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4383,testability,test,test,4383," FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4669,testability,test,test,4669,"y:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4965,testability,test,test,4965,"i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5561,testability,test,test,5561,"tval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5986,testability,test,test,5986,"e-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6218,testability,test,test,6218,"f.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6393,testability,assert,assert,6393,"s=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6488,testability,test,test,6488,"ror is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6766,testability,test,test,6766,"arameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6988,testability,test,test,6988,"/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in Pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7292,testability,test,test,7292,"e._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_stat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7620,testability,test,test,7620," e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should ret",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7912,testability,test,test,7912,"te). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8114,testability,Simpl,SimpleTimer,8114,"e pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8208,testability,Simpl,SimpleTimer,8208,"_patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8321,testability,test,test,8321,"es/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8709,testability,test,test,8709,".<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8816,testability,assert,assert,8816,"rgs, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9124,testability,test,test,9124,") as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9425,testability,test,test,9425,"heck(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2924 # Validate reduction in parfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10242,testability,test,test,10242,"rfors. 2925 for p in parfors:. -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes). 2928 # Validate parameters:. 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10593,testability,test,test,10593,"s, param_nodes, var_to_param). 3547 if param_name in used_vars and param_name not in reduce_varnames:. 3548 param_nodes[param].reverse(). -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir). 3550 # Certain kinds of ill-formed Python (like potentially undefined. 3551 # variables) in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10896,testability,test,test,10896," in combination with SSA can make things look like. 3552 # reductions except that they don't have reduction operators. 3553 # If we get to this point but don't find a reduction operator. 3554 # then assume it is this situation and just don't treat this. 3555 # variable as a reduction. 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11290,testability,test,test,11290,"rfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir). 3635 defs[lhs.name] = rhs. 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:. -> 3637 rhs = lookup(rhs). 3638 if isinstance(rhs, ir.Expr):. 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11593,testability,test,test,11593,"st/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly). 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. -> 3627 return lookup(val). 3628 else:. 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13569,testability,log,logical,13569,"_reduce_nodes.<locals>.lookup(var, varonly). 3624 def lookup(var, varonly=True):. -> 3625 val = defs.get(var.name, None). 3626 if isinstance(val, ir.Var):. 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors). maximum recursion depth exceeded while calling a Python object. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. anndata 0.8.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. h5py 3.6.0. hypergeom_ufunc NA. igraph 0.9.9. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.0. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2022.1. scanpy 1.8.2. scipy 1.8.0. seaborn 0.11.2. setuptools 60.10.0. sinfo 0.3.1. six 1.16.0. sklearn 1.0.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.63.1. traitlets 5.1.1. typing_extensions NA. umap 0.5.2. wcwidth 0.2.5. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.10. -----. Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]. Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31. 8 logical CPU cores, x86_64. -----. Session information updated at 2022-03-24 22:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:127,usability,confirm,confirmed,127,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:210,usability,confirm,confirmed,210,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:277,usability,Minim,Minimal,277,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:640,usability,user,user-images,640,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:871,usability,Input,Input,871,"sc.tl.ingest does not work with Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1025,usability,tool,tools,1025,"ith Python 3.10 ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1383,usability,tool,tools,1383,"9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb. ---------------------------------------------------------------------------. RecursionError Traceback (most recent call last). Input In [6], in <cell line: 1>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 130 ing.map_embedding(method). 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state). 469 if self._use_pynndescent:. 470 self._nnd_idx.search_rng_state = rng_state. --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 474 else:. 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon). 1564 """"""Query the training graph_data for the k nearest neighbors. 1565 . 1566 Parameters. (...). 1592 training graph_data. 1593 """""". 1594 if not hasattr(self, ""_search_graph""):. -> 1595 self._init_search_graph(). 1597 if not self._is_sparse:. 1598 # Standard case. 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3738,usability,error,errors,3738,"py:968, in <listcomp>(.0). 961 self._search_forest = [. 962 convert_tree_format(tree, self._raw_data.shape[0]). 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _Func",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3847,usability,indicat,indicated,3847," 963 for tree in rp_forest. 964 ]. 965 else:. 966 # convert the best trees into a search forest. 967 tree_scores = [. --> 968 score_linked_tree(tree, self._neighbor_graph[0]). 969 for tree in self._rp_forest. 970 ]. 971 if self.verbose:. 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4302,usability,error,errors,4302,"). 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 486 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 487 raise e. 488 finally:. 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4553,usability,statu,status,4553,"mba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4618,usability,statu,status,4618,"self, *args, **kws). 418 return_val = None. 419 try:. --> 420 return_val = self.compile(tuple(argtypes)). 421 except errors.ForceLiteralArg as e:. 422 # Received request for compiler re-entry with the list of arguments. 423 # indicated by e.requested_args. 424 # First, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4883,usability,error,errors,4883,"rst, check if any of these args are already Literal-ized. 425 already_lit_pos = [i for i in e.requested_args. 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig). 963 with ev.trigger_event(""numba:compile"", data=ev_details):. 964 try:. --> 965 cres = self._compiler.compile(args, return_type). 966 except errors.ForceLiteralArg as e:. 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5439,usability,error,error,5439,"125, in _FunctionCompiler.compile(self, args, return_type). 124 def compile(self, args, return_type):. --> 125 status, retval = self._compile_cached(args, return_type). 126 if status:. 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type). 136 pass. 138 try:. --> 139 retval = self._compile_core(args, return_type). 140 except errors.TypingError as e:. 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type). 149 flags = self._customize_flags(flags). 151 impl = self._get_implementation(args, {}). --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,. 153 self.targetdescr.target_context,. 154 impl,. 155 args=args, return_type=return_type,. 156 flags=flags, locals=self.locals,. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6373,usability,input,input,6373,",. 157 pipeline_class=self.pipeline_class). 158 # Check typing error if object mode is used. 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6602,usability,statu,status,6602,"/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 669 """"""Compiler entry point. 670 . 671 Parameter. (...). 689 compiler pipeline. 690 """""". 691 pipeline = pipeline_class(typingctx, targetctx, library,. 692 args, return_type, flags, locals). --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func). 427 self.state.lifted = (). 428 self.state.lifted_from = None. --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self). 493 """""". 494 Populate and run pipeline for bytecode input. 495 """""". 496 assert self.state.func_ir is None. --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self). 474 self.state.status.fail_reason = e. 475 if is_final_pipeline:. --> 476 raise e. 477 else:. 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self). 461 res = None. 462 try:. --> 463 pm.run(self.state). 464 if self.state.cr is not None:. 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state). 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8114,usability,Simpl,SimpleTimer,8114,"e pipeline (step: %s)"" % \. 351 (self.pipeline_name, pass_desc). 352 patched_exception = self._patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8208,usability,Simpl,SimpleTimer,8208,"_patch_error(msg, e). --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state). 339 pass_inst = _pass_registry.get(pss).pass_inst. 340 if isinstance(pass_inst, CompilerPass):. --> 341 self._runPass(idx, pass_inst, state). 342 else:. 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs). 32 @functools.wraps(func). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state). 294 mutated |= check(pss.run_initialization, internal_state). 295 with SimpleTimer() as pass_time:. --> 296 mutated |= check(pss.run_pass, internal_state). 297 with SimpleTimer() as finalize_time:. 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state). 268 def check(func, compiler_state):. --> 269 mangled = func(compiler_state). 270 if mangled not in (True, False):. 271 msg = (""CompilerPass implementations should return True/False. "". 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state). 295 assert state.func_ir. 296 parfor_pass = _parfor_ParforPass(state.func_ir,. 297 state.typemap,. 298 state.calltypes,. (...). 304 state.metadata,. 305 state.parfor_diagnostics). --> 306 parfor_pass.run(). 308 # check the parfor pass worked and warn if it didn't. 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/pull/2192:0,availability,sla,slack,0,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:38,availability,sla,slack,38,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:16,deployability,Updat,Update,16,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:0,reliability,sla,slack,0,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:38,reliability,sla,slack,38,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:16,safety,Updat,Update,16,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/pull/2192:16,security,Updat,Update,16,slack -> zulip; Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/issues/2193:0,availability,Error,Error,0,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1098,availability,down,downgrade,1098,"been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1282,availability,sli,slightly,1282,"**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:174,deployability,version,version,174,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:627,deployability,automat,automatically,627,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:776,deployability,contain,contains,776,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:805,deployability,Version,Versions,805,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1077,deployability,instal,installs,1077,"issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1214,deployability,instal,install,1214,"onfirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3273,deployability,log,logical,3273,"n_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. openpyxl 3.0.9. opt_einsum v3.3.0. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. wrapt 1.14.0. xlrd 1.2.0. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-26 18:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3327,deployability,updat,updated,3327,"n_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. openpyxl 3.0.9. opt_einsum v3.3.0. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. wrapt 1.14.0. xlrd 1.2.0. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-26 18:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3281,energy efficiency,CPU,CPU,3281,"n_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. openpyxl 3.0.9. opt_einsum v3.3.0. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. wrapt 1.14.0. xlrd 1.2.0. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-26 18:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3285,energy efficiency,core,cores,3285,"n_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. openpyxl 3.0.9. opt_einsum v3.3.0. packaging 21.3. pandas 1.3.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.6. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.26.0. scipy 1.7.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. statsmodels 0.13.2. storemagic NA. tables 3.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. terminado 0.11.1. texttable 1.6.4. tornado 6.1. tqdm 4.63.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.2. urllib3 1.26.6. wcwidth 0.2.5. websocket 1.2.1. wrapt 1.14.0. xlrd 1.2.0. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.1.7. notebook 6.4.3. -----. Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17. 36 logical CPU cores, x86_64. -----. Session information updated at 2022-03-26 18:52. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:174,integrability,version,version,174,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:609,integrability,sub,subset,609,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:641,integrability,sub,subset,641,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:805,integrability,Version,Versions,805,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:975,integrability,discover,discoverable,975,"Error in sc.pp.highly_variable_genes function; - [ Yes] I have checked that this issue has not already been reported. - [ Yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1159,integrability,messag,message,1159,"the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. ncase,. n_top_genes=3000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat"". ). ```. ```pytb. ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 8.3.1. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anyio NA. astunparse 1.6.3. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. celltypist 0.2.0. certifi 2021.05.30. cffi 1.14.6. charset_normalizer 2.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. entrypoints 0.3. et_xmlfile 1.1.0. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.3.0. idna 3.2. igraph 0.9.9. ipykernel 6.2.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 3.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.10.2. jupyterlab_server 2.7.1. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.0.1. matplotlib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
