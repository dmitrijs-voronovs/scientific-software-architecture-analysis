id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/11:138,availability,reliab,reliable,138,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:348,performance,content,content,348,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:416,performance,content,content,416,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:138,reliability,reliab,reliable,138,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:166,safety,detect,detecting,166,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:166,security,detect,detecting,166,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:45,usability,experien,experience,45,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:210,availability,operat,operate,210,"Yes, it seems better to specify the number of branches manually. I have tried Monocle 2 though, which gives about 10 branches for the example dataset from Moignard et al., Nat. Biotechn. (2015). Maybe I didn't operate Monocle 2 properly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:24,interoperability,specif,specify,24,"Yes, it seems better to specify the number of branches manually. I have tried Monocle 2 though, which gives about 10 branches for the example dataset from Moignard et al., Nat. Biotechn. (2015). Maybe I didn't operate Monocle 2 properly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:72,reliability,doe,doesn,72,"Thanks for the feedback! It astonishes me a bit, though, that Monocle 2 doesn't work well on that example. For the Paul et al, Cell (2015), it should give very nice results ([link to preprocessing](https://github.com/theislab/scanpy/blob/a2a330fa4640fdd4847fb48970a743242936e1df/scanpy/examples/builtin.py#L183-L199) / [link to plots](https://github.com/theislab/scanpy_usage/blob/master/EXAMPLES.md#paul15)), as they show in the recent preprint I reference above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:15,usability,feedback,feedback,15,"Thanks for the feedback! It astonishes me a bit, though, that Monocle 2 doesn't work well on that example. For the Paul et al, Cell (2015), it should give very nice results ([link to preprocessing](https://github.com/theislab/scanpy/blob/a2a330fa4640fdd4847fb48970a743242936e1df/scanpy/examples/builtin.py#L183-L199) / [link to plots](https://github.com/theislab/scanpy_usage/blob/master/EXAMPLES.md#paul15)), as they show in the recent preprint I reference above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:18,integrability,abstract,abstraction,18,The approx. graph abstraction (AGA) tool resolves this issue: https://doi.org/10.1101/208819 and https://github.com/theislab/graph_abstraction.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:18,modifiability,abstract,abstraction,18,The approx. graph abstraction (AGA) tool resolves this issue: https://doi.org/10.1101/208819 and https://github.com/theislab/graph_abstraction.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/11:36,usability,tool,tool,36,The approx. graph abstraction (AGA) tool resolves this issue: https://doi.org/10.1101/208819 and https://github.com/theislab/graph_abstraction.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11
https://github.com/scverse/scanpy/issues/19:6,energy efficiency,cool,cool,6,Seems cool to me. Let's give this a try as soon as there's a little bit of time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:75,performance,time,time,75,Seems cool to me. Let's give this a try as soon as there's a little bit of time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:91,energy efficiency,adapt,adapting,91,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:91,integrability,adapt,adapting,91,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:91,interoperability,adapt,adapting,91,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:21,modifiability,extens,extensions,21,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:91,modifiability,adapt,adapting,91,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:114,testability,context,context,114,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/issues/19:47,usability,close,close,47,"As we don't have any extensions anymore we can close this for now. Also, many people start adapting numba. In the context of Scanpy this should usually be enough... let's talk again in case we need it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/19
https://github.com/scverse/scanpy/pull/20:101,deployability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:362,deployability,modul,modules,362,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:424,deployability,stack,stackoverflow,424,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,integrability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,interoperability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:201,interoperability,distribut,distributions,201,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:342,interoperability,distribut,distributing,342,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,modifiability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:117,modifiability,extens,extensions,117,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:362,modifiability,modul,modules,362,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:168,performance,overhead,overhead,168,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,reliability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:362,safety,modul,modules,362,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,security,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:89,testability,plan,planning,89,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/pull/20:101,testability,integr,integrating,101,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20
https://github.com/scverse/scanpy/issues/25:611,energy efficiency,reduc,reducing,611,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:867,energy efficiency,reduc,reduce,867,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:524,modifiability,variab,variable,524,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:808,reliability,doe,does,808,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:183,security,sign,significant,183,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:114,usability,person,personal,114,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:797,usability,experien,experience,797,"No, there is no way within Scanpy. I'll talk to Philipp about the find_sigmas function... and get back to you. My personal opinion is that in a wide range of values, the qualitative (significant) results should be independent of the value of k. The default value of k=30, meaning that we construct a k-nearest neighbor graph in which each cell is connected with 30 neighbors, yields good results on all data sets (>10) that I worked with so far. If you have very little noise, for example, by selecting only very few highly variable genes in the preprocessing, you might obtain a more ""pronounced structure"" by reducing k (I'd recommend at least 3, though). Also with very noisy data, k=30 should be high enough to average out noise effects. To summarize, k=30 is a conservative choice that in my experience does the job for everything. In some cases, it pays off to reduce the value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:0,energy efficiency,Cool,Cool,0,"Cool thanks! Also, are there any ways to combine multiple adatas or read multiple csv files?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:143,testability,simpl,simply,143,"No, not right now. You have to do this with numpy or pandas. adata is just a collection of numpy arrays and a dict (`print(adata)`) So you can simply do this manually. If you explain in a more detailed way what you want, I can probably also quickly implement it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:143,usability,simpl,simply,143,"No, not right now. You have to do this with numpy or pandas. adata is just a collection of numpy arrays and a dict (`print(adata)`) So you can simply do this manually. If you explain in a more detailed way what you want, I can probably also quickly implement it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:193,performance,time,time,193,"Basically, I have multiple CSV files, and I would like to run dpt on all of the csv file combined. At the moment, I'm manually copying them and feeding it into a new CSV. However, that is very time consuming and my data is quite large. So, I'm wondering if there is a way to systematically handle multiple CSV files and run a single dpt on all of them. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:16,modifiability,paramet,parameter,16,"Also, there the parameter n_dcs is not documented in the dpt script. Will changing this parameter yield better results? Or should I just stay with the default 10?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:88,modifiability,paramet,parameter,88,"Also, there the parameter n_dcs is not documented in the dpt script. Will changing this parameter yield better results? Or should I just stay with the default 10?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:39,usability,document,documented,39,"Also, there the parameter n_dcs is not documented in the dpt script. Will changing this parameter yield better results? Or should I just stay with the default 10?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:135,energy efficiency,current,current,135,"Regarding `n_dcs`. It's not a ""user parameter"", just stick with the default value. Changing it reasonably won't have any effect, is my current take on it. I've never done production calculation with another value. Regarding multiple csv files: each of these files is a n_sample x n_genes table? Or transposed? I could easily write something that concatenates these tables, sure! I hope I find time for it within the next 7 days or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:36,modifiability,paramet,parameter,36,"Regarding `n_dcs`. It's not a ""user parameter"", just stick with the default value. Changing it reasonably won't have any effect, is my current take on it. I've never done production calculation with another value. Regarding multiple csv files: each of these files is a n_sample x n_genes table? Or transposed? I could easily write something that concatenates these tables, sure! I hope I find time for it within the next 7 days or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:393,performance,time,time,393,"Regarding `n_dcs`. It's not a ""user parameter"", just stick with the default value. Changing it reasonably won't have any effect, is my current take on it. I've never done production calculation with another value. Regarding multiple csv files: each of these files is a n_sample x n_genes table? Or transposed? I could easily write something that concatenates these tables, sure! I hope I find time for it within the next 7 days or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:31,usability,user,user,31,"Regarding `n_dcs`. It's not a ""user parameter"", just stick with the default value. Changing it reasonably won't have any effect, is my current take on it. I've never done production calculation with another value. Regarding multiple csv files: each of these files is a n_sample x n_genes table? Or transposed? I could easily write something that concatenates these tables, sure! I hope I find time for it within the next 7 days or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:26,integrability,rout,route,26,"Just in general: the main route to ""improving the results"" is to make sure that your preprocessing yields a meaningful tSNE for the standard parameters. Then also DPT will perfectly do its job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:132,interoperability,standard,standard,132,"Just in general: the main route to ""improving the results"" is to make sure that your preprocessing yields a meaningful tSNE for the standard parameters. Then also DPT will perfectly do its job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:141,modifiability,paramet,parameters,141,"Just in general: the main route to ""improving the results"" is to make sure that your preprocessing yields a meaningful tSNE for the standard parameters. Then also DPT will perfectly do its job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:429,energy efficiency,current,currently,429,"Okay, so run tSNE first. If it yields meaningful results, then DPT will do fine? So, we don't need to play around with the DPT parameters at all? By preprocessing, you mean like gene filtering, normalization, etc? Also, the CSV files are in n_sample x n_genes, but ideally, it would be great if we could combine multiple adata together, so we can transpose it ourselves (and other preprocessing), if we need to. Thanks! P.S. I'm currently running DPT with n_pcs=0, so no dimension reduction with PCA. Not sure if this is good or not.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:481,energy efficiency,reduc,reduction,481,"Okay, so run tSNE first. If it yields meaningful results, then DPT will do fine? So, we don't need to play around with the DPT parameters at all? By preprocessing, you mean like gene filtering, normalization, etc? Also, the CSV files are in n_sample x n_genes, but ideally, it would be great if we could combine multiple adata together, so we can transpose it ourselves (and other preprocessing), if we need to. Thanks! P.S. I'm currently running DPT with n_pcs=0, so no dimension reduction with PCA. Not sure if this is good or not.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:183,integrability,filter,filtering,183,"Okay, so run tSNE first. If it yields meaningful results, then DPT will do fine? So, we don't need to play around with the DPT parameters at all? By preprocessing, you mean like gene filtering, normalization, etc? Also, the CSV files are in n_sample x n_genes, but ideally, it would be great if we could combine multiple adata together, so we can transpose it ourselves (and other preprocessing), if we need to. Thanks! P.S. I'm currently running DPT with n_pcs=0, so no dimension reduction with PCA. Not sure if this is good or not.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:127,modifiability,paramet,parameters,127,"Okay, so run tSNE first. If it yields meaningful results, then DPT will do fine? So, we don't need to play around with the DPT parameters at all? By preprocessing, you mean like gene filtering, normalization, etc? Also, the CSV files are in n_sample x n_genes, but ideally, it would be great if we could combine multiple adata together, so we can transpose it ourselves (and other preprocessing), if we need to. Thanks! P.S. I'm currently running DPT with n_pcs=0, so no dimension reduction with PCA. Not sure if this is good or not.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:157,energy efficiency,reduc,reducing,157,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:331,integrability,filter,filtering,331,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:342,integrability,batch,batch,342,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:43,modifiability,paramet,parameters,43,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:342,performance,batch,batch,342,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:413,reliability,doe,does,413,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:196,safety,except,except,196,"You don't need to play around with the DPT parameters at all. You should definitely run it with `n_pcs = 50` (the default value). In some cases, it pays off reducing this. But in almost no cases (except if you have very low dimensional data, for example, from qPCR) it's meaningful to set `n_pcs = 0`. By preprocessing I mean gene filtering, batch correction and normalization (e.g. `sc.pp.recipe_zheng17(adata)` does everything, or see the Seurat example).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:118,integrability,filter,filtering,118,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:225,reliability,doe,doesn,225,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:74,testability,understand,understanding,74,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:28,usability,help,help,28,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:364,usability,experien,experience,364,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:513,usability,user,user-images,513,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:629,usability,user,user-images,629,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:794,usability,user,user-images,794,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:909,usability,user,user-images,909,"Thank you very much for the help! Sorry to bother you further, but if I'm understanding filter_gene_dispersion, it is filtering out the highly varying genes. Why would you want to do that? Don't you want to remove genes that doesn't vary and keep the ones that vary a lot because you would think they play a role in cell differentiation? . Also, I don't have much experience with t-SNE. How can we tell if our t-SNE is meaningful? . For example, this data set has an excellent DPT result. t-sne. ![tsne2](https://user-images.githubusercontent.com/23245419/27449211-8e39fa20-5755-11e7-9ef2-175626549800.png). dpt. ![dpt2](https://user-images.githubusercontent.com/23245419/27449233-9cfbc3fe-5755-11e7-84f8-9e98d88308e7.png). meanwhile this data set has no branches at all. tsne. ![tsne](https://user-images.githubusercontent.com/23245419/27449514-abdd1192-5756-11e7-956e-0a702bb51fa4.png). dpt. ![dpt](https://user-images.githubusercontent.com/23245419/27449525-b35f817a-5756-11e7-9499-4b3a79d61dfb.png). Is there anything in particular I should look for? Thanks! P.S. my dpt runs faster than tSNE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:122,availability,cluster,cluster,122,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:170,availability,cluster,clustered,170,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:122,deployability,cluster,cluster,122,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:170,deployability,cluster,clustered,170,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:265,reliability,doe,doesn,265,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:258,testability,simpl,simply,258,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:258,usability,simpl,simply,258,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:441,usability,visual,visualization,441,"The tSNE looks ""good"" if parts of the data that you expect to be connected actually look connected in the tSNE and do not cluster apart. In your case, it looks a bit too clustered, but seeing the DiffMaps, everything turns out to be fine. The second example simply doesn't seem to have a branching. PS: There will soon be a new default tSNE that will ensure that the correspondence between DiffMap and tSNE is better. Still, of course, both visualization methods focus on different aspects of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:90,availability,error,error,90,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:193,availability,error,error,193,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:39,deployability,fail,fails,39,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:90,performance,error,error,90,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:193,performance,error,error,193,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:39,reliability,fail,fails,39,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:505,reliability,Doe,Does,505,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:90,safety,error,error,90,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:193,safety,error,error,193,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:459,security,sign,significant,459,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:90,usability,error,error,90,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:193,usability,error,error,193,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```. scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:. No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:156,deployability,toggl,toggleswitch,156,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:379,energy efficiency,adapt,adapt,379,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:379,integrability,adapt,adapt,379,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:379,interoperability,adapt,adapt,379,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:379,modifiability,adapt,adapt,379,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:389,modifiability,paramet,parameters,389,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:731,modifiability,variab,variabale,731,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:200,reliability,Doe,Does,200,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:317,security,sign,significant,317,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:541,testability,simpl,simple,541,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:691,testability,simpl,simply,691,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:541,usability,simpl,simple,541,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/25:691,usability,simpl,simply,691,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25
https://github.com/scverse/scanpy/issues/28:80,modifiability,pac,packages,80,"fixed, thanks. seems like Bioconductor has turned off the mirror, but put their packages in a github organization",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/28
https://github.com/scverse/scanpy/issues/29:31,usability,minim,minimal,31,Just use `pip` as comes with a minimal conda environment (see `conda list`) and follow the steps in the README. I myself am also using anaconda on many occasions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:81,testability,simpl,simply,81,"PS: If you have a conda environment for Python 3, you do not need to use `pip3`; simply use `pip`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:81,usability,simpl,simply,81,"PS: If you have a conda environment for Python 3, you do not need to use `pip3`; simply use `pip`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:94,security,Hash,Hashem,94,"Hi Alex,. Thanks for your very prompt reply. The problem is solved. Looking forward using it. Hashem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:98,deployability,continu,continuum,98,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:151,deployability,instal,installable,151,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:316,deployability,instal,install,316,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:475,deployability,instal,installing,475,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:226,integrability,event,eventually,226,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:542,integrability,event,eventually,542,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:142,modifiability,pac,packages,142,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:328,modifiability,pac,packages,328,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:352,modifiability,pac,package,352,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:461,modifiability,pac,packages,461,"hi, sorry for the confusion. i removed the comments not relevant to the issue. for the record:. - continuum inc. is responsible for providing packages installable with `conda`, we cant influence that IIRC. they will probably eventually include scanpy. - python comes with `pip` by default, and `pip` can be used to install all packages on [the python package index](https://pypi.python.org). - the only advantage of anaconda is that it comes with preinstalled packages, but installing scanpy via `pip` will always be just as fast as it will eventually be with `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/29:111,interoperability,distribut,distribute,111,"Hi guys,. Scanpy is really awesome and fast !! Just wanted to add here Bioconda could be an alternative way to distribute scanpy but pip too works just fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29
https://github.com/scverse/scanpy/issues/32:63,deployability,instal,install,63,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:80,deployability,releas,release,80,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:120,deployability,instal,install,120,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:438,deployability,build,building,438,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:508,deployability,build,builds,508,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:141,energy efficiency,current,currently,141,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:167,integrability,sub,substantial,167,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:267,modifiability,extens,extensive,267,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:310,reliability,doe,does,310,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:241,safety,test,testing,241,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:241,testability,test,testing,241,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:202,usability,clear,clearly,202,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:453,usability,document,documentation,453,"Hi Sarah,. thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... . Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:27,deployability,version,version,27,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:58,deployability,instal,install,58,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:19,energy efficiency,current,current,19,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:27,integrability,version,version,27,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/32:27,modifiability,version,version,27,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32
https://github.com/scverse/scanpy/issues/34:70,availability,error,error,70,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:50,deployability,fail,fails,50,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:70,performance,error,error,70,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:50,reliability,fail,fails,50,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:70,safety,error,error,70,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:70,usability,error,error,70,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section . ### Using a preprocessing recipe. adata = paul15_raw(). sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:71,deployability,build,build,71,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:37,integrability,sub,substantial,37,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:341,reliability,doe,doesn,341,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:241,safety,test,tests,241,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:297,safety,test,tests,297,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:241,testability,test,tests,241,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:297,testability,test,tests,297,"Hi Alexis,. sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:44,deployability,releas,release,44,"I let you know as soon as there is a stable release back on github. 0.2.5 should be stable [as well](https://github.com/theislab/scanpy_usage), but has some other drawbacks. Things are still progressing fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:163,energy efficiency,draw,drawbacks,163,"I let you know as soon as there is a stable release back on github. 0.2.5 should be stable [as well](https://github.com/theislab/scanpy_usage), but has some other drawbacks. Things are still progressing fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:191,usability,progress,progressing,191,"I let you know as soon as there is a stable release back on github. 0.2.5 should be stable [as well](https://github.com/theislab/scanpy_usage), but has some other drawbacks. Things are still progressing fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:502,deployability,fail,fails,502,"Thanks @falexwolf . I have fixed my local file with. ~ln 209. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_mean_bin[df['mean_bin'].values].values) / disp_std_bin[df['mean_bin'].values].values. ```. and. ~ln 220. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_median_bin[df['mean_bin'].values].values) / disp_mad_bin[df['mean_bin'].values].values. ```. Also plot=True . ```. afilter = sc.pp.recipe_zheng17(a, n_top_genes=1000, zero_center=True, plot=True, copy=True). ```. fails with. ```. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:535,deployability,modul,module,535,"Thanks @falexwolf . I have fixed my local file with. ~ln 209. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_mean_bin[df['mean_bin'].values].values) / disp_std_bin[df['mean_bin'].values].values. ```. and. ~ln 220. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_median_bin[df['mean_bin'].values].values) / disp_mad_bin[df['mean_bin'].values].values. ```. Also plot=True . ```. afilter = sc.pp.recipe_zheng17(a, n_top_genes=1000, zero_center=True, plot=True, copy=True). ```. fails with. ```. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:535,modifiability,modul,module,535,"Thanks @falexwolf . I have fixed my local file with. ~ln 209. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_mean_bin[df['mean_bin'].values].values) / disp_std_bin[df['mean_bin'].values].values. ```. and. ~ln 220. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_median_bin[df['mean_bin'].values].values) / disp_mad_bin[df['mean_bin'].values].values. ```. Also plot=True . ```. afilter = sc.pp.recipe_zheng17(a, n_top_genes=1000, zero_center=True, plot=True, copy=True). ```. fails with. ```. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:502,reliability,fail,fails,502,"Thanks @falexwolf . I have fixed my local file with. ~ln 209. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_mean_bin[df['mean_bin'].values].values) / disp_std_bin[df['mean_bin'].values].values. ```. and. ~ln 220. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_median_bin[df['mean_bin'].values].values) / disp_mad_bin[df['mean_bin'].values].values. ```. Also plot=True . ```. afilter = sc.pp.recipe_zheng17(a, n_top_genes=1000, zero_center=True, plot=True, copy=True). ```. fails with. ```. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:535,safety,modul,module,535,"Thanks @falexwolf . I have fixed my local file with. ~ln 209. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_mean_bin[df['mean_bin'].values].values) / disp_std_bin[df['mean_bin'].values].values. ```. and. ~ln 220. ```. df['dispersion_norm'] = (df['dispersion'].values - disp_median_bin[df['mean_bin'].values].values) / disp_mad_bin[df['mean_bin'].values].values. ```. Also plot=True . ```. afilter = sc.pp.recipe_zheng17(a, n_top_genes=1000, zero_center=True, plot=True, copy=True). ```. fails with. ```. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:44,safety,test,tests,44,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:73,safety,test,tests,73,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:125,safety,test,testing,125,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:44,testability,test,tests,44,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:73,testability,test,tests,73,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:125,testability,test,testing,125,You could use the notebooks as part of your tests - see [GPflow notebook tests](https://github.com/GPflow/GPflow/blob/master/testing/test_notebooks.py) as an example.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:263,deployability,version,version,263,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:274,deployability,version,version,274,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:263,integrability,version,version,263,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:274,integrability,version,version,274,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:263,modifiability,version,version,263,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:274,modifiability,version,version,274,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:123,performance,time,time,123,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:163,performance,time,time,163,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:297,safety,test,testable,297,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:297,testability,test,testable,297,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:223,usability,visual,visual,223,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:164,deployability,version,version,164,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:377,deployability,version,version,377,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:164,integrability,version,version,164,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:377,integrability,version,version,377,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:164,modifiability,version,version,164,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:377,modifiability,version,version,377,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:296,usability,experien,experience,296,"Now, there is a nice overview of all examples [here](https://scanpy.readthedocs.io/en/latest/examples.html). Also, I ran through all example notebooks with the new version 0.2.7 just now: https://github.com/theislab/scanpy_usage and it worked; unfortunately, going through all examples, I didn't experience the bug that you are reporting. Are you maybe using a very old Pandas version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:83,deployability,api,api,83,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:121,deployability,modul,module,121,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:158,deployability,API,API,158,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:203,deployability,api,api,203,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:247,deployability,modul,module,247,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:309,deployability,api,api,309,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:83,integrability,api,api,83,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:158,integrability,API,API,158,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:203,integrability,api,api,203,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:309,integrability,api,api,309,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:83,interoperability,api,api,83,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:158,interoperability,API,API,158,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:203,interoperability,api,api,203,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:309,interoperability,api,api,309,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:121,modifiability,modul,module,121,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:247,modifiability,modul,module,247,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:121,safety,modul,module,121,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:247,safety,modul,module,247,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:333,safety,avoid,avoid,333,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:103,testability,simpl,simply,103,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:103,usability,simpl,simply,103,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:30,availability,error,error,30,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:342,deployability,version,versions,342,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:402,deployability,version,version,402,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:342,integrability,version,versions,342,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:402,integrability,version,version,402,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:342,modifiability,version,versions,342,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:402,modifiability,version,version,402,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:20,performance,time,time,20,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:30,performance,error,error,30,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:30,safety,error,error,30,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:637,testability,simpl,simple,637,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:30,usability,error,error,30,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/34:637,usability,simpl,simple,637,"OK; now I have more time. The error thrown at . ```. 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs. --> 208 - disp_mean_bin[df['mean_bin']].values) \. 209 / disp_std_bin[df['mean_bin']].values. ```. astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34
https://github.com/scverse/scanpy/issues/36:5,energy efficiency,cool,cool,5,Very cool that this works! :smile:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/36
https://github.com/scverse/scanpy/pull/38:27,availability,slo,slowly,27,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38
https://github.com/scverse/scanpy/pull/38:42,performance,time,time,42,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38
https://github.com/scverse/scanpy/pull/38:27,reliability,slo,slowly,27,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38
https://github.com/scverse/scanpy/pull/38:136,safety,test,test,136,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38
https://github.com/scverse/scanpy/pull/38:136,testability,test,test,136,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38
https://github.com/scverse/scanpy/issues/39:91,deployability,version,version,91,"Hi and sorry for the very late response! 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/39:305,deployability,instal,installing,305,"Hi and sorry for the very late response! 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/39:91,integrability,version,version,91,"Hi and sorry for the very late response! 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/39:91,modifiability,version,version,91,"Hi and sorry for the very late response! 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/39:371,usability,experien,experience,371,"Hi and sorry for the very late response! 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/39:0,energy efficiency,Cool,Cool,0,Cool! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39
https://github.com/scverse/scanpy/issues/40:64,deployability,releas,release,64,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:458,deployability,releas,release,458,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:474,energy efficiency,schedul,scheduled,474,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:25,integrability,abstract,abstraction,25,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:313,interoperability,format,format,313,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:25,modifiability,abstract,abstraction,25,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:474,performance,schedul,scheduled,474,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:381,reliability,doe,doesn,381,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:398,safety,test,tests,398,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:105,testability,simpl,simply,105,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:398,testability,test,tests,398,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:105,usability,simpl,simply,105,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/40:125,usability,minim,minimal,125,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,. alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40
https://github.com/scverse/scanpy/issues/41:49,energy efficiency,Current,Currently,49,"OK! We will try to add this as soon as possible. Currently, you can work around this by adding all genes that you find interesting as annotation, for example, following code similar to. ```. # TC (Nat Im review 2014 Yui). tc_surface_receptors = ['Flt3', 'Cd44', 'Il2ra', 'Il7r', 'Cd3e', 'Cd4', 'Cd8a']. tc_markers = [. 'Gata2', 'Hoxa9', 'Meis1', 'Lmo2', 'Mef2c', 'Gfi1b', 'Lyl1', 'Spi1', 'Bcl11a', 'Hhex', 'Mycn', 'Erg', 'Tcf3',. 'Ikzf1', 'Tcf12', 'Notch1', 'Runx1', 'Gfi1', 'Myb', 'Myc', 'Gata3', 'Tcf7', 'Ets1', 'Hes1', 'Ahr', 'Tcf12',. 'Bcl11b', 'Notch3', 'Spib', 'Ets2', 'Lef1', 'Rorc', 'Id3',. ]. # DC, NK (Abcam poster). dc_markers = ['Itgax', 'Cd24a', 'Ptprc']. nk_markers = ['Itgam', 'Il2rb', 'Klrb1', 'Ncr1']. all_markers = tc_surface_receptors + tc_markers + dc_markers + nk_markers. adata.smp[all_markers] = adata[:, all_markers].X. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:204,safety,review,review,204,"OK! We will try to add this as soon as possible. Currently, you can work around this by adding all genes that you find interesting as annotation, for example, following code similar to. ```. # TC (Nat Im review 2014 Yui). tc_surface_receptors = ['Flt3', 'Cd44', 'Il2ra', 'Il7r', 'Cd3e', 'Cd4', 'Cd8a']. tc_markers = [. 'Gata2', 'Hoxa9', 'Meis1', 'Lmo2', 'Mef2c', 'Gfi1b', 'Lyl1', 'Spi1', 'Bcl11a', 'Hhex', 'Mycn', 'Erg', 'Tcf3',. 'Ikzf1', 'Tcf12', 'Notch1', 'Runx1', 'Gfi1', 'Myb', 'Myc', 'Gata3', 'Tcf7', 'Ets1', 'Hes1', 'Ahr', 'Tcf12',. 'Bcl11b', 'Notch3', 'Spib', 'Ets2', 'Lef1', 'Rorc', 'Id3',. ]. # DC, NK (Abcam poster). dc_markers = ['Itgax', 'Cd24a', 'Ptprc']. nk_markers = ['Itgam', 'Il2rb', 'Klrb1', 'Ncr1']. all_markers = tc_surface_receptors + tc_markers + dc_markers + nk_markers. adata.smp[all_markers] = adata[:, all_markers].X. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:204,testability,review,review,204,"OK! We will try to add this as soon as possible. Currently, you can work around this by adding all genes that you find interesting as annotation, for example, following code similar to. ```. # TC (Nat Im review 2014 Yui). tc_surface_receptors = ['Flt3', 'Cd44', 'Il2ra', 'Il7r', 'Cd3e', 'Cd4', 'Cd8a']. tc_markers = [. 'Gata2', 'Hoxa9', 'Meis1', 'Lmo2', 'Mef2c', 'Gfi1b', 'Lyl1', 'Spi1', 'Bcl11a', 'Hhex', 'Mycn', 'Erg', 'Tcf3',. 'Ikzf1', 'Tcf12', 'Notch1', 'Runx1', 'Gfi1', 'Myb', 'Myc', 'Gata3', 'Tcf7', 'Ets1', 'Hes1', 'Ahr', 'Tcf12',. 'Bcl11b', 'Notch3', 'Spib', 'Ets2', 'Lef1', 'Rorc', 'Id3',. ]. # DC, NK (Abcam poster). dc_markers = ['Itgax', 'Cd24a', 'Ptprc']. nk_markers = ['Itgam', 'Il2rb', 'Klrb1', 'Ncr1']. all_markers = tc_surface_receptors + tc_markers + dc_markers + nk_markers. adata.smp[all_markers] = adata[:, all_markers].X. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:15,integrability,pub,publish,15,"Do you plan to publish scanpy on a high impact factor journal later? Some people argue that bioAxiv is not a serious journal and we are a little worried. After all, it will take us much time to follow scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:186,performance,time,time,186,"Do you plan to publish scanpy on a high impact factor journal later? Some people argue that bioAxiv is not a serious journal and we are a little worried. After all, it will take us much time to follow scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:7,testability,plan,plan,7,"Do you plan to publish scanpy on a high impact factor journal later? Some people argue that bioAxiv is not a serious journal and we are a little worried. After all, it will take us much time to follow scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:67,energy efficiency,current,currently,67,Scanpy will very soon be published in a high impact journal (we're currently in the revision). I'll let you know about this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:25,integrability,pub,published,25,Scanpy will very soon be published in a high impact journal (we're currently in the revision). I'll let you know about this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:117,deployability,version,versions,117,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:263,deployability,version,version,263,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:338,deployability,log,logarithm,338,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:539,deployability,version,versions,539,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:807,deployability,version,versions,807,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:103,energy efficiency,load,load,103,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:117,integrability,version,versions,117,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:263,integrability,version,version,263,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:303,integrability,filter,filtering,303,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:539,integrability,version,versions,539,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:807,integrability,version,versions,807,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:602,interoperability,exchang,exchanged,602,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:613,interoperability,Specif,Specifically,613,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:117,modifiability,version,versions,117,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:263,modifiability,version,version,263,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:539,modifiability,version,versions,539,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:807,modifiability,version,versions,807,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:103,performance,load,load,103,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:47,safety,compl,complex,47,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:338,safety,log,logarithm,338,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:687,safety,test,tests,687,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:47,security,compl,complex,47,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:338,security,log,logarithm,338,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:338,testability,log,logarithm,338,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:687,testability,test,tests,687,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:979,testability,simpl,simply,979,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:500,usability,user,user,500,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:859,usability,learn,learning,859,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:979,usability,simpl,simply,979,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:1002,usability,visual,visualization,1002,"We're still hesitant about making AnnData more complex, for these reasons:. * It is not inefficient to load multiple versions of the full data into AnnData. * It is not straightforward to determine the point of the preprocessing at which one would want to save a version of the raw data (probably after filtering out cells and taking the logarithm, but this might change in the future). As the second point implies that some manual intervention would be necessary, anyway, we tend to leave it to the user to keep track of one, two or more versions of the data; each with annotations that can easily be exchanged. Specifically, would you be happy to proceed as in differential expression tests, see e.g., https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb? You keep track of two versions of the data, one for doing all the machine learning inference and another one for doing statistics and plotting. Using the linked example: for plotting, you would simply need to add the visualization basis to the AnnData that stores the raw data. Then you call `sc.pl.tsne`. ```. adata_corrected = sc.read('pbmc3k_corrected'). adata_raw = sc.read('pbmc3k_filtered_raw_log'). adata_raw.smpm['X_tsne'] = adata_corrected.smpm['X_tsne']. adata_raw.smpm['X_pca'] = adata_corrected.smpm['X_pca']. sc.pl.tsne(adata_raw, color='NKG7'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:247,integrability,pub,published,247,"Finally, we could solve this elegantly without sacrificing a scalable design, as shown in the [tutorial](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Also, Scanpy is accepted in Genome Biology and will soon be published. Merry Christmas! :). Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:61,modifiability,scal,scalable,61,"Finally, we could solve this elegantly without sacrificing a scalable design, as shown in the [tutorial](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Also, Scanpy is accepted in Genome Biology and will soon be published. Merry Christmas! :). Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:61,performance,scalab,scalable,61,"Finally, we could solve this elegantly without sacrificing a scalable design, as shown in the [tutorial](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Also, Scanpy is accepted in Genome Biology and will soon be published. Merry Christmas! :). Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:8,modifiability,exten,extend,8,Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:133,reliability,doe,does,133,Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:40,integrability,batch,batch,40,"And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito et al.,) when I execute MNN ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:108,modifiability,variab,variables,108,"And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito et al.,) when I execute MNN ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:40,performance,batch,batch,40,"And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito et al.,) when I execute MNN ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:91,testability,regress,regress,91,"And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito et al.,) when I execute MNN ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:11,reliability,doe,does,11,"Sorry, how does Monocle do it? Do you have a link to an example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:59,integrability,filter,filtered,59,"Oh so wangjiawen2013 means to color in genes that were not filtered out? I see that makes sense. I was wondering if monocle can color by multiple genes in the same plot, but apparently I was completely on the wrong track here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:191,safety,compl,completely,191,"Oh so wangjiawen2013 means to color in genes that were not filtered out? I see that makes sense. I was wondering if monocle can color by multiple genes in the same plot, but apparently I was completely on the wrong track here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/41:191,security,compl,completely,191,"Oh so wangjiawen2013 means to color in genes that were not filtered out? I see that makes sense. I was wondering if monocle can color by multiple genes in the same plot, but apparently I was completely on the wrong track here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/41
https://github.com/scverse/scanpy/issues/43:184,availability,error,error,184,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:152,modifiability,pac,package,152,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:184,performance,error,error,184,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:184,safety,error,error,184,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:114,usability,clear,clearing,114,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:184,usability,error,error,184,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:106,deployability,stack,stackoverflow,106,"ah, i missed the part where it said `/opt/conda/lib/python3.6`. but im confident now that [this](https://stackoverflow.com/questions/23917729/switching-to-python-3-causing-unicodedecodeerror) is your systems problem!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:188,availability,error,error,188,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:150,deployability,fail,fails,150,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:159,deployability,instal,install,159,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:188,performance,error,error,188,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:150,reliability,fail,fails,150,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:21,safety,test,test,21,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:188,safety,error,error,188,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:21,testability,test,test,21,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:188,usability,error,error,188,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:414,usability,support,supported,414,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:323,availability,down,down,323,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. youre right, we should probably do it. the only reason we didnt yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, itll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:41,integrability,configur,configured,41,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. youre right, we should probably do it. the only reason we didnt yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, itll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:41,modifiability,configur,configured,41,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. youre right, we should probably do it. the only reason we didnt yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, itll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:311,performance,time,time,311,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. youre right, we should probably do it. the only reason we didnt yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, itll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:41,security,configur,configured,41,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. youre right, we should probably do it. the only reason we didnt yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, itll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:51,deployability,stack,stackoverflow,51,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:250,integrability,configur,configured,250,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:361,integrability,configur,configured,361,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:414,integrability,configur,configure,414,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:198,modifiability,pac,package,198,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:250,modifiability,configur,configured,250,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:361,modifiability,configur,configured,361,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:414,modifiability,configur,configure,414,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:250,security,configur,configured,250,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:361,security,configur,configured,361,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:414,security,configur,configure,414,"How about [changing the encoding globally](https://stackoverflow.com/questions/2276200/changing-default-encoding-of-python#17628350)? Would that break anything? Also, there is the same bug with the package you rely on, `louvain`. As for the properly configured system, ubuntu:17.10 is the most generic and recent system I can think of, shouldn't it be properly configured out of the box? If not, is there a way to configure the system so that the encoding is globally set to utf-8?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:127,reliability,doe,does,127,i just learned that OSX sends its locale per default when connecting to a server. so is it a local ubuntu or on a server? what does `locale` (executed from a terminal) return?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:7,usability,learn,learned,7,i just learned that OSX sends its locale per default when connecting to a server. so is it a local ubuntu or on a server? what does `locale` (executed from a terminal) return?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:26,availability,error,error,26,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:2,deployability,manag,managed,2,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:464,deployability,instal,install,464,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:630,deployability,instal,installation,630,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:657,deployability,updat,update,657,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:2,energy efficiency,manag,managed,2,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:705,integrability,repositor,repository,705,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:705,interoperability,repositor,repository,705,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:26,performance,error,error,26,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:333,reliability,doe,doesn,333,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:608,reliability,doe,does,608,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:2,safety,manag,managed,2,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:26,safety,error,error,26,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:617,safety,compl,complete,617,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:657,safety,updat,update,657,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:617,security,compl,complete,617,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:657,security,updat,update,657,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:26,usability,error,error,26,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:313,usability,clear,clearly,313,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:370,usability,help,helping,370,"I managed to get past the error by adding. ```. RUN locale-gen en_US.UTF-8. ENV LC_ALL en_US.UTF-8. ```. to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep! EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:463,deployability,instal,installing,463,"Thanks for the info! I was about to rant that this is weird and broken, but locales are literally the first section in the Ubuntu image docs, so I cant blame them (too much): https://hub.docker.com/_/ubuntu. They probably use `POSIX` as `C.UTF-8` isnt standard. ([blame the C standard consortium](https://github.com/mpv-player/mpv/commit/1e70e82baa9193f6f027338b0fab0f5078971fbe)). They recommend `ENV LANG C.UTF-8` though, maybe that works for you. (otherwise installing `locales` and your instructions work too)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:254,interoperability,standard,standard,254,"Thanks for the info! I was about to rant that this is weird and broken, but locales are literally the first section in the Ubuntu image docs, so I cant blame them (too much): https://hub.docker.com/_/ubuntu. They probably use `POSIX` as `C.UTF-8` isnt standard. ([blame the C standard consortium](https://github.com/mpv-player/mpv/commit/1e70e82baa9193f6f027338b0fab0f5078971fbe)). They recommend `ENV LANG C.UTF-8` though, maybe that works for you. (otherwise installing `locales` and your instructions work too)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:278,interoperability,standard,standard,278,"Thanks for the info! I was about to rant that this is weird and broken, but locales are literally the first section in the Ubuntu image docs, so I cant blame them (too much): https://hub.docker.com/_/ubuntu. They probably use `POSIX` as `C.UTF-8` isnt standard. ([blame the C standard consortium](https://github.com/mpv-player/mpv/commit/1e70e82baa9193f6f027338b0fab0f5078971fbe)). They recommend `ENV LANG C.UTF-8` though, maybe that works for you. (otherwise installing `locales` and your instructions work too)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:148,deployability,instal,install,148,"@falexwolf @pwl i used this one, works fine: https://gist.github.com/flying-sheep/0e003ae3398dd543638955a55c031c8d. i wonder why you didnt have to install the dev packages though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:164,modifiability,pac,packages,164,"@falexwolf @pwl i used this one, works fine: https://gist.github.com/flying-sheep/0e003ae3398dd543638955a55c031c8d. i wonder why you didnt have to install the dev packages though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:61,deployability,instal,install,61,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:161,deployability,fail,fails,161,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:170,deployability,instal,install,170,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:77,modifiability,pac,packages,77,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:194,modifiability,pac,packages,194,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:161,reliability,fail,fails,161,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:21,usability,document,documentation,21,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:110,usability,minim,minimal,110,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:110,energy efficiency,adapt,adapting,110,"dont worry, i think they should really default to a better locale: many people will get their Dockerfiles by adapting existing ones instead of finding that specific doc site, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:110,integrability,adapt,adapting,110,"dont worry, i think they should really default to a better locale: many people will get their Dockerfiles by adapting existing ones instead of finding that specific doc site, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:110,interoperability,adapt,adapting,110,"dont worry, i think they should really default to a better locale: many people will get their Dockerfiles by adapting existing ones instead of finding that specific doc site, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:157,interoperability,specif,specific,157,"dont worry, i think they should really default to a better locale: many people will get their Dockerfiles by adapting existing ones instead of finding that specific doc site, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:110,modifiability,adapt,adapting,110,"dont worry, i think they should really default to a better locale: many people will get their Dockerfiles by adapting existing ones instead of finding that specific doc site, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:123,integrability,repositor,repository,123,"@flying-sheep what do you think about mentioning the Dockerfile somewhere in the docs of scanpy or adding it to the scanpy repository? Perhaps even adding a jupyter notebook to the image, this way new users could easily try the package out and run the examples from https://github.com/theislab/scanpy_usage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:123,interoperability,repositor,repository,123,"@flying-sheep what do you think about mentioning the Dockerfile somewhere in the docs of scanpy or adding it to the scanpy repository? Perhaps even adding a jupyter notebook to the image, this way new users could easily try the package out and run the examples from https://github.com/theislab/scanpy_usage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:228,modifiability,pac,package,228,"@flying-sheep what do you think about mentioning the Dockerfile somewhere in the docs of scanpy or adding it to the scanpy repository? Perhaps even adding a jupyter notebook to the image, this way new users could easily try the package out and run the examples from https://github.com/theislab/scanpy_usage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/43:201,usability,user,users,201,"@flying-sheep what do you think about mentioning the Dockerfile somewhere in the docs of scanpy or adding it to the scanpy repository? Perhaps even adding a jupyter notebook to the image, this way new users could easily try the package out and run the examples from https://github.com/theislab/scanpy_usage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43
https://github.com/scverse/scanpy/issues/44:33,deployability,Releas,Release,33,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:167,deployability,api,api,167,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:178,deployability,api,api,178,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:167,integrability,api,api,167,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:178,integrability,api,api,178,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:823,integrability,batch,batch,823,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:167,interoperability,api,api,167,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:178,interoperability,api,api,178,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/44:823,performance,batch,batch,823,"Hi! Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements. Is the following OK for you? From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html. ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44
https://github.com/scverse/scanpy/issues/45:74,deployability,api,api,74,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:85,deployability,api,api,85,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:74,integrability,api,api,74,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:85,integrability,api,api,85,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:731,integrability,batch,batch,731,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:74,interoperability,api,api,74,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:85,interoperability,api,api,85,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:731,performance,batch,batch,731,"- concatenate datasets: OK? [link](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html). ```. >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s1', 's2'],. >>> 'anno1': ['c1', 'c2']},. >>> {'var_names': ['a', 'b', 'c']}). >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s3', 's4'],. >>> 'anno1': ['c3', 'c4']},. >>> {'var_names': ['b', 'c', 'd']}). >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),. >>> {'smp_names': ['s5', 's6'],. >>> 'anno2': ['d3', 'd4']},. >>> {'var_names': ['b', 'c', 'd']}). >>>. >>> adata = adata1.concatenate([adata2, adata3]). >>> adata.X. [[ 2. 3.]. [ 5. 6.]. [ 1. 2.]. [ 4. 5.]. [ 1. 2.]. [ 4. 5.]]. >>> adata.smp. anno1 anno2 batch. s1 c1 NaN 0. s2 c2 NaN 0. s3 c3 NaN 1. s4 c4 NaN 1. s5 NaN d3 2. s6 NaN d4 2. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:38,availability,cluster,clusters,38,"- recluster restricted to a subset of clusters: OK? <img width=""410"" alt=""screen shot 2017-11-14 at 03 21 36"" src=""https://user-images.githubusercontent.com/16916678/32759694-14978c84-c8eb-11e7-8514-78df151431a4.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:38,deployability,cluster,clusters,38,"- recluster restricted to a subset of clusters: OK? <img width=""410"" alt=""screen shot 2017-11-14 at 03 21 36"" src=""https://user-images.githubusercontent.com/16916678/32759694-14978c84-c8eb-11e7-8514-78df151431a4.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:28,integrability,sub,subset,28,"- recluster restricted to a subset of clusters: OK? <img width=""410"" alt=""screen shot 2017-11-14 at 03 21 36"" src=""https://user-images.githubusercontent.com/16916678/32759694-14978c84-c8eb-11e7-8514-78df151431a4.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:123,usability,user,user-images,123,"- recluster restricted to a subset of clusters: OK? <img width=""410"" alt=""screen shot 2017-11-14 at 03 21 36"" src=""https://user-images.githubusercontent.com/16916678/32759694-14978c84-c8eb-11e7-8514-78df151431a4.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:308,availability,down,downstream,308,"Hi all! I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:528,deployability,pipelin,pipelines,528,"Hi all! I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:694,energy efficiency,current,currently,694,"Hi all! I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:528,integrability,pipelin,pipelines,528,"Hi all! I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:356,testability,regress,regressed,356,"Hi all! I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:64,usability,tool,tools,64,@falexwolf where would you expect a new scoring function? Under tools (sc.tl) or preprocessing (sc.pp)? I may contribute to this cell cycle thing if you haven't already,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:65,performance,content,content,65,"MAGIC is outperformed by both [scImpute](https://www.biorxiv.org/content/biorxiv/early/2017/05/24/141598.full.pdf) and [countae](https://github.com/gokceneraslan/countae), so i guess well stick with one of those if we implement imputation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:99,interoperability,standard,standard,99,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:81,modifiability,extens,extensive,81,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:517,safety,test,test,517,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:223,testability,simpl,simple,223,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:357,testability,simpl,simple,357,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:517,testability,test,test,517,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:185,usability,tool,tools,185,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:223,usability,simpl,simple,223,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:357,usability,simpl,simple,357,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:449,usability,visual,visualization,449,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:499,usability,tool,tool,499,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:278,modifiability,pac,package,278,"@dpcook @flying-sheep regarding imputation: my personal view is that nothing is settled there - I can't judge what's a good method and what not and whether one should use it at all. so for now, we wil not include any imputation method in scanpy. but it's easy to just apply any package you like to the data matrix in an AnnData object `adata.X`...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:47,usability,person,personal,47,"@dpcook @flying-sheep regarding imputation: my personal view is that nothing is settled there - I can't judge what's a good method and what not and whether one should use it at all. so for now, we wil not include any imputation method in scanpy. but it's easy to just apply any package you like to the data matrix in an AnnData object `adata.X`...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:140,safety,test,tests,140,"@falexwolf I have the functions in my scanpy branch, right now. It seems to be properly working (take a look, if you want to). I'll add the tests as soon as possibile (now getting back to ""ordinary work"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:140,testability,test,tests,140,"@falexwolf I have the functions in my scanpy branch, right now. It seems to be properly working (take a look, if you want to). I'll add the tests as soon as possibile (now getting back to ""ordinary work"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:130,energy efficiency,optim,optimization,130,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:167,energy efficiency,measur,measures,167,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:130,performance,optimiz,optimization,130,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:155,performance,perform,performance,155,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:103,usability,learn,learn,103,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:155,usability,perform,performance,155,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:84,deployability,contain,contain,84,"well, @gokceneraslan told me. Gkcen, is the preprint for countae online? It should contain what @hammer asked for, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:148,availability,down,downstream,148,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:133,deployability,depend,depends,133,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:133,integrability,depend,depends,133,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:133,modifiability,depend,depends,133,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:89,performance,perform,performance,89,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:133,safety,depend,depends,133,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:133,testability,depend,depends,133,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:89,usability,perform,performance,89,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/45:229,interoperability,specif,specifics,229,"I'm closing this because it's a bit of a very old catch all issue. If somebody in this thread is still lacking functionality in the broader scverse ecosystem or scanpy directly, I'd encourage people to post new issues to discuss specifics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45
https://github.com/scverse/scanpy/issues/47:254,deployability,updat,updated,254,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:326,deployability,api,api,326,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:337,deployability,api,api,337,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:581,deployability,releas,release,581,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:326,integrability,api,api,326,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:337,integrability,api,api,337,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:326,interoperability,api,api,326,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:337,interoperability,api,api,337,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:83,modifiability,paramet,parameter,83,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:406,reliability,doe,doesn,406,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:254,safety,updat,updated,254,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:379,safety,test,test,379,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:529,safety,test,tests,529,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:254,security,updat,updated,254,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:379,testability,test,test,379,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:529,testability,test,tests,529,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:71,deployability,updat,update,71,"Hi Alex,. Thanks for fixing this promptly. I will eagerly wait for the update. I have another query related to usage of this function but I'll create a new issue for that. Parashar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:71,safety,updat,update,71,"Hi Alex,. Thanks for fixing this promptly. I will eagerly wait for the update. I have another query related to usage of this function but I'll create a new issue for that. Parashar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/47:71,security,updat,update,71,"Hi Alex,. Thanks for fixing this promptly. I will eagerly wait for the update. I have another query related to usage of this function but I'll create a new issue for that. Parashar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47
https://github.com/scverse/scanpy/issues/48:231,deployability,api,api,231,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:242,deployability,api,api,242,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:823,energy efficiency,adapt,adapted,823,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:231,integrability,api,api,231,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:242,integrability,api,api,242,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:823,integrability,adapt,adapted,823,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:231,interoperability,api,api,231,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:242,interoperability,api,api,242,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:823,interoperability,adapt,adapted,823,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:367,modifiability,scal,scaling,367,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:547,modifiability,scal,scaling,547,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:823,modifiability,adapt,adapted,823,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:274,performance,Perform,Performing,274,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:689,performance,perform,performs,689,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:870,security,auth,authors,870,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:540,testability,simpl,simple,540,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:274,usability,Perform,Performing,274,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:540,usability,simpl,simple,540,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/48:689,usability,perform,performs,689,"I'm very sorry for having forgotten about this issue... Of course, `sc.pp.normalize_per_cell()` stores the total counts per cell *prior* to normalization as *n_counts*. See the examples here https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. Performing the normalization removes the effect of having different total counts per cell by scaling each gene with the total counts. But one might want more: if there is still some correlation of a gene with *n_counts* *after* normalization, one concludes that the simple scaling done in normalization has *not* fully removed the effect of *n_counts* on that particular gene. Hence, using `sc.pp.regress_out`, one performs an additional gene-wise correction. I have to admit that I have not investigated how necessary this is. As you know, this is adapted from the Seurat tutorial - I guess the authors of Seurat found it useful in some cases to fully remove the effect of *n_counts* on each single gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/48
https://github.com/scverse/scanpy/issues/49:152,deployability,stack,stackoverflow,152,"Thank you for this report! We know about the first issue. It's due to a misconfigured system. The readme is just plain text. Here is the issue: https://stackoverflow.com/questions/23917729/switching-to-python-3-causing-unicodedecodeerror. And here a solution:. ```. export LC_ALL=en_US.UTF-8 . export LANG=en_US.UTF-8. ```. Or, on Mac, edit `/etc/ssh/ssh_config` and change. ```. Host *. SendEnv LANG LC_*. ```. to. ```. Host *. # SendEnv LANG LC_*. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:347,security,ssh,ssh,347,"Thank you for this report! We know about the first issue. It's due to a misconfigured system. The readme is just plain text. Here is the issue: https://stackoverflow.com/questions/23917729/switching-to-python-3-causing-unicodedecodeerror. And here a solution:. ```. export LC_ALL=en_US.UTF-8 . export LANG=en_US.UTF-8. ```. Or, on Mac, edit `/etc/ssh/ssh_config` and change. ```. Host *. SendEnv LANG LC_*. ```. to. ```. Host *. # SendEnv LANG LC_*. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:12,deployability,manag,managed,12,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:23,deployability,instal,install,23,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:12,energy efficiency,manag,managed,12,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:110,integrability,repositor,repository,110,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:110,interoperability,repositor,repository,110,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/49:12,safety,manag,managed,12,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49
https://github.com/scverse/scanpy/issues/50:45,interoperability,specif,specific,45,"i think the reason we do this is for project-specific caching, not temporary files. using the dedicated cache dir is of course preferable to using the working dir, since the OS knows about them (and can clean them once prompted or necessary), and preferable to a tempdir, as they survive restarts. we should use <code>cache_dir = Path([appdirs](https://pypi.python.org/pypi/appdirs/1.4.3).user_cache_dir('scanpy', 'F. Alex Wolf'))</code>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:54,performance,cach,caching,54,"i think the reason we do this is for project-specific caching, not temporary files. using the dedicated cache dir is of course preferable to using the working dir, since the OS knows about them (and can clean them once prompted or necessary), and preferable to a tempdir, as they survive restarts. we should use <code>cache_dir = Path([appdirs](https://pypi.python.org/pypi/appdirs/1.4.3).user_cache_dir('scanpy', 'F. Alex Wolf'))</code>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:104,performance,cach,cache,104,"i think the reason we do this is for project-specific caching, not temporary files. using the dedicated cache dir is of course preferable to using the working dir, since the OS knows about them (and can clean them once prompted or necessary), and preferable to a tempdir, as they survive restarts. we should use <code>cache_dir = Path([appdirs](https://pypi.python.org/pypi/appdirs/1.4.3).user_cache_dir('scanpy', 'F. Alex Wolf'))</code>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:127,usability,prefer,preferable,127,"i think the reason we do this is for project-specific caching, not temporary files. using the dedicated cache dir is of course preferable to using the working dir, since the OS knows about them (and can clean them once prompted or necessary), and preferable to a tempdir, as they survive restarts. we should use <code>cache_dir = Path([appdirs](https://pypi.python.org/pypi/appdirs/1.4.3).user_cache_dir('scanpy', 'F. Alex Wolf'))</code>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:247,usability,prefer,preferable,247,"i think the reason we do this is for project-specific caching, not temporary files. using the dedicated cache dir is of course preferable to using the working dir, since the OS knows about them (and can clean them once prompted or necessary), and preferable to a tempdir, as they survive restarts. we should use <code>cache_dir = Path([appdirs](https://pypi.python.org/pypi/appdirs/1.4.3).user_cache_dir('scanpy', 'F. Alex Wolf'))</code>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:55,deployability,configurat,configuration,55,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:55,integrability,configur,configuration,55,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:46,interoperability,specif,specific,46,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:55,modifiability,configur,configuration,55,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:258,performance,cach,cache,258,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:55,security,configur,configuration,55,"The reason for this directory is just project-specific configuration. Here, https://github.com/theislab/scanpy/commit/7a57fd4cf140dc4b2ffca7ef0651a355c74f0122, I removed the creation of this directory. Nonetheless, it's true that Scanpy, when you tell it to cache a file, it wants to create a directory (by default './write/') for it. Tell me if this is a problem for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:52,performance,cach,caching,52,"ah, yes, i confused `.scanpy` and `.write`. i think caching in a real cache directory instead of `./.write` would be better in any case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:70,performance,cach,cache,70,"ah, yes, i confused `.scanpy` and `.write`. i think caching in a real cache directory instead of `./.write` would be better in any case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:232,testability,simpl,simply,232,"It's `'./write/'`, so it's not a hidden directory - i guess it wouldn't be a good idea to save large files in a hidden fashion; whereas the config was hidden in `'.scanpy/'` - but the latter is not really needed anymore and I could simply remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:232,usability,simpl,simply,232,"It's `'./write/'`, so it's not a hidden directory - i guess it wouldn't be a good idea to save large files in a hidden fashion; whereas the config was hidden in `'.scanpy/'` - but the latter is not really needed anymore and I could simply remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:197,deployability,modul,module,197,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:197,modifiability,modul,module,197,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:136,reliability,doe,does,136,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:197,safety,modul,module,197,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:450,security,control,control,450,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:450,testability,control,control,450,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:253,usability,user,user,253,"I think write is ok, since there is an option to move /write/ around. As a suggestion:. Per default try to write into /write/ - if this does not work for any reason, grab a tempdirectory (tempfile module in python) and use that. Print a warning for the user. Then I would always work. Edit: A temp directory taken from tempfile would have the added bonus that the system could clean it up. But for some usecases (LARGE files...) it would be great to control the folder location as is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:511,performance,time,time,511,"i dimly remember that another project decided against that. its confusing if suddenly the directory becomes writable and then scanpy creates a second one. id say:. ```py. class Writedir:. def __enter__(self):. return Path(sett.writedir). def __exit__(self, exc_type, exc_val, exc_tb):. if issubclass(exc_type, PermissionError):. errno, reason = exc_val.args. exc_val.args = (errno, f'{reason}. Try to set sc.sett.writedir to e.g.: {cache_dir}'). writedir_context = Writedir(). del Writedir. ```. and now each time we use it, we do:. ```py. with writedir_context as writedir:. (writedir / 'blah').open('w')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:8,safety,reme,remember,8,"i dimly remember that another project decided against that. its confusing if suddenly the directory becomes writable and then scanpy creates a second one. id say:. ```py. class Writedir:. def __enter__(self):. return Path(sett.writedir). def __exit__(self, exc_type, exc_val, exc_tb):. if issubclass(exc_type, PermissionError):. errno, reason = exc_val.args. exc_val.args = (errno, f'{reason}. Try to set sc.sett.writedir to e.g.: {cache_dir}'). writedir_context = Writedir(). del Writedir. ```. and now each time we use it, we do:. ```py. with writedir_context as writedir:. (writedir / 'blah').open('w')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:312,safety,Permiss,PermissionError,312,"i dimly remember that another project decided against that. its confusing if suddenly the directory becomes writable and then scanpy creates a second one. id say:. ```py. class Writedir:. def __enter__(self):. return Path(sett.writedir). def __exit__(self, exc_type, exc_val, exc_tb):. if issubclass(exc_type, PermissionError):. errno, reason = exc_val.args. exc_val.args = (errno, f'{reason}. Try to set sc.sett.writedir to e.g.: {cache_dir}'). writedir_context = Writedir(). del Writedir. ```. and now each time we use it, we do:. ```py. with writedir_context as writedir:. (writedir / 'blah').open('w')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:54,deployability,manag,manager,54,I like the idea. You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:54,energy efficiency,manag,manager,54,I like the idea. You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:36,safety,avoid,avoid,36,I like the idea. You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:54,safety,manag,manager,54,I like the idea. You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:46,testability,context,context,46,I like the idea. You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:32,deployability,manag,manager,32,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:32,energy efficiency,manag,manager,32,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:61,integrability,wrap,wrapping,61,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:14,safety,avoid,avoid,14,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:32,safety,manag,manager,32,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:24,testability,context,context,24,how would you avoid the context manager? its either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:95,availability,slo,slow,95,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:652,availability,state,state,652,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:219,energy efficiency,load,loaded,219,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:482,energy efficiency,load,load,482,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:644,energy efficiency,current,current,644,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:652,integrability,state,state,652,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:932,integrability,sub,subdirectory,932,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:129,interoperability,format,formats,129,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:746,interoperability,specif,specific,746,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:59,modifiability,concern,concerns,59,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:219,performance,load,loaded,219,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:236,performance,memor,memory,236,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:482,performance,load,load,482,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:505,performance,memor,memory,505,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:555,performance,disk,disk,555,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:568,performance,time,time,568,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:687,performance,cach,cache,687,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:878,performance,disk,disk,878,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1020,performance,cach,cache,1020,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1168,performance,cach,cache,1168,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:95,reliability,slo,slow,95,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:59,testability,concern,concerns,59,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1043,testability,simpl,simply,1043,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:39,usability,Person,Person,39,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:236,usability,memor,memory,236,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:291,usability,user,user,291,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:312,usability,interact,interact,312,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:505,usability,memor,memory,505,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:823,usability,user,user,823,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1043,usability,simpl,simply,1043,"OK, will talk to Philipp about this in Person... This only concerns speeding up the reading of slow (e.g., text-based) data file formats. This might also be relevant for this discussion: foreseeing the use of partially loaded data into memory, files for backing AnnData remain something the user has to actively interact with. With the creation of an AnnData object, she/he would then have the option to create a corresponding ""backing-file"", which is internally used by AnnData to load needed parts into memory and leave parts that are not needed on the disk. At any time when there is no active write or read to the file, the file stores the current state of AnnData. I felt that both cache files and ""backing files"" should happen in a project-specific './write' directory - that is, at a location where an inexperienced user directly ""sees"" what happens and how this affects disk space. One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... But I agree true cache files might be better placed in a tmp directory. As said, will discuss this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:815,availability,reboot,reboot,815,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:907,availability,reboot,reboot,907,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:952,deployability,manag,manager,952,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:952,energy efficiency,manag,manager,952,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:156,integrability,sub,subdirectory,156,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:537,interoperability,standard,standard,537,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:244,performance,cach,cache,244,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:406,performance,cach,cache,406,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:476,performance,cach,cache,476,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:882,performance,content,contents,882,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1110,performance,cach,cache,1110,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1119,performance,cach,cache,1119,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1279,performance,cach,cache,1279,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1362,performance,cach,cache,1362,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1495,performance,cach,cache,1495,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1521,performance,cach,cache,1521,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:56,safety,except,except,56,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:952,safety,manag,manager,952,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1591,safety,safe,safely,1591,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1561,security,sign,signify,1561,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:267,testability,simpl,simply,267,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:944,testability,context,context,944,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:267,usability,simpl,simply,267,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1155,usability,user,user,1155,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1250,usability,clear,clear,1250,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1445,usability,user,user,1445,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/50:1553,usability,help,help,1553,"sure, well talk in 10 days or so, after my holidays . except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents dont survive a reboot). ```py. # python gives you a context manager that deletes the file after its block. with tempfile.TemporaryFile() as fp:. use(fp). # fp and the file are gone now. ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50
https://github.com/scverse/scanpy/issues/51:333,availability,cluster,clustering,333,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:333,deployability,cluster,clustering,333,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:405,deployability,api,api,405,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:416,deployability,api,api,416,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:405,integrability,api,api,405,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:416,integrability,api,api,416,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:28,interoperability,distribut,distributions,28,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:317,interoperability,standard,standard,317,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:405,interoperability,api,api,405,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:416,interoperability,api,api,416,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:16,usability,visual,visualizing,16,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/51:514,usability,user,user-images,514,"Better way of **visualizing distributions of gene expression across groups and conditions**: https://github.com/theislab/scanpy/commit/1d7c51e8c1ed743e3581fdc7315ebc0239631496. The option `compute_distribution` in `sc.tl.rank_genes_groups` is no longer needed and is now deprecated. Here follows one example from the standard Seurat clustering tutorial. See [here](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.rank_genes_groups_violin.html) for more options. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/33292927-3f66280e-d3cb-11e7-9849-a8a5b7c719fc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/51
https://github.com/scverse/scanpy/issues/52:78,deployability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,integrability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,interoperability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,modifiability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,reliability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,security,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:78,testability,integr,integration,78,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:52,usability,tool,tool,52,"Sorry about this; `sc.tl.sim` used to be a separate tool in the beginning and integration into Scanpy was erroneous. For the past months I've only used to produce the two reference datasets linked below. All of the problems you mentioned are fixed in Scanpy 0.3.2. Take a look at:. https://github.com/theislab/scanpy_usage/tree/master/170430_krumsiek11. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:41,modifiability,paramet,parameters,41,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:709,modifiability,paramet,parameters,709,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:116,performance,cach,caching,116,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:218,testability,simul,simulations,218,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:532,testability,simul,simulation,532,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/52:573,usability,clear,clear,573,"Thanks for the quick reaction. While the parameters seem to be respected in Scnapy 0.3.2, there is still some weird caching issue. Everything works OK when the ```write``` directory is empty, but when running multiple simulations in a row, e.g.:. ```. adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=1). sc.pl.sim(adam_krumsiek11_2). adam_krumsiek11_2 = sc.tl.sim('krumsiek11.txt', nrRealizations=2). sc.pl.sim(adam_krumsiek11_2). ```. I sometime get the same result (and both calls report reading from the very same simulation result file). However, when I clear the ```write``` directory between the calls to ```sc.tl.sim```, the results are as expected. This problem occurs only for certain parameters (for example, varying seed this way works as expected - I get two different figures).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52
https://github.com/scverse/scanpy/issues/53:410,availability,consist,consistent,410,"Oh, sorry about having completely forgot about this issue... Instead of providing a ""mapping into diffmap"" method, we will provide generic methods for mapping new data into the fundamental single-cell graph, which is the basis for all embeddings. So, we do not plan to provide something for diffusion maps only. While this generic ""mapping new data into existing data"" will take another while, you do the most consistent thing if you merge your dataset, recompute the graph and embed that merged graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/53
https://github.com/scverse/scanpy/issues/53:23,safety,compl,completely,23,"Oh, sorry about having completely forgot about this issue... Instead of providing a ""mapping into diffmap"" method, we will provide generic methods for mapping new data into the fundamental single-cell graph, which is the basis for all embeddings. So, we do not plan to provide something for diffusion maps only. While this generic ""mapping new data into existing data"" will take another while, you do the most consistent thing if you merge your dataset, recompute the graph and embed that merged graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/53
https://github.com/scverse/scanpy/issues/53:23,security,compl,completely,23,"Oh, sorry about having completely forgot about this issue... Instead of providing a ""mapping into diffmap"" method, we will provide generic methods for mapping new data into the fundamental single-cell graph, which is the basis for all embeddings. So, we do not plan to provide something for diffusion maps only. While this generic ""mapping new data into existing data"" will take another while, you do the most consistent thing if you merge your dataset, recompute the graph and embed that merged graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/53
https://github.com/scverse/scanpy/issues/53:261,testability,plan,plan,261,"Oh, sorry about having completely forgot about this issue... Instead of providing a ""mapping into diffmap"" method, we will provide generic methods for mapping new data into the fundamental single-cell graph, which is the basis for all embeddings. So, we do not plan to provide something for diffusion maps only. While this generic ""mapping new data into existing data"" will take another while, you do the most consistent thing if you merge your dataset, recompute the graph and embed that merged graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/53
https://github.com/scverse/scanpy/issues/53:410,usability,consist,consistent,410,"Oh, sorry about having completely forgot about this issue... Instead of providing a ""mapping into diffmap"" method, we will provide generic methods for mapping new data into the fundamental single-cell graph, which is the basis for all embeddings. So, we do not plan to provide something for diffusion maps only. While this generic ""mapping new data into existing data"" will take another while, you do the most consistent thing if you merge your dataset, recompute the graph and embed that merged graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/53
https://github.com/scverse/scanpy/issues/55:512,deployability,version,version,512,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:23,energy efficiency,Current,Currently,23,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:512,integrability,version,version,512,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:512,modifiability,version,version,512,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:400,testability,simpl,simply,400,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:53,usability,behavi,behavior,53,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:400,usability,simpl,simply,400,"Hi Davide,. thank you! Currently, we use the default behavior of pandas concatenate: see [here](https://github.com/theislab/anndata/blob/562954b43a9b8faa969e0ec01707bc56cbc021b0/anndata/base.py#L1371-L1400). I'll not be able to fix this during the next days. @flying-sheep, could you have a look and maybe figure out a meaningful option or meaningful default to circumvent this? It should be easy to simply pass an option to DataFrame.concat(). @dawe Thanks again for your pull request. I also put a new anndata version that incorporates it on PyPI. Cheers, . Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:89,availability,error,error,89,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:63,deployability,observ,observations,63,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:98,deployability,observ,observations,98,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:89,performance,error,error,89,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:89,safety,error,error,89,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:53,security,ident,identical,53,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:63,testability,observ,observations,63,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:98,testability,observ,observations,98,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:89,usability,error,error,89,What would be a useful default? I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:355,deployability,observ,observation,355,"I wouldn't make assumptions on the data themselves, it may be that different cells (with the same name) in different experiments get the same counts for the same gene, especially if this is low (0-2). I'm also a Seurat user, which allows only pairwise merging of different dataset and I believe that a useful default would be add a N_ at the beginning of observation names with N being in a range(len(experiments)). This would allow seamless automatic merging of multiple datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:442,deployability,automat,automatic,442,"I wouldn't make assumptions on the data themselves, it may be that different cells (with the same name) in different experiments get the same counts for the same gene, especially if this is low (0-2). I'm also a Seurat user, which allows only pairwise merging of different dataset and I believe that a useful default would be add a N_ at the beginning of observation names with N being in a range(len(experiments)). This would allow seamless automatic merging of multiple datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:355,testability,observ,observation,355,"I wouldn't make assumptions on the data themselves, it may be that different cells (with the same name) in different experiments get the same counts for the same gene, especially if this is low (0-2). I'm also a Seurat user, which allows only pairwise merging of different dataset and I believe that a useful default would be add a N_ at the beginning of observation names with N being in a range(len(experiments)). This would allow seamless automatic merging of multiple datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:442,testability,automat,automatic,442,"I wouldn't make assumptions on the data themselves, it may be that different cells (with the same name) in different experiments get the same counts for the same gene, especially if this is low (0-2). I'm also a Seurat user, which allows only pairwise merging of different dataset and I believe that a useful default would be add a N_ at the beginning of observation names with N being in a range(len(experiments)). This would allow seamless automatic merging of multiple datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:219,usability,user,user,219,"I wouldn't make assumptions on the data themselves, it may be that different cells (with the same name) in different experiments get the same counts for the same gene, especially if this is low (0-2). I'm also a Seurat user, which allows only pairwise merging of different dataset and I believe that a useful default would be add a N_ at the beginning of observation names with N being in a range(len(experiments)). This would allow seamless automatic merging of multiple datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:12,deployability,observ,observation,12,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:74,deployability,observ,observations,74,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:108,deployability,automat,automatically,108,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:12,testability,observ,observation,12,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:74,testability,observ,observations,74,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:108,testability,automat,automatically,108,"Hmm, maybe observation names arent something I commonly use to refer to observations, mostly metadata. So automatically changing them might have less impact than fiddling with any other kind of IDs. @falexwolf, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:132,security,ident,identify,132,"Im working with an implementation of dropseq that needs to preserve cell names as I need to match two sequencing technologies that identify the same barcode, Id rather preserve names (or store them in an optional dictionary)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:500,availability,consist,consistent,500,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:90,deployability,contain,contain,90,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:811,deployability,observ,observations,811,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:889,deployability,observ,observation,889,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:957,deployability,observ,observation,957,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1163,deployability,observ,observation,1163,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1249,deployability,observ,observation,1249,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1417,deployability,observ,observations,1417,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1487,deployability,observ,observation,1487,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1565,deployability,observ,observation,1565,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1598,deployability,observ,observation,1598,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1682,deployability,observ,observation,1682,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:27,integrability,batch,batch,27,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1188,modifiability,variab,variable,1188,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1274,modifiability,variab,variable,1274,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1623,modifiability,variab,variable,1623,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1707,modifiability,variab,variable,1707,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:27,performance,batch,batch,27,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:418,testability,simpl,simply,418,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:811,testability,observ,observations,811,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:889,testability,observ,observation,889,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:957,testability,observ,observation,957,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1163,testability,observ,observation,1163,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1249,testability,observ,observation,1249,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1417,testability,observ,observations,1417,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1487,testability,observ,observation,1487,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1565,testability,observ,observation,1565,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1598,testability,observ,observation,1598,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1682,testability,observ,observation,1682,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:418,usability,simpl,simply,418,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:461,usability,behavi,behavior,461,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:500,usability,consist,consistent,500,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:1023,usability,behavi,behavior,1023,"@dawe What if you use the 'batch' field in `adata.obs` together with the index that might contain duplicates to get the uniqueness that your're missing. If that's not enough. I would do the same thing as [pandas.concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html), namely generating a multi-index. This would be just a one-line edit for `AnnData.concatenate()` and we should do this; we simply need to make sure that the indexing behavior of AnnData as a whole remains consistent with the following. @flying-sheep, could you do this? . ```. import pandas as pd. s1 = pd.DataFrame({'v1': ['a', 'b'], 'v2': [2, 3]}). s2 = pd.DataFrame({'v1': ['c', 'd'], 'v2': [3, 4]}). s = pd.concat([s1, s2], keys=['s1', 's2']). print('... the concatenated annotations'). print(s). print('... all observations corresponding to ""s1""'). print(s.loc['s1']). print('... a single observation'). print(s.loc['s1', 0]). print('... values of a single observation'). # this is what we do not want in AnnData, only the behavior of the next line. # that is, a multi-index should be indexed with lists or tuples. print(s.loc['s1', 0].values). print('... single observation and a single variable'). print(s.loc[['s1', 0], 'v1']). print('... single observation and a single variable'). print(s.loc[('s1', 0), 'v1']). ```. gives. ```. ... the concatenated annotations. v1 v2. s1 0 a 2. 1 b 3. s2 0 c 3. 1 d 4. ... all observations corresponding to ""s1"". v1 v2. 0 a 2. 1 b 3. ... a single observation. v1 a. v2 2. Name: (s1, 0), dtype: object. ... values of a single observation. ['a' 2]. ... single observation and a single variable. s1 0 a. 1 b. Name: v1, dtype: object. ... single observation and a single variable. a. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:216,availability,consist,consistent,216,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:252,integrability,batch,batch,252,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:28,modifiability,paramet,parameter,28,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:95,modifiability,paramet,parameter,95,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:173,modifiability,paramet,parameter,173,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:236,performance,content,content,236,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:252,performance,batch,batch,252,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:216,usability,consist,consistent,216,"Instead of passing a `keys` parameter to `AnnData.concatenate()`, I would pass a ""multi_index"" parameter, that triggers passing `keys=[0, 1, ..., n_datasets]` to the `keys` parameter of `pandas.concat`. This is then consistent with the content of the `batch` field.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/55:60,deployability,releas,release,60,"So, this is solved in anndata 0.5 and scanpy 0.4.3. See the release notes (https://scanpy.readthedocs.io) and https://github.com/theislab/anndata/commit/63500075e926f202e856bd04ec673df55bbd2460 and the [example](http://anndata.readthedocs.io/en/latest/anndata.AnnData.concatenate.html). Hope this is a meaningful default. If you pass `index_unique=None`, then it keeps the previous indices including duplicates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55
https://github.com/scverse/scanpy/issues/56:197,deployability,instal,installed,197,"Dear Bo, sorry for the late response. I just became the father of twins a few days ago and couldn't respond earlier. If you still need an answer, I will look into this tomorrow. If you have `h5ls` installed on the command line, it would be great to show me the output of running `h5ls your_file.h5`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:214,usability,command,command,214,"Dear Bo, sorry for the late response. I just became the father of twins a few days ago and couldn't respond earlier. If you still need an answer, I will look into this tomorrow. If you have `h5ls` installed on the command line, it would be great to show me the output of running `h5ls your_file.h5`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:99,interoperability,format,format,99,"@falexwolf , congratulations! I have already found a workaround. But if you want to support v0.2.8 format, I'm happy to provide the information you asked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:84,usability,support,support,84,"@falexwolf , congratulations! I have already found a workaround. But if you want to support v0.2.8 format, I'm happy to provide the information you asked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:186,deployability,version,version,186,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:197,deployability,version,version,197,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:394,deployability,pipelin,pipelines,394,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:461,deployability,version,versions,461,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:186,integrability,version,version,186,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:197,integrability,version,version,197,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:394,integrability,pipelin,pipelines,394,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:461,integrability,version,versions,461,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:354,interoperability,compatib,compatible,354,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:186,modifiability,version,version,186,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:197,modifiability,version,version,197,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:267,modifiability,evolv,evolves,267,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:461,modifiability,version,versions,461,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:102,safety,test,tests,102,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:174,safety,test,tested,174,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:102,testability,test,tests,102,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/56:174,testability,test,tested,174,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56
https://github.com/scverse/scanpy/issues/57:74,deployability,version,version,74,"thank you! is fixed in a4baaaf6c29b8da4f3d9026552719039d2600ca9, which is version 0.4.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/57
https://github.com/scverse/scanpy/issues/57:74,integrability,version,version,74,"thank you! is fixed in a4baaaf6c29b8da4f3d9026552719039d2600ca9, which is version 0.4.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/57
https://github.com/scverse/scanpy/issues/57:74,modifiability,version,version,74,"thank you! is fixed in a4baaaf6c29b8da4f3d9026552719039d2600ca9, which is version 0.4.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/57
https://github.com/scverse/scanpy/issues/58:432,deployability,api,api,432,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/58:443,deployability,api,api,443,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/58:432,integrability,api,api,432,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/58:443,integrability,api,api,443,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/58:432,interoperability,api,api,432,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/58:443,interoperability,api,api,443,"Fixed stuff:. - [02e78bb025f9cd8d02cf6d39256fea008ec51d7f] Used intersphinx for links to `anndata.AnnData`. - [ead51644fb700b9d40c48a44e7eb53c678d872dd] Put the references first in the toctree to make the dodgy references resolve (id be happy if we didnt have to do that. maybe a hidden toctree before the real one?). - [8b612743b796f045da3fe7af57763c0a995aefdf] Fixed the [Neighbors class](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.html) by removing the sections and incorporating a sphinx bugfix. - [theislab/anndata@828d7eb503863df8ec1926190da37c931daa5dd5] no idea about the attribute order in anndata: from what i can puzzle together, that order should be everywhere, as [the template](https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/autosummary/templates/autosummary/class.rst) lists methods before attributes. so the question is: why isnt the order like anndatas in scanpy, numpy, scipy, ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/58
https://github.com/scverse/scanpy/issues/59:42,deployability,instal,install,42,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:65,deployability,instal,installing,65,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:84,deployability,depend,dependencies,84,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:208,deployability,depend,dependencies,208,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:301,deployability,instal,install,301,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:313,deployability,depend,dependencies,313,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:341,deployability,continu,continue,341,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:353,deployability,instal,install,353,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:370,deployability,depend,dependencies,370,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:26,energy efficiency,Current,Currently,26,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:84,integrability,depend,dependencies,84,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:208,integrability,depend,dependencies,208,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:313,integrability,depend,dependencies,313,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:370,integrability,depend,dependencies,370,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:84,modifiability,depend,dependencies,84,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:208,modifiability,depend,dependencies,208,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:313,modifiability,depend,dependencies,313,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:370,modifiability,depend,dependencies,370,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:58,safety,avoid,avoids,58,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:84,safety,depend,dependencies,84,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:208,safety,depend,dependencies,208,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:313,safety,depend,dependencies,313,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:370,safety,depend,dependencies,370,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:84,testability,depend,dependencies,84,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:208,testability,depend,dependencies,208,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:313,testability,depend,dependencies,313,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:370,testability,depend,dependencies,370,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:114,usability,user,users,114,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:222,usability,user,users,222,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:24,deployability,instal,installations,24,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:66,deployability,instal,installing,66,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:90,deployability,depend,dependencies,90,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:190,deployability,version,version,190,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:298,deployability,instal,installation,298,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:325,deployability,depend,dependencies,325,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:90,integrability,depend,dependencies,90,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:190,integrability,version,version,190,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:325,integrability,depend,dependencies,325,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:90,modifiability,depend,dependencies,90,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:190,modifiability,version,version,190,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:325,modifiability,depend,dependencies,325,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:90,safety,depend,dependencies,90,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:325,safety,depend,dependencies,325,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:90,testability,depend,dependencies,90,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:325,testability,depend,dependencies,325,"so you would want three installations, right? - full (by manually installing all optional dependencies). - uncomplicated but limited. - super barebones. since `scanpy` is already the second version, we dont lose anything this way. in the future maybe we can achieve that `scanpy` becomes the full installation (once the C++ dependencies start shipping wheels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:187,deployability,instal,installation,187,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:529,deployability,instal,installed,529,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:217,energy efficiency,core,core,217,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:482,integrability,wrap,wrapper,482,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:561,integrability,wrap,wrapper,561,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:482,interoperability,wrapper,wrapper,482,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:561,interoperability,wrapper,wrapper,561,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:82,modifiability,pac,packages,82,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:494,modifiability,pac,packages,494,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:714,modifiability,reu,reusing,714,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:728,modifiability,paramet,parameters,728,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:53,performance,time,time,53,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:722,safety,input,input,722,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:627,testability,simpl,simply,627,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:291,usability,stop,stop,291,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:296,usability,support,supporting,296,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:627,usability,simpl,simply,627,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:678,usability,visual,visualization,678,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:701,usability,efficien,efficient,701,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:722,usability,input,input,722,"Yes, I think that would be the best solution for the time during which we rely on packages which do not ship proper wheels... . I agree that in the future, `scanpy` could become the full installation. Why not `scanpy-core`, `scanpy`, `scanpy-full`? I don't think it will bother anyone if we stop supporting `scanpy-full` at some point and only use `scanpy`. Given how Scanpy is set up and used, I could also imagine that, upon growing, it will become in some parts even more a thin wrapper for packages that should be optionally installed (it is already a thin wrapper for `igraph`, `louvain` and `MulticoreTSNE`, where Scanpy simply makes the usage more convenient by unifying visualization etc. and efficient by reusing input parameters that have previously been computed and used in other parts of Scanpy - right now, essentially all the preprocessing, the neighborhood relations and graph stuff). . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:26,deployability,version,version,26,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:68,deployability,depend,depend,68,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:26,integrability,version,version,26,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:68,integrability,depend,depend,68,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:26,modifiability,version,version,26,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:68,modifiability,depend,depend,68,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:51,reliability,doe,does,51,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:68,safety,depend,depend,68,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/issues/59:68,testability,depend,depend,68,"sure! as long as the last version of `scanpy-full` does nothing but depend on `scanpy`, nobody will suffer any consequences if it becomes obsolete one day.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59
https://github.com/scverse/scanpy/pull/60:27,safety,compl,completely,27,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60
https://github.com/scverse/scanpy/pull/60:72,safety,test,tests,72,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60
https://github.com/scverse/scanpy/pull/60:27,security,compl,completely,27,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60
https://github.com/scverse/scanpy/pull/60:72,testability,test,tests,72,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60
https://github.com/scverse/scanpy/issues/61:1003,availability,down,down,1003,"I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:268,deployability,continu,continue,268,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:762,energy efficiency,current,current,762,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:1073,energy efficiency,current,currently,1073,"returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:561,integrability,transform,transforming,561,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:561,interoperability,transform,transforming,561,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:1547,security,modif,modifactions,1547,"he user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply using a dataframe and putting it in the unstructured annotation `.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:1311,testability,simpl,simple,1311,"he user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply using a dataframe and putting it in the unstructured annotation `.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:2072,testability,simpl,simply,2072,"he user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply using a dataframe and putting it in the unstructured annotation `.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:153,usability,user,user,153,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:414,usability,intuit,intuitive,414,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:462,usability,user,users,462,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:770,usability,workflow,workflow,770,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:1311,usability,simpl,simple,1311,"he user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply using a dataframe and putting it in the unstructured annotation `.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:2072,usability,simpl,simply,2072,"he user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`. . our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibility but we should probably stick with it. hence, another argument for simply using a dataframe and putting it in the unstructured annotation `.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:6,modifiability,interm,intermediate,6,"As an intermediate solution, we could. 1. implement https://github.com/scverse/anndata/issues/679. 2. write recarrays as dataframes. 3. make sure tests run successfully on anndata objects where `adata.uns[""rank_genes_groups_filtered""][""names""]` has been converted into a DataFrame",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:146,safety,test,tests,146,"As an intermediate solution, we could. 1. implement https://github.com/scverse/anndata/issues/679. 2. write recarrays as dataframes. 3. make sure tests run successfully on anndata objects where `adata.uns[""rank_genes_groups_filtered""][""names""]` has been converted into a DataFrame",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/61:146,testability,test,tests,146,"As an intermediate solution, we could. 1. implement https://github.com/scverse/anndata/issues/679. 2. write recarrays as dataframes. 3. make sure tests run successfully on anndata objects where `adata.uns[""rank_genes_groups_filtered""][""names""]` has been converted into a DataFrame",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61
https://github.com/scverse/scanpy/issues/62:112,deployability,instal,install,112,"Sorry about this bug in AnnData views, which have only recently been introduced. Is fixed in anndata 0.4.4 `pip install anndata --upgrade` and on the master branch: https://github.com/theislab/anndata/commit/ba9b3eed381ce427920ec67e13331d5423a5d9b3. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/62
https://github.com/scverse/scanpy/issues/62:130,deployability,upgrad,upgrade,130,"Sorry about this bug in AnnData views, which have only recently been introduced. Is fixed in anndata 0.4.4 `pip install anndata --upgrade` and on the master branch: https://github.com/theislab/anndata/commit/ba9b3eed381ce427920ec67e13331d5423a5d9b3. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/62
https://github.com/scverse/scanpy/issues/62:130,modifiability,upgrad,upgrade,130,"Sorry about this bug in AnnData views, which have only recently been introduced. Is fixed in anndata 0.4.4 `pip install anndata --upgrade` and on the master branch: https://github.com/theislab/anndata/commit/ba9b3eed381ce427920ec67e13331d5423a5d9b3. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/62
https://github.com/scverse/scanpy/issues/63:119,deployability,releas,release,119,thank you! the bug was fixed in https://github.com/theislab/scanpy/commit/a4baaaf6c29b8da4f3d9026552719039d2600ca9 and release 0.4.1: `pip install scanpy --upgrade`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63
https://github.com/scverse/scanpy/issues/63:139,deployability,instal,install,139,thank you! the bug was fixed in https://github.com/theislab/scanpy/commit/a4baaaf6c29b8da4f3d9026552719039d2600ca9 and release 0.4.1: `pip install scanpy --upgrade`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63
https://github.com/scverse/scanpy/issues/63:156,deployability,upgrad,upgrade,156,thank you! the bug was fixed in https://github.com/theislab/scanpy/commit/a4baaaf6c29b8da4f3d9026552719039d2600ca9 and release 0.4.1: `pip install scanpy --upgrade`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63
https://github.com/scverse/scanpy/issues/63:156,modifiability,upgrad,upgrade,156,thank you! the bug was fixed in https://github.com/theislab/scanpy/commit/a4baaaf6c29b8da4f3d9026552719039d2600ca9 and release 0.4.1: `pip install scanpy --upgrade`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63
https://github.com/scverse/scanpy/issues/64:104,deployability,scale,scale,104,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/64:104,energy efficiency,scale,scale,104,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/64:177,integrability,filter,filtering,177,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/64:131,interoperability,standard,standard,131,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/64:104,modifiability,scal,scale,104,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/64:104,performance,scale,scale,104,"Sorry about me having totally forgot about this. This is probably due to the fact that you're trying to scale genes that have zero standard deviation. If you do some very basic filtering, you should never run into this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64
https://github.com/scverse/scanpy/issues/65:176,deployability,automat,automatically,176,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:297,deployability,API,API,297,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:347,deployability,api,api,347,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:411,deployability,releas,release,411,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:297,integrability,API,API,297,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:347,integrability,api,api,347,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:297,interoperability,API,API,297,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:347,interoperability,api,api,347,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:164,performance,cach,cache,164,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:176,testability,automat,automatically,176,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:536,usability,help,helps,536,"Hi Jorvis! This should be very easy. Use the text file reader:. ```. adata = sc.read_text(filename).transpose(). ```. or use the general purpose reader that writes cache files automatically. ```. adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same. ```. see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:111,deployability,contain,contains,111,"Ah, ok see the problem... your example is no standard 'csv'/'table' format, as far as I see, as the first line contains the name of the index (the gene names). In this case,. ```py. adata = sc.read_text(filename, first_column_names=True).transpose(). ```. or . ```py. adata = sc.read(filename, ext='txt', first_column_names=True).transpose(). ```. should do the job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:45,interoperability,standard,standard,45,"Ah, ok see the problem... your example is no standard 'csv'/'table' format, as far as I see, as the first line contains the name of the index (the gene names). In this case,. ```py. adata = sc.read_text(filename, first_column_names=True).transpose(). ```. or . ```py. adata = sc.read(filename, ext='txt', first_column_names=True).transpose(). ```. should do the job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:68,interoperability,format,format,68,"Ah, ok see the problem... your example is no standard 'csv'/'table' format, as far as I see, as the first line contains the name of the index (the gene names). In this case,. ```py. adata = sc.read_text(filename, first_column_names=True).transpose(). ```. or . ```py. adata = sc.read(filename, ext='txt', first_column_names=True).transpose(). ```. should do the job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:34,availability,consist,consists,34,"But actually, if the first column consists in strings, passing `first_column_names` should not be necessary, and everything should work as explained in my response above. The second response should also work, but is a bit verbose. See the code [here](https://github.com/theislab/anndata/blob/eba3080e51fab9d21c73b746a32cb74284ff2e46/anndata/readwrite/read.py#L243-L255)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:34,usability,consist,consists,34,"But actually, if the first column consists in strings, passing `first_column_names` should not be necessary, and everything should work as explained in my response above. The second response should also work, but is a bit verbose. See the code [here](https://github.com/theislab/anndata/blob/eba3080e51fab9d21c73b746a32cb74284ff2e46/anndata/readwrite/read.py#L243-L255)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:71,deployability,contain,contains,71,"OK, I'll try looking through that. And, to clarify, the first *column* contains the gene names - the first *row* contains the cell names. Thanks for taking the time to respond.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:113,deployability,contain,contains,113,"OK, I'll try looking through that. And, to clarify, the first *column* contains the gene names - the first *row* contains the cell names. Thanks for taking the time to respond.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:160,performance,time,time,160,"OK, I'll try looking through that. And, to clarify, the first *column* contains the gene names - the first *row* contains the cell names. Thanks for taking the time to respond.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/issues/65:0,reliability,Doe,Does,0,Does this work for you?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65
https://github.com/scverse/scanpy/pull/68:109,energy efficiency,Cool,Cool,109,"Awesome, Gokcen, thank you! :grin:. Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:131,testability,simpl,simple,131,"Awesome, Gokcen, thank you! :grin:. Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:131,usability,simpl,simple,131,"Awesome, Gokcen, thank you! :grin:. Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:616,deployability,instal,install,616,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:124,energy efficiency,Cool,Cool,124,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:655,interoperability,plug,plugin,655,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:684,interoperability,plug,plugins,684,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:694,interoperability,plug,plugin,694,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:477,security,access,access,477,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:146,testability,simpl,simple,146,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:146,usability,simpl,simple,146,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/pull/68:1105,usability,user,user-images,1105,"> Awesome, Gokcen, thank you! . >. Thank you! . > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this. > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python. # python-igraph from master branch is required. # see https://github.com/igraph/python-igraph/issues/115. from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata). # would be also nice have access to igraph object right after sc.tl.draw_graph. g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:. # https://gephi.org/plugins/#/plugin/graphstreaming. # and start the Gephi master server. streamer = GephiGraphStreamer(). conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64. g.es['weight'] = [float(x) for x in g.es['weight']]. g.vs['groups'] = adata.obs['louvain_groups'].tolist(). streamer.post(g, conn). ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68
https://github.com/scverse/scanpy/issues/69:396,availability,state,stated,396,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:37,deployability,automat,automatic,37,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:457,deployability,updat,update,457,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:396,integrability,state,stated,396,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:357,performance,time,time-python,357,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:457,safety,updat,update,457,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:171,security,control,control,171,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:457,security,updat,update,457,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:37,testability,automat,automatic,37,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:171,testability,control,control,171,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:160,usability,user,user,160,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:309,usability,mous,mouse,309,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:369,usability,user,user,369,"Hi Benedikt! Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`. PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:10,energy efficiency,cool,cool,10,"Hi Alex,. cool thanks. btw great package, so happy I can do this in python!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:33,modifiability,pac,package,33,"Hi Alex,. cool thanks. btw great package, so happy I can do this in python!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/69:63,deployability,releas,release,63,This has been implemented in anndata 0.5 and scanpy 0.4.3. See release notes (https://scanpy.readthedocs.io). See https://github.com/theislab/anndata/commit/8cabf9c86a38d6db88c664e2ea28e3fb29bdf99e and a few fixes after that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69
https://github.com/scverse/scanpy/issues/70:20,deployability,Stack,StackOverflow,20,I also [put this on StackOverflow](https://stackoverflow.com/questions/48326579/unable-to-iterate-over-pandas-dataframe-loaded-from-tabular-data),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:43,deployability,stack,stackoverflow,43,I also [put this on StackOverflow](https://stackoverflow.com/questions/48326579/unable-to-iterate-over-pandas-dataframe-loaded-from-tabular-data),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:120,energy efficiency,load,loaded-from-tabular-data,120,I also [put this on StackOverflow](https://stackoverflow.com/questions/48326579/unable-to-iterate-over-pandas-dataframe-loaded-from-tabular-data),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:120,performance,load,loaded-from-tabular-data,120,I also [put this on StackOverflow](https://stackoverflow.com/questions/48326579/unable-to-iterate-over-pandas-dataframe-loaded-from-tabular-data),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:218,deployability,version,version,218,"For anyone else who comes across this, here is an example of how it's done:. ```py. adata = sc.read_h5ad(filename). # this is for the cancer dataset. selected = adata[:, adata.var_names.isin({'AAR2', 'ECT2'})]. # this version only works if I'm using a sparse matrix. cx = adata.X.tocoo() . for cell, gene, value in zip(adata.obs_names[cx.row], adata.var_names[cx.col], cx.data):. print(cell, gene, value). # This works for full matrix. for g, gene in enumerate(selected.var_names):. for c, cell in enumerate(selected.obs_names):. print(cell, gene, selected.X[c, g]). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:218,integrability,version,version,218,"For anyone else who comes across this, here is an example of how it's done:. ```py. adata = sc.read_h5ad(filename). # this is for the cancer dataset. selected = adata[:, adata.var_names.isin({'AAR2', 'ECT2'})]. # this version only works if I'm using a sparse matrix. cx = adata.X.tocoo() . for cell, gene, value in zip(adata.obs_names[cx.row], adata.var_names[cx.col], cx.data):. print(cell, gene, value). # This works for full matrix. for g, gene in enumerate(selected.var_names):. for c, cell in enumerate(selected.obs_names):. print(cell, gene, selected.X[c, g]). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:218,modifiability,version,version,218,"For anyone else who comes across this, here is an example of how it's done:. ```py. adata = sc.read_h5ad(filename). # this is for the cancer dataset. selected = adata[:, adata.var_names.isin({'AAR2', 'ECT2'})]. # this version only works if I'm using a sparse matrix. cx = adata.X.tocoo() . for cell, gene, value in zip(adata.obs_names[cx.row], adata.var_names[cx.col], cx.data):. print(cell, gene, value). # This works for full matrix. for g, gene in enumerate(selected.var_names):. for c, cell in enumerate(selected.obs_names):. print(cell, gene, selected.X[c, g]). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/70:25,deployability,stack,stackoverflow,25,"now you missed the sweet stackoverflow reputation, alex ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/70
https://github.com/scverse/scanpy/issues/71:219,modifiability,variab,variables,219,"`n_genes_user` is supposed to limit the length of the returned tables. however, one still needs to search all genes `n_genes` (`== X.shape[1]`) in order to get the top-scoring ones. this is the rationale behind the two variables and the naming",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/71
https://github.com/scverse/scanpy/issues/72:73,energy efficiency,current,currently,73,I would be very interested in helping to add any of these if they do not currently exist or aren't already in development.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:30,usability,help,helping,30,I would be very interested in helping to add any of these if they do not currently exist or aren't already in development.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:289,reliability,doe,does,289,"Dear both, sorry about the late response... I've become the father of twins in the past weeks... Will respond much more quickly again soon. Yes, we're working on this and will provide one solution within the next days. @tcallies could you push what you wrote? You can then tell me if this does the job for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:38,availability,avail,available,38,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:502,deployability,contain,containing,502,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1060,energy efficiency,optim,optimized,1060,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1346,energy efficiency,heat,heatmap,1346,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:890,integrability,wrap,wraps,890,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1326,integrability,wrap,wrapper,1326,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:538,interoperability,specif,specified,538,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:594,interoperability,specif,specified,594,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:737,interoperability,specif,specify,737,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:946,interoperability,specif,specify,946,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1326,interoperability,wrapper,wrapper,1326,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1502,interoperability,specif,specified,1502,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:275,modifiability,paramet,parameters,275,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1060,performance,optimiz,optimized,1060,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1074,performance,perform,performance,1074,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:38,reliability,availab,available,38,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1561,reliability,doe,does,1561,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:38,safety,avail,available,38,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:361,safety,test,testing,361,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1099,safety,test,tested,1099,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:38,security,availab,available,38,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:361,testability,test,testing,361,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1099,testability,test,tested,1099,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:84,usability,tool,tools,84,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1074,usability,perform,performance,1074,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:1277,usability,tool,tool,1277,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. . I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. . _name_list_ is a string containing gene names and should be specified. . _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data . _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:208,deployability,api,api,208,"Cool, sounds great! Thank you! I will also play around with this. Why don't you add it to the documentation? Maybe here https://github.com/theislab/scanpy/blob/980aa00adca49f6aa994a6f870ad98c3ad9218af/scanpy/api/__init__.py#L60?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:0,energy efficiency,Cool,Cool,0,"Cool, sounds great! Thank you! I will also play around with this. Why don't you add it to the documentation? Maybe here https://github.com/theislab/scanpy/blob/980aa00adca49f6aa994a6f870ad98c3ad9218af/scanpy/api/__init__.py#L60?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:208,integrability,api,api,208,"Cool, sounds great! Thank you! I will also play around with this. Why don't you add it to the documentation? Maybe here https://github.com/theislab/scanpy/blob/980aa00adca49f6aa994a6f870ad98c3ad9218af/scanpy/api/__init__.py#L60?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:208,interoperability,api,api,208,"Cool, sounds great! Thank you! I will also play around with this. Why don't you add it to the documentation? Maybe here https://github.com/theislab/scanpy/blob/980aa00adca49f6aa994a6f870ad98c3ad9218af/scanpy/api/__init__.py#L60?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:94,usability,document,documentation,94,"Cool, sounds great! Thank you! I will also play around with this. Why don't you add it to the documentation? Maybe here https://github.com/theislab/scanpy/blob/980aa00adca49f6aa994a6f870ad98c3ad9218af/scanpy/api/__init__.py#L60?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:188,interoperability,specif,specific,188,Ah! And we should also think about the naming convention here. Maybe `gene_gene_correlation`? We will have all kinds of correlation matrices floating around scanpy and we should have very specific naming conventions...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:92,interoperability,specif,specific,92,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:180,interoperability,compatib,compatibility,180,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:19,modifiability,maintain,maintain,19,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:162,modifiability,maintain,maintain,162,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:19,safety,maintain,maintain,19,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:162,safety,maintain,maintain,162,It will be hard to maintain an overview of what's going on with all the names that were not specific enough and had to be removed but still kept at some place to maintain backward compatibility.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:68,availability,cluster,cluster,68,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:98,availability,cluster,clustering,98,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:183,availability,cluster,clustermap,183,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:253,availability,cluster,clustermap,253,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:287,availability,cluster,clusters,287,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:68,deployability,cluster,cluster,68,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:98,deployability,cluster,clustering,98,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:183,deployability,cluster,clustermap,183,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:235,deployability,api,api,235,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:246,deployability,api,api,246,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:253,deployability,cluster,clustermap,253,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:287,deployability,cluster,clusters,287,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:277,energy efficiency,current,currently,277,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:235,integrability,api,api,235,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:246,integrability,api,api,246,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:235,interoperability,api,api,235,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:246,interoperability,api,api,246,"@seth-ament @jorvis Having the correlation matrix, you then want to cluster it using hierarchical clustering, right? So, in order to achieve this, shall we add this functionality to [clustermap](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.clustermap.html), which currently clusters the expression matrix itself?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:17,deployability,updat,update,17,I will certainly update my new stuff today at least once (probably more often ) and change the name / add the documentation . and then let you know as soon as the name has changed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:17,safety,updat,update,17,I will certainly update my new stuff today at least once (probably more often ) and change the name / add the documentation . and then let you know as soon as the name has changed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:17,security,updat,update,17,I will certainly update my new stuff today at least once (probably more often ) and change the name / add the documentation . and then let you know as soon as the name has changed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:110,usability,document,documentation,110,I will certainly update my new stuff today at least once (probably more often ) and change the name / add the documentation . and then let you know as soon as the name has changed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:54,availability,avail,available,54,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:54,reliability,availab,available,54,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:54,safety,avail,available,54,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:54,security,availab,available,54,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:95,availability,cluster,clusters,95,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:121,availability,cluster,clusters,121,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:177,availability,cluster,cluster,177,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:95,deployability,cluster,clusters,95,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:121,deployability,cluster,clusters,121,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:177,deployability,cluster,cluster,177,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:216,energy efficiency,profil,profile,216,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:216,performance,profil,profile,216,"Yes, thanks so much. This looks great. Typically, we cut the hierarchical tree to produce gene clusters, summarize these clusters as the mean expression of the genes within the cluster, then pass the mean expression profile to plotting functions like coloring tSNE plots and violin plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,deployability,updat,updates,4,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,safety,updat,updates,4,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,security,updat,updates,4,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:54,usability,tool,tool,54,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:59,usability,UI,UI,59,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:108,deployability,version,version,108,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:100,energy efficiency,current,current,100,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:108,integrability,version,version,108,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:27,interoperability,skeleton,skeleton,27,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:63,interoperability,share,share,63,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:108,modifiability,version,version,108,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:7,reliability,doe,does,7,Hi alldoes anybody have a skeleton snippet they're willing to share here on how to run this in the current version of Scanpy? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:742,energy efficiency,cool,cool,742,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:121,testability,simpl,simple,121,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:121,usability,simpl,simple,121,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:246,usability,visual,visualizing,246,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:583,usability,tool,tools,583,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:789,usability,clear,clearly,789,"Unfortunately, all of this discussion here was not really further pursued, I have to admit. In principle, these are very simple things. However, I'm a bit afraid of offering a canonical function as I fear that there are also a lot of bad ways of visualizing gene correlation plots and I don't feel capable of judging this. If no one else wants to make a pull request for that (maybe using what @tcallies already did, but I fear it's not really serving the purpose of the discussion here: [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/tools/top_genes.py), [here](https://github.com/theislab/scanpy/blob/8e06ff6ecfab892240b58d2206e461685216a926/scanpy/plotting/top_genes_visual.py)) it would be cool if someone sent me an example case, which clearly shows what you want. Maybe @jorvis, you can send images for the examples you have in mind?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:353,deployability,modul,module,353,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:506,deployability,modul,module,506,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:353,modifiability,modul,module,353,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:506,modifiability,modul,module,506,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:353,safety,modul,module,353,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:506,safety,modul,module,506,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:264,testability,Trace,Traceback,264,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:521,usability,tool,tools,521,"Hello @tcallies @falexwolf @flying-sheep . Somehow, it looks like `sc.tl.correlation_matrix` was removed from scanpy? ```python. sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError Traceback (most recent call last). ~\AppData\Local\Temp/ipykernel_3196/1400689712.py in <module>. ----> 1 sc.tl.correlation_matrix(adata_sub2, name_list=['SMARCA4', 'TP53'], n_genes=20, annotation_key=None, method='pearson'). AttributeError: module 'scanpy.tools' has no attribute 'correlation_matrix'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:5,availability,error,error,5,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:5,performance,error,error,5,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:5,safety,error,error,5,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:5,usability,error,error,5,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:57,usability,tool,tools,57,"A very dodgy workaround would be. ```Python. from scanpy.tools import _top_genes. from scanpy.plotting import _anndata. _top_genes.correlation_matrix(adata, names, annotation_key=None, method='pearson'). _anndata.correlation_matrix(adata, groupby='leiden'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,deployability,updat,updates,4,Any updates on this? Has `correlation_matrix()` been removed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,safety,updat,updates,4,Any updates on this? Has `correlation_matrix()` been removed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/72:4,security,updat,updates,4,Any updates on this? Has `correlation_matrix()` been removed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72
https://github.com/scverse/scanpy/issues/73:204,deployability,version,version,204,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:297,deployability,version,version,297,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:204,integrability,version,version,204,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:297,integrability,version,version,297,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:204,modifiability,version,version,204,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:297,modifiability,version,version,297,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:64,usability,document,documentation,64,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:264,usability,visual,visualize,264,The figures directory can be set using - I will add this to the documentation... ```. sc.settings.figdir = 'whateverpathyoulike'. ```. The default is './figures/'. You only get to save the non-normalized version as this is what Cell Ranger and Seurat allow you to visualize. Do you need the other version? I can easily add this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:128,deployability,pipelin,pipeline,128,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:128,integrability,pipelin,pipeline,128,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:79,security,access,access,79,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:208,usability,user,user,208,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:230,usability,command,commands,230,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:348,availability,cluster,cluster,348,"How images are saved has also improved in Scanpy 1.0 and produces less white space etc.. In addition, you can set `sc.settings.autosave = True` and this will automatically save all images instead of showing them, see [here](https://github.com/theislab/scanpy_usage/blob/3ba68ab52ee4e5db39da13f449b575402f404df4/170522_visualizing_one_million_cells/cluster.py#L7).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:158,deployability,automat,automatically,158,"How images are saved has also improved in Scanpy 1.0 and produces less white space etc.. In addition, you can set `sc.settings.autosave = True` and this will automatically save all images instead of showing them, see [here](https://github.com/theislab/scanpy_usage/blob/3ba68ab52ee4e5db39da13f449b575402f404df4/170522_visualizing_one_million_cells/cluster.py#L7).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:348,deployability,cluster,cluster,348,"How images are saved has also improved in Scanpy 1.0 and produces less white space etc.. In addition, you can set `sc.settings.autosave = True` and this will automatically save all images instead of showing them, see [here](https://github.com/theislab/scanpy_usage/blob/3ba68ab52ee4e5db39da13f449b575402f404df4/170522_visualizing_one_million_cells/cluster.py#L7).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/73:158,testability,automat,automatically,158,"How images are saved has also improved in Scanpy 1.0 and produces less white space etc.. In addition, you can set `sc.settings.autosave = True` and this will automatically save all images instead of showing them, see [here](https://github.com/theislab/scanpy_usage/blob/3ba68ab52ee4e5db39da13f449b575402f404df4/170522_visualizing_one_million_cells/cluster.py#L7).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73
https://github.com/scverse/scanpy/issues/74:35,deployability,automat,automatic,35,"Hi Elisabetta,. this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. An easy work around is to call. ```. adata.obs['cell_groups'] = anno['cell_groups'].values. ```. as then, the index is ignored. Or you do the following directly:. ```. adata.obs = anno. ```. Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... Hope this helps. Let me know if our convention for building the indices of AnnData is not a good one... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:693,deployability,build,building,693,"Hi Elisabetta,. this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. An easy work around is to call. ```. adata.obs['cell_groups'] = anno['cell_groups'].values. ```. as then, the index is ignored. Or you do the following directly:. ```. adata.obs = anno. ```. Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... Hope this helps. Let me know if our convention for building the indices of AnnData is not a good one... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:35,testability,automat,automatic,35,"Hi Elisabetta,. this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. An easy work around is to call. ```. adata.obs['cell_groups'] = anno['cell_groups'].values. ```. as then, the index is ignored. Or you do the following directly:. ```. adata.obs = anno. ```. Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... Hope this helps. Let me know if our convention for building the indices of AnnData is not a good one... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:156,usability,behavi,behavior,156,"Hi Elisabetta,. this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. An easy work around is to call. ```. adata.obs['cell_groups'] = anno['cell_groups'].values. ```. as then, the index is ignored. Or you do the following directly:. ```. adata.obs = anno. ```. Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... Hope this helps. Let me know if our convention for building the indices of AnnData is not a good one... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:652,usability,help,helps,652,"Hi Elisabetta,. this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. An easy work around is to call. ```. adata.obs['cell_groups'] = anno['cell_groups'].values. ```. as then, the index is ignored. Or you do the following directly:. ```. adata.obs = anno. ```. Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... Hope this helps. Let me know if our convention for building the indices of AnnData is not a good one... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:222,availability,error,errors,222,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:233,interoperability,standard,standard,233,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:222,performance,error,errors,222,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:222,safety,error,errors,222,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:444,safety,input,inputs,444,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:64,usability,user,user,64,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:184,usability,help,help,184,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:209,usability,command,commands,209,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:222,usability,error,errors,222,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:288,usability,tool,tools,288,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:444,usability,input,inputs,444,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:490,usability,document,documentation,490,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:514,usability,help,helpful,514,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. . Cheers, . Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:378,usability,help,help,378,"You can google everything in Python as well, you should end up on the following pages... at least if you add ""pandas"" or ""numpy"" to your search term... http://pandas.pydata.org/pandas-docs/stable/. https://docs.scipy.org/doc/numpy-1.13.0/reference/. Don't you get there? The docs there should be at least as good as the Scanpy docs... PS: In Jupyter notebooks, you can also get help by pressing ""Shift + Tab"" twice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:730,security,auth,authored,730,"Yes, I know that.. but I was referring to new libraries such as your scanpy. > On 07 Feb 2018, at 16:48, Alex Wolf <notifications@github.com> wrote:. > . > You can google everything in Python as well, you should end up on the following pages... at least if you add ""pandas"" or ""numpy"" to your search term... > http://pandas.pydata.org/pandas-docs/stable/ <http://pandas.pydata.org/pandas-docs/stable/>. > https://docs.scipy.org/doc/numpy-1.13.0/reference/ <https://docs.scipy.org/doc/numpy-1.13.0/reference/>. > Don't you get there? The docs there should be at least as good as the Scanpy docs... > . > PS: In Jupyter notebooks, you can also get help by pressing ""Shift + Tab"" twice. > . > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub <https://github.com/theislab/scanpy/issues/74#issuecomment-363811584>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ATrry-J6GapAinea12bqhcDfiqghcKuOks5tScXRgaJpZM4R6xBm>. > .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:937,security,auth,auth,937,"Yes, I know that.. but I was referring to new libraries such as your scanpy. > On 07 Feb 2018, at 16:48, Alex Wolf <notifications@github.com> wrote:. > . > You can google everything in Python as well, you should end up on the following pages... at least if you add ""pandas"" or ""numpy"" to your search term... > http://pandas.pydata.org/pandas-docs/stable/ <http://pandas.pydata.org/pandas-docs/stable/>. > https://docs.scipy.org/doc/numpy-1.13.0/reference/ <https://docs.scipy.org/doc/numpy-1.13.0/reference/>. > Don't you get there? The docs there should be at least as good as the Scanpy docs... > . > PS: In Jupyter notebooks, you can also get help by pressing ""Shift + Tab"" twice. > . > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub <https://github.com/theislab/scanpy/issues/74#issuecomment-363811584>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ATrry-J6GapAinea12bqhcDfiqghcKuOks5tScXRgaJpZM4R6xBm>. > .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:646,usability,help,help,646,"Yes, I know that.. but I was referring to new libraries such as your scanpy. > On 07 Feb 2018, at 16:48, Alex Wolf <notifications@github.com> wrote:. > . > You can google everything in Python as well, you should end up on the following pages... at least if you add ""pandas"" or ""numpy"" to your search term... > http://pandas.pydata.org/pandas-docs/stable/ <http://pandas.pydata.org/pandas-docs/stable/>. > https://docs.scipy.org/doc/numpy-1.13.0/reference/ <https://docs.scipy.org/doc/numpy-1.13.0/reference/>. > Don't you get there? The docs there should be at least as good as the Scanpy docs... > . > PS: In Jupyter notebooks, you can also get help by pressing ""Shift + Tab"" twice. > . > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub <https://github.com/theislab/scanpy/issues/74#issuecomment-363811584>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ATrry-J6GapAinea12bqhcDfiqghcKuOks5tScXRgaJpZM4R6xBm>. > .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:564,deployability,releas,release,564,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:658,deployability,releas,release,658,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1050,deployability,modul,modular,1050,"ral differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1241,deployability,pipelin,pipeline,1241,"st, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to clos",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1498,deployability,pipelin,pipeline,1498,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1718,energy efficiency,adapt,adapting,1718,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1050,integrability,modular,modular,1050,"ral differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1241,integrability,pipelin,pipeline,1241,"st, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to clos",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1498,integrability,pipelin,pipeline,1498,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1718,integrability,adapt,adapting,1718,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:87,interoperability,standard,standards,87,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1480,interoperability,standard,standard,1480,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1718,interoperability,adapt,adapting,1718,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:23,modifiability,concern,concern,23,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:112,modifiability,pac,packages,112,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:127,modifiability,pac,packages,127,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:290,modifiability,pac,packages,290,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:367,modifiability,pac,package,367,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:602,modifiability,pac,package,602,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:649,modifiability,pac,packages,649,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:811,modifiability,pac,package,811,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1050,modifiability,modul,modular,1050,"ral differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1262,modifiability,pac,packages,1262,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1718,modifiability,adapt,adapting,1718,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:2076,modifiability,pac,packages,2076,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:2095,performance,time,time,2095,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1881,reliability,doe,does,1881,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1050,safety,modul,modular,1050,"ral differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:241,security,attest,attest,241,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1695,security,barrier,barrier,1695,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:23,testability,concern,concern,23,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:894,testability,understand,understand,894,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1050,testability,modula,modular,1050,"ral differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1565,testability,understand,understand,1565,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:2120,testability,understand,understand,2120,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:73,usability,document,documentation,73,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:347,usability,document,documenting,347,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:775,usability,help,helping,775,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:838,usability,document,documentation,838,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1357,usability,navigat,navigate,1357,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1712,usability,user,users,1712,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1927,usability,user,users,1927,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:2028,usability,user,user-base,2028,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:2241,usability,close,close,2241,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:256,deployability,observ,observation,256,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:74,modifiability,pac,package,74,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:298,safety,prevent,prevents,298,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:298,security,preven,prevents,298,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:157,testability,understand,understand,157,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:256,testability,observ,observation,256,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:38,usability,help,helping,38,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:101,usability,document,documentation,101,"> Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. thats a cultural observation, not a technical one. nothing prevents people from writing great notebook-based vignettes (as alex proves)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:755,availability,down,download,755,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:853,integrability,coupl,couple,853,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:133,interoperability,standard,standards,133,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:407,interoperability,Standard,Standards,407,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:428,modifiability,pac,packages,428,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:853,modifiability,coupl,couple,853,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:885,modifiability,pac,packages,885,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:347,performance,time,time,347,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:918,performance,time,time,918,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:195,reliability,doe,does,195,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:748,testability,simpl,simply,748,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:853,testability,coupl,couple,853,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:47,usability,document,documentation,47,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:386,usability,document,documentation,386,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:481,usability,learn,learn,481,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:748,usability,simpl,simply,748,"Thank you for these thoughts! I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:18,deployability,build,build,18,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:675,deployability,Instal,Installation,675,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:692,deployability,instal,installation,692,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:713,deployability,API,API,713,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:721,deployability,api,api,721,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:923,deployability,Instal,Installation,923,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:990,deployability,instal,installation,990,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1011,deployability,API,API,1011,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1069,deployability,api,api,1069,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:713,integrability,API,API,713,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:721,integrability,api,api,721,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1011,integrability,API,API,1011,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1069,integrability,api,api,1069,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:713,interoperability,API,API,713,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:721,interoperability,api,api,721,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1011,interoperability,API,API,1011,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1069,interoperability,api,api,1069,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:418,usability,navigat,navigation,418,"OK, so we want to build and upload the notebooks. With a bit of convincing, we can get readthedocs to do that for us. But (for a good reason) `scanpy_usage` is a different repo. This means:. 1. Changing something there should trigger a rebuild, not changing the scanpy repo. 2. We probably need to put them on https://scanpy_usage.readthedocs.io. 3. We can convince sphinx to create an index entry for the docs in the navigation sidebar that leads to the scanpy_usage site. Then it would look like this:. https://scanpy.readthedocs.io:. - Examples  Converted to a fake index entry that is a link to https://scanpy_usage.readthedocs.io. - Basic Usage  /basic_usage.html. - Installation  /installation.html. - API  /api/index.html. - References  /references.html. https://scanpy_usage.readthedocs.io:. - Examples  /index.html. - Basic Usage  Fake index extry to https://scanpy.readthedocs.io//basic_usage.html. - Installation  Fake index extry to https://scanpy.readthedocs.io//installation.html. - API  Fake index extry to https://scanpy.readthedocs.io//api/index.html. - References  Fake index extry to https://scanpy.readthedocs.io//references.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:60,availability,slo,slowly,60,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:99,availability,down,download,99,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:512,availability,down,download,512,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:129,deployability,automat,automatically,129,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:152,deployability,build,build,152,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:60,reliability,slo,slowly,60,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:231,safety,test,testing,231,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:129,testability,automat,automatically,129,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:231,testability,test,testing,231,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:473,usability,user,user,473,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:154,energy efficiency,draw,draw,154,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:504,interoperability,standard,standard,504,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:428,modifiability,pac,packages,428,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:166,usability,user,users,166,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:188,usability,minim,minimal,188,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:339,usability,document,documentation,339,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:406,usability,experien,experience,406,"Fantastic that this is all getting thought about! :). Obviously this isn't an overnight thing, it's just something worth thinking about if the hope is to draw in new users (ie. those with minimal computational skills and limited knowledge of scRNA-Seq analysis). I think much of Monocle and Seurat's popularity owes to their comprehensive documentation. I've seen many people with little-to-no programming experience pick these packages up and give them a shot. No reason why Scanpy can't be a new ""gold standard"" for the field :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:185,deployability,automat,automation,185,"> Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... ive seen it, it looks really nice! but yes, automation would be cool! Then wed never forget to add a new notebook to the list, or get outdated info somewhere and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:205,energy efficiency,cool,cool,205,"> Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... ive seen it, it looks really nice! but yes, automation would be cool! Then wed never forget to add a new notebook to the list, or get outdated info somewhere and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:185,testability,automat,automation,185,"> Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... ive seen it, it looks really nice! but yes, automation would be cool! Then wed never forget to add a new notebook to the list, or get outdated info somewhere and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:43,deployability,automat,automatic,43,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:763,deployability,build,building,763,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1005,integrability,sub,subset,1005,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:43,testability,automat,automatic,43,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:164,usability,behavi,behavior,164,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:716,usability,help,helps,716,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1105,usability,user,user-images,1105,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/issues/74:1250,usability,user,user-images,1250,"> Hi Elisabetta,. > . > this is related to automatic matching of indices in dataframes. If the indices don't match, you'll not assign anything. This is the generic behavior of pandas. > . > If your `anno` dataframe has a different index as compared to the `adata.obs` dataframe, then you cannot meaningfully assign values. > . > An easy work around is to call. > . > ```. > adata.obs['cell_groups'] = anno['cell_groups'].values. > ```. > . > as then, the index is ignored. > . > Or you do the following directly:. > . > ```. > adata.obs = anno. > ```. > . > Or you init the index of `adata.obs` with the cell names in `anno`: either via `adata.obs.index` or `adata.obs_names`. It's the same thing... > . > Hope this helps. > . > Let me know if our convention for building the indices of AnnData is not a good one... > . > Cheers, Alex. Hi! I am not sure if this forum is still open or not, but I had a similar question about my code. . Basically, my indices (rows) do not have a ""name"" and I am trying to subset off it. Is there anyway to do this? Thanks! ![Screen Shot 2022-01-16 at 10 21 19 PM](https://user-images.githubusercontent.com/97864137/149703124-497ef65e-4d3a-4c45-bd12-45ef67f5d543.png). ![Screen Shot 2022-01-16 at 10 21 31 PM](https://user-images.githubusercontent.com/97864137/149703138-aa2ae8bf-4506-47ba-9bc1-8f5f25e8ad7d.png). Hi! I am not sure if this forum is still open or not, but I had a similar question about my code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74
https://github.com/scverse/scanpy/pull/76:225,deployability,modul,module,225,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:621,energy efficiency,cool,cool,621,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:885,energy efficiency,cool,cool,885,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:676,integrability,sub,subdirectory,676,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:1134,interoperability,specif,specified,1134,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:225,modifiability,modul,module,225,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:1093,modifiability,paramet,parameters,1093,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:225,safety,modul,module,225,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:837,safety,test,test,837,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:180,security,auth,author,180,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:344,testability,Simpl,Simply,344,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:837,testability,test,test,837,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:344,usability,Simpl,Simply,344,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:1129,usability,user,user-specified,1129,"Hi Davide! Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,. Alex.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:88,deployability,api,api,88,"I've now also added this to the [documentation](https://scanpy.readthedocs.io/en/latest/api/index.html#tools-tl) so that we see how ""it looks"". Do you think the naming convention is good like that? Or shall we rather make it `score_gene_sets` and `score_genes_cell_cycle` [more symmetry and more rigour in naming?]. Now we can easily change this without having to worry about backwards compat... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:88,integrability,api,api,88,"I've now also added this to the [documentation](https://scanpy.readthedocs.io/en/latest/api/index.html#tools-tl) so that we see how ""it looks"". Do you think the naming convention is good like that? Or shall we rather make it `score_gene_sets` and `score_genes_cell_cycle` [more symmetry and more rigour in naming?]. Now we can easily change this without having to worry about backwards compat... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:88,interoperability,api,api,88,"I've now also added this to the [documentation](https://scanpy.readthedocs.io/en/latest/api/index.html#tools-tl) so that we see how ""it looks"". Do you think the naming convention is good like that? Or shall we rather make it `score_gene_sets` and `score_genes_cell_cycle` [more symmetry and more rigour in naming?]. Now we can easily change this without having to worry about backwards compat... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:33,usability,document,documentation,33,"I've now also added this to the [documentation](https://scanpy.readthedocs.io/en/latest/api/index.html#tools-tl) so that we see how ""it looks"". Do you think the naming convention is good like that? Or shall we rather make it `score_gene_sets` and `score_genes_cell_cycle` [more symmetry and more rigour in naming?]. Now we can easily change this without having to worry about backwards compat... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:103,usability,tool,tools-tl,103,"I've now also added this to the [documentation](https://scanpy.readthedocs.io/en/latest/api/index.html#tools-tl) so that we see how ""it looks"". Do you think the naming convention is good like that? Or shall we rather make it `score_gene_sets` and `score_genes_cell_cycle` [more symmetry and more rigour in naming?]. Now we can easily change this without having to worry about backwards compat... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:178,availability,operat,operators,178,"@falexwolf I'm glad you merged. A couple of things. - ok for the name change. I see you have a different naming and syntax style, I'll try to stick to that (e.g. no space around operators). - I do not have any notebook ready, I'll prepare one. - As for the gene list, I used the Regev lab one, I'm adding that into the notebook. - I will try to explain how the comparison works. I actually had to figure it out myself, as reverse engineering `R` code is far beyond human capabilities :-). - you don't have to apologize for being late. I'm father of two and I haven't worked after 21:00 since my first was born 7 years ago",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:34,integrability,coupl,couple,34,"@falexwolf I'm glad you merged. A couple of things. - ok for the name change. I see you have a different naming and syntax style, I'll try to stick to that (e.g. no space around operators). - I do not have any notebook ready, I'll prepare one. - As for the gene list, I used the Regev lab one, I'm adding that into the notebook. - I will try to explain how the comparison works. I actually had to figure it out myself, as reverse engineering `R` code is far beyond human capabilities :-). - you don't have to apologize for being late. I'm father of two and I haven't worked after 21:00 since my first was born 7 years ago",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:34,modifiability,coupl,couple,34,"@falexwolf I'm glad you merged. A couple of things. - ok for the name change. I see you have a different naming and syntax style, I'll try to stick to that (e.g. no space around operators). - I do not have any notebook ready, I'll prepare one. - As for the gene list, I used the Regev lab one, I'm adding that into the notebook. - I will try to explain how the comparison works. I actually had to figure it out myself, as reverse engineering `R` code is far beyond human capabilities :-). - you don't have to apologize for being late. I'm father of two and I haven't worked after 21:00 since my first was born 7 years ago",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:34,testability,coupl,couple,34,"@falexwolf I'm glad you merged. A couple of things. - ok for the name change. I see you have a different naming and syntax style, I'll try to stick to that (e.g. no space around operators). - I do not have any notebook ready, I'll prepare one. - As for the gene list, I used the Regev lab one, I'm adding that into the notebook. - I will try to explain how the comparison works. I actually had to figure it out myself, as reverse engineering `R` code is far beyond human capabilities :-). - you don't have to apologize for being late. I'm father of two and I haven't worked after 21:00 since my first was born 7 years ago",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:240,availability,state,statements,240,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:259,availability,operat,operators,259,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:396,deployability,modul,module,396,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:462,energy efficiency,model,model,462,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:240,integrability,state,statements,240,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:396,modifiability,modul,module,396,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:396,safety,modul,module,396,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:462,security,model,model,462,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:894,usability,tool,tools,894,"@dawe . - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments. - thank you for a notebook! - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point. - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/pull/76:83,testability,regress,regression,83,"@falexwolf I've added a silly notebook in the scanpy_usage repo showing cell cycle regression, pretty much following most important bits of [Seurat's vignette](http://satijalab.org/seurat/cell_cycle_vignette.html#assign-cell-cycle-scores). Note that this will work only after the scoring function code will be fixed. As mentioned in #82 , when my functions were merged and names changed, not all calls were renamed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76
https://github.com/scverse/scanpy/issues/77:35,deployability,fail,fails,35,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:245,energy efficiency,core,core,245,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:368,energy efficiency,core,core,368,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:504,energy efficiency,core,core,504,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:660,energy efficiency,core,core,660,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:93,modifiability,pac,packages,93,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:229,modifiability,pac,packages,229,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:352,modifiability,pac,packages,352,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:488,modifiability,pac,packages,488,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:644,modifiability,pac,packages,644,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:35,reliability,fail,fails,35,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:743,reliability,doe,does,743,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:809,reliability,doe,does,809,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:123,testability,simpl,simple,123,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:123,usability,simpl,simple,123,"There's my initial attempt, but it fails with:. ```pytb. File ""/usr/local/lib/python3.6/dist-packages/scanpy/preprocessing/simple.py"", line 169, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. If it isn't obvious to you what's wrong I'll return to it after my conference this weekend. Every hour is critical right now. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:14,safety,compl,complete,14,Is this issue complete? It seems like the bug has been fixed after 96890730972162aa531c3289b38ad728a7585c85,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:14,security,compl,complete,14,Is this issue complete? It seems like the bug has been fixed after 96890730972162aa531c3289b38ad728a7585c85,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/77:45,usability,close,close,45,"@falexwolf reported it as a fix, yes. I will close.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/77
https://github.com/scverse/scanpy/issues/1:1134,deployability,modul,module,1134,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:640,energy efficiency,adapt,adapted,640,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:640,integrability,adapt,adapted,640,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:640,interoperability,adapt,adapted,640,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:640,modifiability,adapt,adapted,640,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:1134,modifiability,modul,module,1134,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:1134,safety,modul,module,1134,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:429,security,attack,attack,429,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:213,testability,simpl,simply,213,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:673,testability,simpl,simply,673,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:90,usability,efficien,efficient,90,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:191,usability,help,help,191,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:213,usability,simpl,simply,213,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:673,usability,simpl,simply,673,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind. 1. yes, that's important - can i help? 2. that's easy, simply put it in smp as a multicolumn object. 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*. ---. *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:159,usability,tool,tool,159,"Generally: What shall I do in order to merge ann_matrix as quickly as possible with the master branch? Starting from tomorrow, fiona would like to work on one tool using the nestorowa16 case i mentioned before. So if you allow me, I'll try to get everything running and polished tonight. . PS: During the day, I'll be offline.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/issues/1:322,usability,person,person,322,"damn, I'm not fit enough to make ann_matrix work tonight. so, in order to get figures, analysis and a barebone code for fiona ready (we have a skype conference with fabian and the group in cambridge tomorrow at 11am, and fabian is quite pushy), i'll use the working master branch. let's discuss merging with ann_matrix in person during the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1
https://github.com/scverse/scanpy/pull/2:216,deployability,continu,continuous,216,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/pull/2:276,energy efficiency,adapt,adapt,276,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/pull/2:142,integrability,sub,subgroups,142,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/pull/2:276,integrability,adapt,adapt,276,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/pull/2:276,interoperability,adapt,adapt,276,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/pull/2:276,modifiability,adapt,adapt,276,"no, not great, but it work's and one should now be much better settled for the future with AnnData. for example, the gene plots and different subgroups work. if you have a good suggestion for a default color map for continuous and categorial columns in smp, I'm very happy to adapt it. :). https://github.com/falexwolf/collab_alex/blob/master/scanpy/examples/maehr17.md. or here directly in the main readme. https://github.com/theislab/scanpy#moignard15",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2
https://github.com/scverse/scanpy/issues/3:24,deployability,observ,observe,24,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:223,deployability,continu,continuous,223,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:167,energy efficiency,green,green,167,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:327,energy efficiency,reduc,reduces,327,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:59,interoperability,distribut,distribution,59,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:24,testability,observ,observe,24,"haha with ease. you can observe the inhomogeneous contrast distribution with C2 and C10 there: the colors are indistinguishable dark blue while C7 and C8 go from snot green all the way to orange. that would be horrible for continuous data, but merely makes C2 and C10 indistinguishable for categorical colors and unnecessarily reduces contrast there (as its a color map and no palette).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:196,performance,content,content,196,"check out e.g. color brewers paired, which has 12 easily distinguishable colors (although that yellow is a bit light for a white background):. ![color brewer qual](http://moderndata.plot.ly/wp-content/uploads/2015/04/qual-500x127.jpg)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,deployability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,integrability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,interoperability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,modifiability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,reliability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,security,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/3:45,testability,integr,integrating,45,"looks good, let's take one these. but before integrating it, the scatter plot of dpt should invoke `plotting.plot_tool` as well. then it's going to be just a one line change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3
https://github.com/scverse/scanpy/issues/4:417,deployability,updat,update,417,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:25,integrability,rout,route,25,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:172,integrability,filter,filter,172,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:334,integrability,filter,filtered,334,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:417,safety,updat,update,417,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:417,security,updat,update,417,"i guess we could go this route:. ```py. mean_filter = 0.01. cv_filter = 2. nr_pcs = 50. # row normalize . adata = adata.smp_norm(max_fraction=0.05, mult_with_mean=True). # filter out genes with mean expression < 0.1 and coefficient of variance < . # cvFilter . adata = adata.filter_var_cv(mean_filter, cv_filter). # compute zscore of filtered matrix . Xz = zscore(adata.X). # PCA . Xpca = pca(Xz, nr_comps=nr_pcs). # update dictionary. adata['Xpca'] = Xpca. sett.m(0, 'Xpca has shape', Xpca.shape[0], 'x', Xpca.shape[1]). print(adata.X). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:127,integrability,filter,filtering,127,obviously we shouldnt kitchen-sink everything in there but maybe it would be useful to have the most common normalization and filtering procedures on there. or go with a subclass of AnnData that has them.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:171,integrability,sub,subclass,171,obviously we shouldnt kitchen-sink everything in there but maybe it would be useful to have the most common normalization and filtering procedures on there. or go with a subclass of AnnData that has them.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:461,availability,error,errors,461,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:673,availability,error,error,673,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:79,integrability,sub,subclass,79,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:461,performance,error,errors,461,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:673,performance,error,error,673,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:461,safety,error,errors,461,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:673,safety,error,error,673,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:108,usability,prefer,prefer,108,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:461,usability,error,errors,461,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:673,usability,error,error,673,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:173,availability,state,state,173,"> something like `adata.var = adata.var[gene_filter]` should work. i disagree. `adata = adata[:, gene_filter]` should work. the object shouldnt be able to be in an invalid state.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:173,integrability,state,state,173,"> something like `adata.var = adata.var[gene_filter]` should work. i disagree. `adata = adata[:, gene_filter]` should work. the object shouldnt be able to be in an invalid state.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/4:43,usability,person,person,43,"ok, of course this right, let's discuss in person.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4
https://github.com/scverse/scanpy/issues/7:373,deployability,updat,updated,373,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:317,energy efficiency,current,currently,317,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:74,modifiability,pac,package,74,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:211,modifiability,Pac,Packaging,211,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:98,safety,test,testing,98,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:373,safety,updat,updated,373,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:373,security,updat,updated,373,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:98,testability,test,testing,98,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated! Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:109,modifiability,pac,package,109,Nice! Could you please write here once you're done with the major changes? I'm looking forward to using this package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:27,availability,state,state,27,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:181,deployability,Version,Versioning,181,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:27,integrability,state,state,27,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:181,integrability,Version,Versioning,181,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:46,modifiability,pac,package,46,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:140,modifiability,pac,package,140,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:181,modifiability,Version,Versioning,181,"Hi Pawel, we now reached a state in which the package structure will not be fundamentally reorganized anymore. We will actively develop the package further on development branches. Versioning will hopefully start soon, too. If you have any questions, I'm happy to answer them!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:33,performance,time,time,33,"Thanks! Hopefully I'll find some time to test it out this week, I'll get back to you once I do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:41,safety,test,test,41,"Thanks! Hopefully I'll find some time to test it out this week, I'll get back to you once I do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:41,testability,test,test,41,"Thanks! Hopefully I'll find some time to test it out this week, I'll get back to you once I do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1043,availability,error,error,1043,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1188,availability,error,error,1188,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:19,deployability,instal,install,19,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:83,deployability,instal,install,83,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:161,deployability,updat,update,161,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:172,deployability,Instal,Installation,172,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:289,deployability,instal,install,289,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:311,deployability,instal,installation,311,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:324,deployability,fail,failed,324,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:465,deployability,build,build,465,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1176,deployability,fail,failed,1176,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1222,deployability,build,build,1222,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1258,deployability,instal,install,1258,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1268,deployability,upgrad,upgrade,1268,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:262,integrability,repositor,repository,262,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:262,interoperability,repositor,repository,262,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1011,interoperability,standard,standard,1011,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:31,modifiability,pac,package,31,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1050,modifiability,pac,package,1050,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1268,modifiability,upgrad,upgrade,1268,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1043,performance,error,error,1043,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1188,performance,error,error,1188,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1281,performance,cach,cache-dir,1281,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:324,reliability,fail,failed,324,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1081,reliability,doe,does,1081,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1176,reliability,fail,failed,1176,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:161,safety,updat,update,161,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:472,safety,Compl,Complete,472,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1043,safety,error,error,1043,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1188,safety,error,error,1188,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:161,security,updat,update,161,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:472,security,Compl,Complete,472,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:493,usability,command,command,493,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1043,usability,error,error,1043,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1141,usability,Command,Command,1141,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1188,usability,error,error,1188,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:1234,usability,command,command,1234,"So I just tried to install the package from the master branch by running. ```. pip install git+https://github.com/theislab/scanpy.git. ```. (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build. Complete output from command python setup.py egg_info:. running egg_info. creating pip-egg-info/scanpy.egg-info. writing pip-egg-info/scanpy.egg-info/PKG-INFO. writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt. writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt. writing requirements to pip-egg-info/scanpy.egg-info/requires.txt. writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt. writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'. warning: manifest_maker: standard file '-c' not found. . error: package directory 'scanpy/exs' does not exist. . ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/. The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:75,deployability,instal,install,75,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:152,deployability,instal,install,152,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:226,deployability,version,versioning,226,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:316,deployability,automat,automatically,316,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:330,deployability,updat,update,330,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:350,deployability,instal,installation,350,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:226,integrability,version,versioning,226,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:226,modifiability,version,versioning,226,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:330,safety,updat,update,330,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:330,security,updat,update,330,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:316,testability,automat,automatically,316,"Sorry for that, fixed this bug. I think there is no way to make . ```. pip install git+https://github.com/theislab/scanpy.git. ```. work if you want to install using symbolic links (to your local clone of the git repo). Until versioning starts, it's good to be able to type `git pull` in the local clone and by that automatically update the `scanpy` installation without having to do anything else. But you're right, this is should just be a temporary solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/7:44,usability,experien,experience,44,Good! Looking forward to reading about your experience.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7
https://github.com/scverse/scanpy/issues/15:13,deployability,releas,release,13,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:52,deployability,upgrad,upgrade,52,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:69,deployability,version,version,69,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:201,deployability,instal,installed,201,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:69,integrability,version,version,69,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:52,modifiability,upgrad,upgrade,52,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:69,modifiability,version,version,69,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:40,deployability,releas,released,40,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:57,deployability,version,version,57,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:72,deployability,releas,release,72,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:57,integrability,version,version,57,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:57,modifiability,version,version,57,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:85,testability,simpl,simply,85,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:85,usability,simpl,simply,85,"as soon as `0.1` is ready, this will be released and the version of the release will simply be `0.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:18,deployability,version,versions,18,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:119,deployability,version,version,119,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:18,integrability,version,versions,18,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:119,integrability,version,version,119,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:18,modifiability,version,versions,18,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:119,modifiability,version,version,119,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:86,usability,clear,clear,86,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/15:100,usability,user,user,100,"later development versions will then again show `0.1+NUMCOMMITS.gHASH` and it will be clear for the user which kind of version she/he uses. i think it makes sense, do you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15
https://github.com/scverse/scanpy/issues/16:88,usability,command,command,88,"yes! i will look into that. i just started using something different than emacs and the command line. so, yes, it wasn't very thoughtful to put such settings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:19,deployability,automat,automatic,19,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:403,deployability,log,logs,403,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:493,deployability,fail,fail,493,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:56,energy efficiency,Current,Currently,56,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:643,modifiability,variab,variable,643,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:284,performance,time,time,284,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:493,reliability,fail,fail,493,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:403,safety,log,logs,403,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:324,security,session,session,324,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:403,security,log,logs,403,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:415,security,ssh,ssh,415,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:693,security,ssh,ssh,693,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:19,testability,automat,automatic,19,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:403,testability,log,logs,403,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:486,testability,simpl,simply,486,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:586,testability,understand,understand,586,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:116,usability,progress,progress,116,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:168,usability,command,command,168,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:354,usability,user,user,354,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:461,usability,interact,interactive,461,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:486,usability,simpl,simply,486,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:522,usability,user,user,522,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:663,usability,interact,interactive,663,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that). ```. ... WARNING: did not find DISPLAY variable needed for interactive plotting. --> try ssh with `-X` or `-Y`. setting `sett.savefigs = True`. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:137,safety,detect,detect,137,[heres code](https://github.com/flying-sheep/smart-progress/blob/1091a0a9cc2d7a6304f992d13cb718d5150a64c6/smart_progress.py#L12-L21) to detect if were in a notebook or not. we could use that to decide if we want to use `tqdm_notebook` or `tqdm`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:137,security,detect,detect,137,[heres code](https://github.com/flying-sheep/smart-progress/blob/1091a0a9cc2d7a6304f992d13cb718d5150a64c6/smart_progress.py#L12-L21) to detect if were in a notebook or not. we could use that to decide if we want to use `tqdm_notebook` or `tqdm`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:52,usability,progress,progress,52,[heres code](https://github.com/flying-sheep/smart-progress/blob/1091a0a9cc2d7a6304f992d13cb718d5150a64c6/smart_progress.py#L12-L21) to detect if were in a notebook or not. we could use that to decide if we want to use `tqdm_notebook` or `tqdm`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:312,deployability,fail,fail,312,"Ah, looks great! Better than what I do right now. matplotlibs `is_interactive()` is not useful for this. The solution I have [now](https://github.com/theislab/scanpy/blob/a75f7158a599d2f30289154bc65656f72dd26674/scanpy/settings.py#L112-L123) does the job when comparing jupyter and running a script. But it will fail in the regular Python shell.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:242,reliability,doe,does,242,"Ah, looks great! Better than what I do right now. matplotlibs `is_interactive()` is not useful for this. The solution I have [now](https://github.com/theislab/scanpy/blob/a75f7158a599d2f30289154bc65656f72dd26674/scanpy/settings.py#L112-L123) does the job when comparing jupyter and running a script. But it will fail in the regular Python shell.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:312,reliability,fail,fail,312,"Ah, looks great! Better than what I do right now. matplotlibs `is_interactive()` is not useful for this. The solution I have [now](https://github.com/theislab/scanpy/blob/a75f7158a599d2f30289154bc65656f72dd26674/scanpy/settings.py#L112-L123) does the job when comparing jupyter and running a script. But it will fail in the regular Python shell.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:15,deployability,releas,release,15,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:23,deployability,version,version,23,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:23,integrability,version,version,23,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:23,modifiability,version,version,23,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:7,testability,plan,plan,7,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:245,deployability,releas,release,245,"protip: when wanting to link to lines, press the <kbd>y</kbd> key to change the url from `/master/` to `/<sha1sum>/`. that way the copied URL will stay valid and not break once the file is modified on the master branch. no objections to the release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:156,safety,valid,valid,156,"protip: when wanting to link to lines, press the <kbd>y</kbd> key to change the url from `/master/` to `/<sha1sum>/`. that way the copied URL will stay valid and not break once the file is modified on the master branch. no objections to the release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/16:193,security,modif,modified,193,"protip: when wanting to link to lines, press the <kbd>y</kbd> key to change the url from `/master/` to `/<sha1sum>/`. that way the copied URL will stay valid and not break once the file is modified on the master branch. no objections to the release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16
https://github.com/scverse/scanpy/issues/22:170,deployability,instal,installing,170,"I readded cython to the requirements: https://github.com/theislab/scanpy/commit/2ae826b71c1eefa16b165d4ff85de9f76fc9e62d. I thought it would be unnecessary when directly installing from the .c files, but evidently, it is not. Anyhow, this should fix it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22
https://github.com/scverse/scanpy/pull/23:110,modifiability,maintain,maintain,110,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/pull/23:110,safety,maintain,maintain,110,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/pull/23:181,security,Auth,Author,181,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/pull/23:239,security,Auth,Author,239,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/pull/23:25,testability,plan,plan,25,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/pull/23:137,testability,plan,plan,137,"Thanks! :smile: . FYI: I plan to remove the references in the future, though, as they are quite cumbersome to maintain. In the future, I plan to just reference papers using `[First Author *et al.*](https://doi.org/...)` instead of `[First Author *et al.*](#ref_firstauthor)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/23
https://github.com/scverse/scanpy/issues/24:202,deployability,releas,release,202,"Thanks! And sorry, this was something I had already fixed locally, but not yet pushed. Now it's up (https://github.com/theislab/scanpy/commit/320fa421aa2e1dcb15d047c629416b8640eb1635). The first stable release is not far away.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/24
https://github.com/scverse/scanpy/issues/26:187,availability,robust,robust,187,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:267,availability,robust,robust,267,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:950,deployability,log,log-normalization,950,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:332,modifiability,extens,extensive,332,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:481,modifiability,variab,variable,481,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:187,reliability,robust,robust,187,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:267,reliability,robust,robust,267,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:31,safety,input,input,31,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:187,safety,robust,robust,187,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:267,safety,robust,robust,267,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:950,safety,log,log-normalization,950,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:814,security,control,control,814,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:950,security,log,log-normalization,950,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:240,testability,simpl,simply,240,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:389,testability,understand,understanding,389,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:510,testability,simpl,simply,510,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:814,testability,control,control,814,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:943,testability,simpl,simple,943,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:950,testability,log,log-normalization,950,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1085,testability,simpl,simple,1085,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1453,testability,simpl,simple,1453,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:31,usability,input,input,31,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:240,usability,simpl,simply,240,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:374,usability,experien,experience,374,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:510,usability,simpl,simply,510,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:834,usability,workflow,workflow,834,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:943,usability,simpl,simple,943,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1085,usability,simpl,simple,1085,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1453,usability,simpl,simple,1453,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)). * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:927,availability,avail,available,927,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:290,deployability,log,log,290,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:319,deployability,log,log,319,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:470,deployability,log,log,470,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:474,deployability,scale,scale,474,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:474,energy efficiency,scale,scale,474,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1496,energy efficiency,model,modeling,1496,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:323,integrability,transform,transform,323,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1138,integrability,pub,publications,1138,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:323,interoperability,transform,transform,323,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:394,interoperability,distribut,distribution,394,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:203,modifiability,variab,variable,203,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:474,modifiability,scal,scale,474,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1201,modifiability,variab,variable,1201,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:130,performance,perform,perform,130,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:474,performance,scale,scale,474,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1387,performance,time,time,1387,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1488,performance,network,network,1488,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1525,performance,time,time,1525,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:927,reliability,availab,available,927,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:290,safety,log,log,290,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:319,safety,log,log,319,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:470,safety,log,log,470,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:927,safety,avail,available,927,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:146,security,control,control,146,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:290,security,log,log,290,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:319,security,log,log,319,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:470,security,log,log,470,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:927,security,availab,available,927,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1488,security,network,network,1488,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1496,security,model,modeling,1496,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:112,testability,understand,understandable,112,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:146,testability,control,control,146,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:290,testability,log,log,290,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:319,testability,log,log,319,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:470,testability,log,log,470,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1232,testability,understand,understanding,1232,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:130,usability,perform,perform,130,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1223,usability,person,personal,1223,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:1333,usability,help,help,1333,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by . `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`. and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:79,deployability,log,log,79,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:83,deployability,scale,scale,83,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:104,deployability,log,log-transform,104,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:83,energy efficiency,scale,scale,83,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:108,integrability,transform,transform,108,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:375,integrability,pub,public,375,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:108,interoperability,transform,transform,108,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:83,modifiability,scal,scale,83,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:83,performance,scale,scale,83,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:79,safety,log,log,79,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:104,safety,log,log-transform,104,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:438,safety,input,input,438,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:79,security,log,log,79,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:104,security,log,log-transform,104,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:79,testability,log,log,79,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:104,testability,log,log-transform,104,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:438,usability,input,input,438,"Hi! Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more! Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/26:58,usability,feedback,feedback,58,Thanks for your reply. I will try that and may given more feedback. Cheers!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26
https://github.com/scverse/scanpy/issues/27:270,availability,down,download,270,"About dpt_order in the Moignard example, if we plot the pseudotime vs. dpt-order at last manually like follows, . `plt.figure(figsize=(8,8)). plt.plot(adata.smp['dpt_order'], adata.smp['dpt_pseudotime']). plt.xlabel('dpt-order'). plt.ylabel('pseudotime')`. we'll get. ![download 1](https://user-images.githubusercontent.com/20141984/28011291-687c20e0-6594-11e7-8068-472b4ab4d8a8.png). which is totally chaotic, unlike the one we get through `sc.pl.dpt`. Anyway, did I misunderstand the concept of dpt-order or is there a bug about this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:290,usability,user,user-images,290,"About dpt_order in the Moignard example, if we plot the pseudotime vs. dpt-order at last manually like follows, . `plt.figure(figsize=(8,8)). plt.plot(adata.smp['dpt_order'], adata.smp['dpt_pseudotime']). plt.xlabel('dpt-order'). plt.ylabel('pseudotime')`. we'll get. ![download 1](https://user-images.githubusercontent.com/20141984/28011291-687c20e0-6594-11e7-8068-472b4ab4d8a8.png). which is totally chaotic, unlike the one we get through `sc.pl.dpt`. Anyway, did I misunderstand the concept of dpt-order or is there a bug about this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:14,availability,slo,slow,14,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:694,modifiability,paramet,parameter,694,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:765,modifiability,paramet,parameters,765,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:14,reliability,slo,slow,14,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:1028,reliability,Doe,Does,1028,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:746,security,control,control,746,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:746,testability,control,control,746,"Sorry for the slow response. The `'dpt_order'` is an index vector that orders cells according to pseudotime within each group. So, `adata[adata.smp['dpt_order']]` will be ordered in this way. You should not expect correlation of the index vector, which has very weird-looking entries, and `dpt_pseudotime`. I recommend only using `'dpt_pseudotime'` and `'dpt_groups'`. With `adata_0 = adata[adata.smp['dpt_groups']=='0']` you select the data points within group '0', which you could, e.g. order by pseudotime manually using `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. To resize figures, use matplolib's `rcParams['savefig.dpi']` or the convenience function that writes that parameter `sc.settings.set_dpi(150)`. You can fully control the figure parameters by changing the rcParams after importing scanpy. Scanpy, similarly to Seaborn, changes a few default settings when imported, see [here](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/plotting/utils.py#L55-L95). Does this answer your questions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:210,usability,user,user-images,210,"Many thanks. I got your idea about setting the figure properties now. However, regarding dpt-order, I am still a little confused. By running the Moignard example, we can get the following figure,. ![1](https://user-images.githubusercontent.com/20141984/28050880-153abf14-6633-11e7-971f-30b841dba50e.png). In this figure, is the dpt-order the same one as we have acquired by `sc.write('data/moignard15.csv', adata)`. It seems not because in the generated _smp.csv_, the dpt_order is not varying from 0 to about 700 for group 0, which is shown in the figure. Therefore, the above figure cannot be produced with the dpt_order in the generated _smp.csv_, right? We have to recompute the order manually by what you have said, like `adata_0 = adata_0[np.argsort(adata_0.smp['dpt_pseudotime'])]`. If so, then I got it. In short, we cannot use the dpt_order field in the generated _smp.csv_ directly. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:502,integrability,sub,sub-figure,502,"Thanks for your patience. I am almost there. . With your code, I can reproduce the figure on the bottom, i.e., pseudotime-dpt order. However, how about the top one? After we write the result, in the smp.csv file, the data looks like following. (I ordered by dpt_group in Excel.). ![2](https://user-images.githubusercontent.com/20141984/28059812-ff899ea4-6657-11e7-90a7-2857969775ba.png). Apparently, the cells with dpt_order such as 971, 966 and 960 belong to group 0, which is different from the top sub-figure, where they are assigned into group 1. How shall we explain this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:294,usability,user,user-images,294,"Thanks for your patience. I am almost there. . With your code, I can reproduce the figure on the bottom, i.e., pseudotime-dpt order. However, how about the top one? After we write the result, in the smp.csv file, the data looks like following. (I ordered by dpt_group in Excel.). ![2](https://user-images.githubusercontent.com/20141984/28059812-ff899ea4-6657-11e7-90a7-2857969775ba.png). Apparently, the cells with dpt_order such as 971, 966 and 960 belong to group 0, which is different from the top sub-figure, where they are assigned into group 1. How shall we explain this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:125,testability,simpl,simply,125,"Ok, now I see why you are confused! The x-axis in the figure above is somehow confusingly labeled 'dpt_order' even though it simply corresponds to `range(adata.n_smps)`, as evident from the code snippet I posted above; posting it again with the weird axis labeling that confuses you. ```. import matplotlib.pyplot as pl. pl.plot(range(adata.n_smps), adata.smp['dpt_pseudotime'][adata.smp['dpt_order']]). pl.xlabel('dpt_order'). pl.show(). ```. I definitely have to change this naming. Still it is meaningful that `adata.smp['dpt_order']` is an index vector that ""generates"" the order. OK, very soon, I could do the following. I'll rename the index array that generates the order `adata.smp['dpt_generate_order']` and the order you see in the plot `adata.smp['dpt_ordering_id']`, if you think this is better. So, one probably fast computation of this is the following. ```. ordering_id = np.zeros(adata.n_smps, dtype=int). for count, idx in adata.smp['dpt_generate_order']:. ordering_id[idx] = count. ```. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:125,usability,simpl,simply,125,"Ok, now I see why you are confused! The x-axis in the figure above is somehow confusingly labeled 'dpt_order' even though it simply corresponds to `range(adata.n_smps)`, as evident from the code snippet I posted above; posting it again with the weird axis labeling that confuses you. ```. import matplotlib.pyplot as pl. pl.plot(range(adata.n_smps), adata.smp['dpt_pseudotime'][adata.smp['dpt_order']]). pl.xlabel('dpt_order'). pl.show(). ```. I definitely have to change this naming. Still it is meaningful that `adata.smp['dpt_order']` is an index vector that ""generates"" the order. OK, very soon, I could do the following. I'll rename the index array that generates the order `adata.smp['dpt_generate_order']` and the order you see in the plot `adata.smp['dpt_ordering_id']`, if you think this is better. So, one probably fast computation of this is the following. ```. ordering_id = np.zeros(adata.n_smps, dtype=int). for count, idx in adata.smp['dpt_generate_order']:. ordering_id[idx] = count. ```. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:33,availability,consist,consistent,33,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:81,availability,robust,robustly,81,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:702,deployability,continu,continuous,702,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:81,reliability,robust,robustly,81,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:81,safety,robust,robustly,81,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:103,security,lineag,lineage,103,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:834,testability,understand,understandable,834,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:33,usability,consist,consistent,33,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:115,availability,consist,consistent,115,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:199,availability,consist,consistent,199,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:258,energy efficiency,current,currently,258,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:316,reliability,doe,does,316,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:80,safety,compl,completely,80,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:80,security,compl,completely,80,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:115,usability,consist,consistent,115,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/27:199,usability,consist,consistent,199,"The dpt branch field you are look for is the `adata.smp['dpt_groups']` field. I completely agree that it should be consistent with our paper; that's what it was meant to be. Also the figure above is consistent with that, it's just that the 'dpt_order' field currently is an index field that generates the order, but does not provide ids for it. I'll make this more transparent in the future. Cheers!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27
https://github.com/scverse/scanpy/issues/30:37,integrability,interfac,interface,37,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:37,interoperability,interfac,interface,37,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:37,modifiability,interfac,interface,37,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:24,security,command-lin,command-line,24,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:85,testability,simpl,simply,85,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:24,usability,command,command-line,24,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/30:85,usability,simpl,simply,85,"Hi! Sorry for that, the command-line interface got a bit behind. I fixed everything, simply pull again. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30
https://github.com/scverse/scanpy/issues/31:262,integrability,sub,subset,262,"Hi Zachary,. thank you for your remark. Yes, I agree, there should be a hint that tells the user to provide a set of selected genes; I've done this many times already but it didn't end up in the function definition. I'll add a hint and a possibility to select a subset of genes very soon. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:153,performance,time,times,153,"Hi Zachary,. thank you for your remark. Yes, I agree, there should be a hint that tells the user to provide a set of selected genes; I've done this many times already but it didn't end up in the function definition. I'll add a hint and a possibility to select a subset of genes very soon. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:72,usability,hint,hint,72,"Hi Zachary,. thank you for your remark. Yes, I agree, there should be a hint that tells the user to provide a set of selected genes; I've done this many times already but it didn't end up in the function definition. I'll add a hint and a possibility to select a subset of genes very soon. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:92,usability,user,user,92,"Hi Zachary,. thank you for your remark. Yes, I agree, there should be a hint that tells the user to provide a set of selected genes; I've done this many times already but it didn't end up in the function definition. I'll add a hint and a possibility to select a subset of genes very soon. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:227,usability,hint,hint,227,"Hi Zachary,. thank you for your remark. Yes, I agree, there should be a hint that tells the user to provide a set of selected genes; I've done this many times already but it didn't end up in the function definition. I'll add a hint and a possibility to select a subset of genes very soon. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:11,deployability,version,version,11,"In the new version (0.2.7), this is resolved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:11,integrability,version,version,11,"In the new version (0.2.7), this is resolved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/31:11,modifiability,version,version,11,"In the new version (0.2.7), this is resolved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/31
https://github.com/scverse/scanpy/issues/33:553,availability,cluster,clustering,553,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:553,deployability,cluster,clustering,553,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:599,reliability,doe,doesn,599,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:37,safety,detect,detects,37,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:37,security,detect,detects,37,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:639,security,sign,signature,639,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:165,usability,help,helps,165,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:843,usability,help,helps,843,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:885,usability,document,documentation,885,"Hi Jiping! I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,. Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:95,availability,down,downstream,95,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:245,availability,error,error,245,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:158,energy efficiency,reduc,reduce,158,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:19,integrability,filter,filtered,19,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:211,modifiability,variab,variable,211,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:245,performance,error,error,245,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:245,safety,error,error,245,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/33:245,usability,error,error,245,"Hi Alex! Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. . Thanks a lot,. Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33
https://github.com/scverse/scanpy/issues/35:291,availability,error,error,291,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:97,deployability,version,version,97,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:216,deployability,stack,stackoverflow,216,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:97,integrability,version,version,97,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:97,modifiability,version,version,97,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:291,performance,error,error,291,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:119,safety,test,tested,119,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:291,safety,error,error,291,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:119,testability,test,tested,119,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:291,usability,error,error,291,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:18,deployability,instal,install,18,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:35,deployability,upgrad,upgrade,35,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:65,deployability,updat,update,65,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:104,deployability,version,version,104,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:104,integrability,version,version,104,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:35,modifiability,upgrad,upgrade,35,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:104,modifiability,version,version,104,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:0,reliability,Doe,Does,0,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:65,safety,updat,update,65,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:65,security,updat,update,65,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:44,usability,help,help,44,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:96,usability,minim,minimal,96,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:258,availability,error,error,258,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:430,modifiability,pac,packages,430,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:258,performance,error,error,258,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:36,reliability,doe,doesn,36,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:239,reliability,doe,does,239,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:258,safety,error,error,258,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:392,security,hash,hashem,392,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:339,testability,simpl,simply,339,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:127,usability,user,user,127,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:258,usability,error,error,258,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:339,usability,simpl,simply,339,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type. ```. import psutil. psutil.process_iter(). ```. does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,usability,document,documentation,31,Btw: Scanpy now has an initial documentation at https://scanpy.readthedocs.io.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:208,availability,error,error,208,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,deployability,updat,updating,31,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:362,deployability,modul,module,362,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:755,deployability,log,logg,755,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1351,deployability,modul,module,1351,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1549,deployability,upgrad,upgrade,1549,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1710,deployability,upgrad,upgrade,1710,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:362,modifiability,modul,module,362,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:524,modifiability,pac,packages,524,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:969,modifiability,pac,packages,969,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1319,modifiability,pac,packages,1319,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1351,modifiability,modul,module,1351,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1549,modifiability,upgrad,upgrade,1549,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1710,modifiability,upgrad,upgrade,1710,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:208,performance,error,error,208,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,safety,updat,updating,31,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:208,safety,error,error,208,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:335,safety,input,input-,335,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:362,safety,modul,module,362,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:755,safety,log,logg,755,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1351,safety,modul,module,1351,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1426,safety,avoid,avoid,1426,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1600,safety,avoid,avoid,1600,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,security,updat,updating,31,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:263,security,Hash,Hashem,263,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:486,security,hash,hashem,486,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:755,security,log,logg,755,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:931,security,hash,hashem,931,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1281,security,hash,hashem,1281,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:291,testability,Trace,Traceback,291,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:755,testability,log,logg,755,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:208,usability,error,error,208,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:335,usability,input,input-,335,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:540,usability,tool,tools,540,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1483,usability,visual,visualization,1483,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:1651,usability,visual,visualization,1651,"Hi Alex, . The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`. , I get the following error. The igraph I am using is V 0.1.11. Many thanks. Hashem. `DeprecationWarning Traceback (most recent call last). <ipython-input-20-fb44185f2d28> in <module>(). 1 . ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True). 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy). 78 directed = False. 79 if not directed: logg.m(' using the undirected graph', v=4). ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 81 if flavor == 'vtraag':. 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 41 def get_igraph_from_adjacency(adjacency, directed=None):. 42 """"""Get igraph graph from adjacency matrix."""""". ---> 43 import igraph as ig. 44 sources, targets = adjacency.nonzero(). 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:16,deployability,configurat,configuration,16,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:80,deployability,instal,installed,80,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:292,deployability,automat,automatic,292,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:302,deployability,instal,installation,302,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:348,deployability,updat,updated,348,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:429,deployability,instal,install,429,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:161,energy efficiency,power,powerful,161,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:183,energy efficiency,core,core,183,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:16,integrability,configur,configuration,16,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:16,modifiability,configur,configuration,16,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:348,safety,updat,updated,348,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:16,security,configur,configuration,16,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:348,security,updat,updated,348,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:292,testability,automat,automatic,292,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:404,testability,simpl,simply,404,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:126,usability,user,users,126,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:404,usability,simpl,simply,404,This is again a configuration problem. You don't have http://igraph.org/python/ installed. That's a library with thousands of users and citations. It has a very powerful and fast C++ core that allows treating dataset sizes with a million cells. I realize that I misspecified this in Scanpy's automatic installation in the requirements file. I just updated this and will push it to the master branch. You simply need to type `pip install python-igraph` and then everything should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,deployability,version,version,31,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:55,deployability,instal,installed,55,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:100,deployability,instal,install,100,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:165,deployability,updat,updated,165,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,integrability,version,version,31,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:31,modifiability,version,version,31,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:122,reliability,doe,doesnt,122,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:165,safety,updat,updated,165,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:165,security,updat,updated,165,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ). pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:88,deployability,instal,installing,88,"I think this was happening because of confusion between igraph and python-igraph, by un-installing both and reinstalling just python-igraph, the issue was solved. Interesting enough installation with conda didnt work, only installation with pip worked. thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:182,deployability,instal,installation,182,"I think this was happening because of confusion between igraph and python-igraph, by un-installing both and reinstalling just python-igraph, the issue was solved. Interesting enough installation with conda didnt work, only installation with pip worked. thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:223,deployability,instal,installation,223,"I think this was happening because of confusion between igraph and python-igraph, by un-installing both and reinstalling just python-igraph, the issue was solved. Interesting enough installation with conda didnt work, only installation with pip worked. thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:345,availability,mainten,maintenance,345,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:89,deployability,version,version,89,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:171,deployability,releas,release,171,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:272,deployability,stage,stage,272,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:548,deployability,stage,stage,548,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:588,deployability,version,version,588,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:89,integrability,version,version,89,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:588,integrability,version,version,588,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:89,modifiability,version,version,89,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:285,modifiability,pac,package,285,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:364,modifiability,pac,package,364,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:475,modifiability,pac,packages,475,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:588,modifiability,version,version,588,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:345,reliability,mainten,maintenance,345,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:305,usability,progress,progressing,305,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:603,usability,document,documentation,603,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage. Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:177,availability,cluster,cluster,177,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:177,deployability,cluster,cluster,177,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:253,deployability,configurat,configuration,253,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:329,deployability,version,version,329,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:253,integrability,configur,configuration,253,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:329,integrability,version,version,329,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:253,modifiability,configur,configuration,253,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:329,modifiability,version,version,329,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:253,security,configur,configuration,253,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:374,security,Hash,Hashem,374,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/35:105,usability,efficien,efficiently,105,No worries and thank you for usually very prompt suggestions. The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. . Looking forward to a more stable version with more added function. Thank you. Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35
https://github.com/scverse/scanpy/issues/78:8,deployability,continu,continued,8,"Also, I continued our [pull request discussion](https://github.com/theislab/scanpy/pull/76)... :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/78
https://github.com/scverse/scanpy/pull/80:114,availability,error,error,114,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:51,energy efficiency,green,green,51,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:114,performance,error,error,114,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:25,reliability,doe,doesn,25,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:92,safety,test,test,92,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:114,safety,error,error,114,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:102,security,expos,exposes,102,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:92,testability,test,test,92,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:114,usability,error,error,114,"Thank you! So you say it doesnt work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:24,interoperability,standard,standard,24,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:33,safety,input,input,33,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:59,safety,test,testing,59,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:59,testability,test,testing,59,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:33,usability,input,input,33,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:159,availability,down,downloaded,159,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK theres no scRNA-Seq ones that arent dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesnt end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:283,deployability,build,building,283,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK theres no scRNA-Seq ones that arent dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesnt end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:242,reliability,doe,doesn,242,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK theres no scRNA-Seq ones that arent dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesnt end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:183,safety,test,tests,183,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK theres no scRNA-Seq ones that arent dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesnt end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:183,testability,test,tests,183,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK theres no scRNA-Seq ones that arent dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesnt end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:12,availability,down,downloaded,12,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:23,deployability,automat,automatically,23,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:43,reliability,pra,practical,43,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:23,testability,automat,automatically,23,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:48,availability,down,downloaded,48,"Ah, I didn't know others are also automatically downloaded, very nice. paul15 uses `sc.utils.check_presence_download()`, while others use `check_datafile_present_and_download()` via `readwrite.read()`, though. Is this intentional?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:34,deployability,automat,automatically,34,"Ah, I didn't know others are also automatically downloaded, very nice. paul15 uses `sc.utils.check_presence_download()`, while others use `check_datafile_present_and_download()` via `readwrite.read()`, though. Is this intentional?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:34,testability,automat,automatically,34,"Ah, I didn't know others are also automatically downloaded, very nice. paul15 uses `sc.utils.check_presence_download()`, while others use `check_datafile_present_and_download()` via `readwrite.read()`, though. Is this intentional?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:14,availability,down,downloaded,14,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:25,deployability,automat,automatically,25,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:112,deployability,automat,automated,112,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:132,deployability,continu,continuous,132,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,deployability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:74,energy efficiency,cool,cool,74,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,integrability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,interoperability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,modifiability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:45,reliability,pra,practical,45,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,reliability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:122,safety,test,testing,122,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,security,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:25,testability,automat,automatically,25,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:112,testability,automat,automated,112,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:122,testability,test,testing,122,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:143,testability,integr,integration,143,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:83,usability,interact,interactive,83,"> `paul15` is downloaded automatically, very practical. Yeah, its really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1133,availability,error,error,1133,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:290,deployability,modul,module,290,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:512,energy efficiency,core,core,512,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:635,energy efficiency,core,core,635,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:771,energy efficiency,core,core,771,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:927,energy efficiency,core,core,927,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:290,modifiability,modul,module,290,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:496,modifiability,pac,packages,496,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:619,modifiability,pac,packages,619,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:755,modifiability,pac,packages,755,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:911,modifiability,pac,packages,911,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1133,performance,error,error,1133,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1010,reliability,doe,does,1010,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1076,reliability,doe,does,1076,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:8,safety,test,test,8,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:290,safety,modul,module,290,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1133,safety,error,error,1133,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:8,testability,test,test,8,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:199,testability,Trace,Traceback,199,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:390,testability,simpl,simple,390,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:390,usability,simpl,simple,390,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:1133,usability,error,error,1133,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb. Initial shape: 737280x28002. After min_genes: 5128x28002. After max_genes: 1431x28002. Traceback (most recent call last):. File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>. sc.pp.filter_genes(adata, min_cells=3). File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes. adata.var['n_cells'] = number. File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item. value = self._sanitize_column(key, value). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column. value = _sanitize_index(value, self.index, copy=False). File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index. raise ValueError('Length of values does not match length of ' 'index'). ValueError: Length of values does not match length of index. ```. Note that this same error displays on both of the following lines:. ```python. sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_genes(adata, max_cells=1000). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:70,availability,failur,failures,70,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:70,deployability,fail,failures,70,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:70,performance,failur,failures,70,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:70,reliability,fail,failures,70,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:82,safety,test,testing,82,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:82,testability,test,testing,82,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/pull/80:22,usability,clear,clear,22,"Oh, damn... It wasn't clear to me that you were actually saying that this is broke... Sorry, I went over a few pull requests too quickly. Anyways, so the master branch was broke for a day. It's resolved in https://github.com/theislab/scanpy/commit/96890730972162aa531c3289b38ad728a7585c85. The next pull request goes smoother... :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80
https://github.com/scverse/scanpy/issues/81:259,deployability,automat,automatically,259,"Use the `right_margin` option in the plotting functions... You need more space on the right to display all the columns. Or use `legend_loc='on data'`. Sorry, for that I still haven't figured out how to compute the white space needed to the left of the figure automatically. Ah, just now I'm having an idea for this. I'll soon fix this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/81
https://github.com/scverse/scanpy/issues/81:259,testability,automat,automatically,259,"Use the `right_margin` option in the plotting functions... You need more space on the right to display all the columns. Or use `legend_loc='on data'`. Sorry, for that I still haven't figured out how to compute the white space needed to the left of the figure automatically. Ah, just now I'm having an idea for this. I'll soon fix this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/81
https://github.com/scverse/scanpy/pull/82:177,deployability,releas,release,177,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:391,deployability,releas,release,391,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:524,deployability,contain,contain,524,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:704,deployability,API,API,704,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:243,energy efficiency,cool,cool,243,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:704,integrability,API,API,704,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:704,interoperability,API,API,704,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:515,reliability,doe,does,515,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:414,testability,context,context,414,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week! Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:315,deployability,manag,manage,315,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:315,energy efficiency,manag,manage,315,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:503,integrability,translat,translation,503,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:541,integrability,translat,translation,541,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:503,interoperability,translat,translation,503,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:541,interoperability,translat,translation,541,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:87,safety,permiss,permissions,87,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:315,safety,manag,manage,315,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:341,security,ident,identifiers,341,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:667,security,modif,modified,667,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:571,usability,user,user,571,"Hi @falexwolf , . I'd like to directly push such small things but either I do not have permissions or I'm not proficient enough in git :-/. That said, following another thread about gene lists, I'm quite skeptical about the implementation of gene list class, or at least I believe it is out of scope. How would you manage, for example, gene identifiers? The list used for cell cycle is for humans and include HGCN symbols, but Entrez ID or ENSEMBL ID may be used, and since there may be confusion in ID translation, I'd leave the definition/translation part to the final user. As for the notebook, I pushed a notebook for cell cycle in scanpy_usage repo, it could be modified/prettified/whateverfied. cheers. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:78,availability,consist,consistent,78,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:179,deployability,api,api,179,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:190,deployability,api,api,190,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:255,deployability,api,api,255,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:266,deployability,api,api,266,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:179,integrability,api,api,179,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:190,integrability,api,api,190,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:255,integrability,api,api,255,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:266,integrability,api,api,266,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:179,interoperability,api,api,179,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:190,interoperability,api,api,190,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:255,interoperability,api,api,255,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:266,interoperability,api,api,266,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:485,security,auth,author,485,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:78,usability,consist,consistent,78,"Hi @dawe! OK, I'm done. I think now everything makes a nice impression and is consistent with the other naming conventions etc. in Scanpy. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. I also added you to the author list (already wanted to do this before)... Sorry that it took so long... the kids... Thank you very much! :smile:. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:36,availability,error,error,36,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:60,deployability,instal,installation,60,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:392,interoperability,specif,specify,392,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:117,modifiability,pac,package,117,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:574,modifiability,pac,package,574,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:36,performance,error,error,36,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:36,safety,error,error,36,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:400,safety,valid,valid,400,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:485,safety,compl,complexity,485,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:485,security,compl,complexity,485,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:36,usability,error,error,36,"Hi, . I just stumbled upon the same error, maybe due to the installation method. Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase). at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,. Raphal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:73,availability,error,error,73,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:127,availability,error,error,127,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:97,deployability,instal,installation,97,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:208,deployability,version,version,208,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:208,integrability,version,version,208,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:208,modifiability,version,version,208,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:73,performance,error,error,73,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:127,performance,error,error,127,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:73,safety,error,error,73,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:127,safety,error,error,127,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:73,usability,error,error,73,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/82:127,usability,error,error,127,"Hi Raphal! Thanks! What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error? Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82
https://github.com/scverse/scanpy/pull/83:108,interoperability,format,format,108,"Just push things like this on the master branch. :wink: And, consider using `'a string with a variable: {}'.format(variable)` for formatting strings. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/83
https://github.com/scverse/scanpy/pull/83:130,interoperability,format,formatting,130,"Just push things like this on the master branch. :wink: And, consider using `'a string with a variable: {}'.format(variable)` for formatting strings. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/83
https://github.com/scverse/scanpy/pull/83:94,modifiability,variab,variable,94,"Just push things like this on the master branch. :wink: And, consider using `'a string with a variable: {}'.format(variable)` for formatting strings. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/83
https://github.com/scverse/scanpy/pull/83:115,modifiability,variab,variable,115,"Just push things like this on the master branch. :wink: And, consider using `'a string with a variable: {}'.format(variable)` for formatting strings. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/83
https://github.com/scverse/scanpy/issues/84:58,integrability,sub,submit,58,"Thank you! :smile:. Of course! I agree! Would you like to submit a pull request? That might be the fastest way to achieve this... If you don't think you want to do it, I'll look into it as soon as possible (~weeks)...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/84
https://github.com/scverse/scanpy/issues/85:451,deployability,api,api,451,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:462,deployability,api,api,462,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:527,deployability,api,api,527,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:538,deployability,api,api,538,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:451,integrability,api,api,451,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:462,integrability,api,api,462,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:527,integrability,api,api,527,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:538,integrability,api,api,538,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:451,interoperability,api,api,451,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:462,interoperability,api,api,462,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:527,interoperability,api,api,527,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:538,interoperability,api,api,538,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:293,performance,time,times,293,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:238,security,expos,expose,238,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:259,usability,user,user,259,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:343,usability,intuit,intuitive,343,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up... PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc. PPS: The new cell cycle example could interest you:. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html. Both link to the notebook in the ""Examples"" section. https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:326,integrability,pub,public,326,"Alex - Thanks for the links, I'll look them over. And good news about the gene correlation work. I've placed links to both the tab and h5ad files for an example dataset in a [folder on Dropbox](https://www.dropbox.com/sh/44i9jiy6h8ms9mc/AADOITmx9URHloDF7Yj6NTE2a?dl=0). That's not the same as in the screenshot, which isn't a public dataset yet, but this one is the same idea. Wanting to be able to rapidly generate a violin plot for any given gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:120,integrability,filter,filter,120,"Thinking about this more I think ideally we wouldn't really on the obs column name ""--"" convention and rather place and filter this based on data put in .uns, right? Just have to learn how to do that ....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:179,usability,learn,learn,179,"Thinking about this more I think ideally we wouldn't really on the obs column name ""--"" convention and rather place and filter this based on data put in .uns, right? Just have to learn how to do that ....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:92,deployability,observ,observations,92,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:343,interoperability,standard,standard,343,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:676,reliability,Doe,Does,676,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:92,testability,observ,observations,92,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:686,usability,help,help,686,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:761,usability,efficien,efficient,761,"Hi Joshua,. ok, first of all, you should store the group id as a field in the annotation of observations/cells (`.obs`). Taking your AnnData, you'd do the following:. ```. adata.obs['mygroups'] = [name.split('--')[0] for name in adata.obs_names]. ```. You can then do . ```. sc.pl.violin(adata, 'mygene', group_by='mygroups'). ```. as in the [standard example](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), box [32]. Instead of 'mygene', you can use any annotation key; for instance gene scores, as produced by `sc.pp.score_genes`. Or averages over genes `adata.obs['my_gene_set_avg'] = adata[:, gene_set].X.mean(axis=1)`. Does this help or did I misunderstand something? PS: As a principle rule for writing efficient python code: never loop over more than a 100 items... absolutely never use nested loops. :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:252,reliability,doe,doesn,252,"Maybe I misunderstood something, because your loop over genes. ```. for g, gene in enumerate(selected.var_names):. for c, cell in enumerate(selected.obs_names):. if '--' in cell:. cell = cell.split('--')[0]. edata.append( [selected.X[c], cell] ). ```. doesn't seem to actually do something...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,deployability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:333,deployability,scale,scale,333,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:333,energy efficiency,scale,scale,333,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,integrability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,interoperability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,modifiability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:333,modifiability,scal,scale,333,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:333,performance,scale,scale,333,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,reliability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,security,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:76,testability,integr,integrated,76,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:24,usability,help,helpful,24,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:131,usability,efficien,efficient,131,"Thanks, that's all very helpful. I'll work on getting these recommendations integrated. One quick question, is this still the most efficient way to get the data for one gene for the violin plot? selected = adata[:, adata.var_names.isin([gene.gene_symbol,])]. And before all the data was just in relational tables but, of course, the scale was a lot less. EDIT: I just re-read and saw that it seems you can pass the gene name to the violin() call itself. Beautiful magic.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:9,testability,simpl,simply,9,"Yes, you simply pass a single gene name to the violin plot... :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:9,usability,simpl,simply,9,"Yes, you simply pass a single gene name to the violin plot... :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:165,security,access,access,165,"I wanted to report success here. I had to change your references to var_names above to obs_names but got it working after that. Now I just need to figure out how to access the plot customization methods so I can clean it up. The labels are all blurred together, for example. ![screenshot from 2018-03-06 11-16-16](https://user-images.githubusercontent.com/330899/37047580-01c7b8e2-2131-11e8-9bb7-d060bfc6d0d6.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:181,usability,custom,customization,181,"I wanted to report success here. I had to change your references to var_names above to obs_names but got it working after that. Now I just need to figure out how to access the plot customization methods so I can clean it up. The labels are all blurred together, for example. ![screenshot from 2018-03-06 11-16-16](https://user-images.githubusercontent.com/330899/37047580-01c7b8e2-2131-11e8-9bb7-d060bfc6d0d6.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:322,usability,user,user-images,322,"I wanted to report success here. I had to change your references to var_names above to obs_names but got it working after that. Now I just need to figure out how to access the plot customization methods so I can clean it up. The labels are all blurred together, for example. ![screenshot from 2018-03-06 11-16-16](https://user-images.githubusercontent.com/330899/37047580-01c7b8e2-2131-11e8-9bb7-d060bfc6d0d6.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:51,availability,failur,failures,51,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:51,deployability,fail,failures,51,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:288,deployability,updat,updates,288,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:51,performance,failur,failures,51,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:51,reliability,fail,failures,51,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:288,safety,updat,updates,288,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:288,security,updat,updates,288,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:20,usability,document,documentation,20,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:84,availability,operat,operate,84,Great! More customization can be done when you pass `show=False` to `pp.violin` and operate on the returned `matplotlib.Axes` object. In your case you can just do `pl.xticks(rotation=90)`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:174,security,rotat,rotation,174,Great! More customization can be done when you pass `show=False` to `pp.violin` and operate on the returned `matplotlib.Axes` object. In your case you can just do `pl.xticks(rotation=90)`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:12,usability,custom,customization,12,Great! More customization can be done when you pass `show=False` to `pp.violin` and operate on the returned `matplotlib.Axes` object. In your case you can just do `pl.xticks(rotation=90)`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:77,modifiability,paramet,parameter,77,"So I guess, this is fine, now. PS: In Scanpy 1.0, there is also a `rotation` parameter for the labels in the violin plot. The introductory [tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) shows how this works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/issues/85:67,security,rotat,rotation,67,"So I guess, this is fine, now. PS: In Scanpy 1.0, there is also a `rotation` parameter for the labels in the violin plot. The introductory [tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) shows how this works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85
https://github.com/scverse/scanpy/pull/87:58,usability,learn,learn,58,"Thank you! I'll rename the result according to the scikit-learn convention, though. If they call it `explained_variance_`, we should also call it that way - we can add in the docs, that it equals the eigenvalues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/87
https://github.com/scverse/scanpy/issues/88:92,availability,error,error,92,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:92,performance,error,error,92,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:92,safety,error,error,92,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:92,usability,error,error,92,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:112,usability,help,help,112,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:33,availability,error,error,33,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:39,integrability,messag,message,39,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:39,interoperability,messag,message,39,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:33,performance,error,error,33,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:33,safety,error,error,33,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:33,usability,error,error,33,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:19,availability,error,error,19,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:141,availability,error,error,141,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:25,integrability,messag,message,25,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:147,integrability,messag,message,147,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:25,interoperability,messag,message,25,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:147,interoperability,messag,message,147,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:19,performance,error,error,19,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:141,performance,error,error,141,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:19,safety,error,error,19,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:141,safety,error,error,141,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:19,usability,error,error,19,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/88:141,usability,error,error,141,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88
https://github.com/scverse/scanpy/issues/89:6,deployability,version,version,6,Which version of numpy and scipy are you running?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/89:6,integrability,version,version,6,Which version of numpy and scipy are you running?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/89:6,modifiability,version,version,6,Which version of numpy and scipy are you running?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/89:148,performance,memor,memory,148,"Thanks Mohammad, we will resolve this! @dawe It's not related to numpy or scipy, as it only occurs when running AnnData in `backed` mode for out-of-memory computing; this becomes necessary only for >100K cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/89:148,usability,memor,memory,148,"Thanks Mohammad, we will resolve this! @dawe It's not related to numpy or scipy, as it only occurs when running AnnData in `backed` mode for out-of-memory computing; this becomes necessary only for >100K cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/89:120,usability,close,close,120,"That's kind of a longer-term project and will not be directly solved by adding a method ""mean"" to SparseDataset... I'll close this for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/89
https://github.com/scverse/scanpy/issues/90:331,deployability,build,build,331,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:366,deployability,build,build,366,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:397,deployability,version,versioneer,397,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:480,deployability,version,versioneer,480,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:686,deployability,version,version,686,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:711,deployability,version,version,711,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:752,deployability,updat,updating,752,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:703,energy efficiency,Current,Current,703,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:397,integrability,version,versioneer,397,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:480,integrability,version,versioneer,480,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:686,integrability,version,version,686,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:711,integrability,version,version,711,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:118,modifiability,maintain,maintainers,118,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:397,modifiability,version,versioneer,397,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:480,modifiability,version,versioneer,480,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:686,modifiability,version,version,686,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:711,modifiability,version,version,711,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:766,modifiability,pac,packages,766,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:118,safety,maintain,maintainers,118,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:752,safety,updat,updating,752,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:752,security,updat,updating,752,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:213,testability,understand,understand,213,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:273,testability,trace,traceback,273,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:94,usability,help,helpful,94,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:113,usability,help,help,113,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:457,usability,command,command,457,"Thank you @maximilianh for debugging this and telling us the actual values here! Thats super helpful, and would help maintainers extremely if everybody did it. But I think its relatively advanced to do it, so I understand when people dont. OK, what I can glean from the traceback:. 1. setup.py is invoked. 2. `self.run_command('build')` might mean that `setup.py build` is invoked. 3. /scanpy/versioneer.py  `_build_py.run(self)` so at some point some command defined by the versioneer is used. 4. as @maximilianh said, the end is a line in `build_py.py`. which was [replaced two years ago](https://github.com/pypa/setuptools/commit/4f6fc8537842c14b03c4a1ffd25b88f2f4c276c6), in version 25.1.2. (Current version is 38.5.1). Could you please try updating your packages to see if theres still an issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:10,deployability,upgrad,upgrade,10,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:102,deployability,instal,install,102,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:112,deployability,upgrad,upgrade,112,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:10,modifiability,upgrad,upgrade,10,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:34,modifiability,pac,packages,34,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:112,modifiability,upgrad,upgrade,112,"Oh! I did upgrade pip and all the packages needed by scanpy, but didn't have the idea of doing:. pip3 install --upgrade setuptools. This fixed it! Many thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/issues/90:40,usability,help,help,40,"Again, many thanks for your super quick help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90
https://github.com/scverse/scanpy/pull/91:471,modifiability,paramet,parameters,471,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/91:178,security,command-lin,command-line,178,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/91:368,security,control,control,368,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/91:368,testability,control,control,368,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/91:178,usability,command,command-line,178,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/91:440,usability,tool,tools,440,"Thank you, Gokcen! All these recompute arguments are, of course, not a good thing - they arose when I first drafted Scanpy thinking that everything should be concise single-word command-line arguments... As mentioned on our Mattermost channel, I want to get away from it; there is one convenience preprocessing function `neighbors` and one class `Neighbors` with more control that should be called as a step in the preprocessing; all other tools will then delegate graph parameters to this...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/91
https://github.com/scverse/scanpy/pull/92:54,usability,user,user-images,54,"OK, this was easier than I thought:. ![image](https://user-images.githubusercontent.com/1140359/36549134-0215d542-17c0-11e8-9683-941e30e278a0.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/92
https://github.com/scverse/scanpy/pull/92:33,usability,user,user-images,33,More examples:. ![image](https://user-images.githubusercontent.com/1140359/36547957-102800ea-17bd-11e8-97c2-899df89bcdc0.png). ![image](https://user-images.githubusercontent.com/1140359/36548769-25d0786c-17bf-11e8-9646-cacd34b0a294.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/92
https://github.com/scverse/scanpy/pull/92:144,usability,user,user-images,144,More examples:. ![image](https://user-images.githubusercontent.com/1140359/36547957-102800ea-17bd-11e8-97c2-899df89bcdc0.png). ![image](https://user-images.githubusercontent.com/1140359/36548769-25d0786c-17bf-11e8-9646-cacd34b0a294.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/92
https://github.com/scverse/scanpy/pull/93:124,modifiability,variab,variable,124,"Also `groups_names` was undefined in the same function, I changed it to `groups_order` but I'm not sure if it's the correct variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/93
https://github.com/scverse/scanpy/pull/93:41,performance,time,time,41,"grrr, sorry, it's not been used for some time it seems... thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/93
https://github.com/scverse/scanpy/issues/94:50,availability,cluster,cluster,50,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:357,availability,error,error,357,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:464,availability,cluster,clustering,464,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:713,availability,error,error,713,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:25,deployability,manag,manage,25,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:50,deployability,cluster,cluster,50,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:464,deployability,cluster,clustering,464,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:25,energy efficiency,manag,manage,25,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:916,interoperability,format,format,916,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:357,performance,error,error,357,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:713,performance,error,error,713,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:25,safety,manag,manage,25,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:357,safety,error,error,357,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:713,safety,error,error,713,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:357,usability,error,error,357,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:713,usability,error,error,713,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb. ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7']. ```. PS: The error is raised by the following. ```py. if (reference != 'rest' . and reference not in set(adata.obs[group_by].cat.categories)): . raise ValueError('reference = {} needs to be one of group_by = {}.' . .format(reference, . adata.obs[group_by].cat.categories.tolist())). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:502,deployability,version,version,502,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:548,deployability,version,version,548,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:575,deployability,depend,dependencies,575,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:606,deployability,instal,install,606,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:616,deployability,upgrad,upgrade,616,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:502,integrability,version,version,502,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:548,integrability,version,version,548,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:575,integrability,depend,dependencies,575,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:60,interoperability,standard,standard,60,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:502,modifiability,version,version,502,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:548,modifiability,version,version,548,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:575,modifiability,depend,dependencies,575,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:616,modifiability,upgrad,upgrade,616,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:575,safety,depend,dependencies,575,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:575,testability,depend,dependencies,575,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:343,usability,tool,tools,343,"This is very strange... Do you have this issue also in the [standard tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb)? Of course, the louvain function produces string-named categories, see [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L135) and has always done so. I'm puzzled that the `.astype('U')`, where the `'U'` stands for unicode-string, seems to have no effect in your version of Scanpy. Do you use the most recent version (0.4.4) and recent dependencies? If not, run `pip install --upgrade scanpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:78,deployability,api,api,78,"I got ints as well in the past, not now though:. ```py. In [1]: import scanpy.api as sc. In [2]: sc.__version__. Out[2]: '0.4.4'. In [3]: m = sc.datasets.moignard15(). In [4]: sc.tl.louvain(m). In [5]: m.obs.louvain_groups.cat.categories. Out[5]: Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:78,integrability,api,api,78,"I got ints as well in the past, not now though:. ```py. In [1]: import scanpy.api as sc. In [2]: sc.__version__. Out[2]: '0.4.4'. In [3]: m = sc.datasets.moignard15(). In [4]: sc.tl.louvain(m). In [5]: m.obs.louvain_groups.cat.categories. Out[5]: Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:78,interoperability,api,api,78,"I got ints as well in the past, not now though:. ```py. In [1]: import scanpy.api as sc. In [2]: sc.__version__. Out[2]: '0.4.4'. In [3]: m = sc.datasets.moignard15(). In [4]: sc.tl.louvain(m). In [5]: m.obs.louvain_groups.cat.categories. Out[5]: Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:40,deployability,version,version,40,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:134,deployability,version,version,134,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:40,integrability,version,version,40,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:134,integrability,version,version,134,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:40,modifiability,version,version,40,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:134,modifiability,version,version,134,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:95,safety,reme,remember,95,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:82,testability,simpl,simply,82,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:82,usability,simpl,simply,82,Thank you for this; maybe there was one version where this was inconsistent and I simply don't remember... @AnatoleKing have you used version 0.4.4?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:28,deployability,version,version,28,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:44,deployability,updat,update,44,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:84,energy efficiency,power,powerful,84,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:28,integrability,version,version,28,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:28,modifiability,version,version,28,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:44,safety,updat,update,44,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:44,security,updat,update,44,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/94:93,usability,tool,tool,93,"@falexwolf , I used '0.4.2' version, I will update to the latest. Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94
https://github.com/scverse/scanpy/issues/95:246,deployability,log,logistic,246,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:324,deployability,updat,updated,324,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:378,modifiability,Pac,Pachter,378,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:386,reliability,doe,does,386,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:88,safety,test,testing,88,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:246,safety,log,logistic,246,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:324,safety,updat,updated,324,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:246,security,log,logistic,246,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:324,security,updat,updated,324,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:88,testability,test,testing,88,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:246,testability,log,logistic,246,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:255,testability,regress,regression,255,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:490,usability,experien,experience,490,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:110,integrability,wrap,wrapper,110,"Agreed. I dont think we should rush and include everything into scanpy, especially when it would be a simple wrapper of something existing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:110,interoperability,wrapper,wrapper,110,"Agreed. I dont think we should rush and include everything into scanpy, especially when it would be a simple wrapper of something existing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:103,testability,simpl,simple,103,"Agreed. I dont think we should rush and include everything into scanpy, especially when it would be a simple wrapper of something existing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/95:103,usability,simpl,simple,103,"Agreed. I dont think we should rush and include everything into scanpy, especially when it would be a simple wrapper of something existing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95
https://github.com/scverse/scanpy/issues/96:190,availability,cluster,clusters,190,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:622,availability,cluster,clustered,622,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:190,deployability,cluster,clusters,190,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:622,deployability,cluster,clustered,622,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1195,deployability,version,version,1195,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:252,energy efficiency,Current,Currently,252,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:440,energy efficiency,model,model,440,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:786,integrability,abstract,abstracted,786,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1195,integrability,version,version,1195,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1208,integrability,coupl,couple,1208,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1291,interoperability,specif,specific,1291,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:786,modifiability,abstract,abstracted,786,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1195,modifiability,version,version,1195,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1208,modifiability,coupl,couple,1208,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:440,security,model,model,440,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:500,security,sign,significance,500,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:698,security,sign,significance,698,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1034,testability,simpl,simply,1034,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1208,testability,coupl,couple,1208,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:80,usability,minim,minimum,80,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:324,usability,minim,minimum,324,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:477,usability,clear,clearer,477,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:1034,usability,simpl,simply,1034,"Hi! Thanks for reaching out! We have an option to compute connectivity based on minimum distance, right. The default choice, however, is based on edge-statistics (actual inter-edges between clusters vs. expected number of edges in random connections). Currently, I'm working on the revision of the algorithm. The option for minimum distance will disappear and everything will become much cleaner. I'm also trying to improve the statistical model for connectivity and provide a clearer option for its significance threshold. Right now, the only relevant option in the whole AGA [given the single-cell graph is computed and clustered] is `tree_based_confidence=True`; if you set this to `False`, the significance value for edges to appear will be much lower and you'll get a much sparser abstracted graph. However, this graph is sometimes too sparse. If `tree_based_confidence=True`, as per default, this works fine on very connected datasets, but sometimes gives results that are too dense on disconnected datasets. For now, you could simply try setting `tree_based_confidence=False` and see whether this is satisfying. If not; probably too sparse, it would be great if you could try the new AGA version in a couple of days. Also, I'd be very happy to run the method on your data and look at specific issues. You can also approach me via email... Cheers,. Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:342,availability,cluster,clusters,342,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:342,deployability,cluster,clusters,342,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:482,integrability,sub,subtype,482,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:503,integrability,sub,subtype,503,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:590,performance,perform,perform,590,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:305,reliability,doe,does,305,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:12,usability,confirm,confirm,12,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:590,usability,perform,perform,590,"Hi, just to confirm that I tried the new PAGA functions a while ago and the results look very good. (sorry for the delay of the response. I meant to respond to the thread much earlier but got busy doing other stuff.). Now I'm wondering about how to interpret the graph connectivities. An undirected graph does not imply whether two connected clusters are sequential (e.g. progenitors -> newborn neurons -> mature neurons) or on different branches but highly correlated (e.g. neuron subtype 1 vs. neuron subtype 2). . Do you think it's possible to use RNA velocity (http://velocyto.org/) to perform quantitative interference on the directionality of the edges? I have the velocity data but not sure how to mathematically infer edge directions. Maybe I should open a new issue on this or approach you via email? Thanks! .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:59,availability,cluster,clusters,59,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:163,availability,cluster,cluster-edges,163,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:59,deployability,cluster,clusters,59,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:163,deployability,cluster,cluster-edges,163,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:544,energy efficiency,model,model,544,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:575,integrability,sub,subject,575,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:135,security,sign,significant,135,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:544,security,model,model,544,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:42,testability,simpl,simply,42,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:412,testability,plan,planaria,412,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:42,usability,simpl,simply,42,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:492,usability,document,documented,492,"Hi! Good to read! :smile:. The PAGA edges simply mean that clusters are topologically connected - in the single-cell graph, there is a significant number of inter-cluster-edges, above noise-level. They absolutely don't have an orientation. Regarding velocyto: yes, it's possible to use it to orient the edges in PAGA. You can get that functionality following [this](https://github.com/falexwolf/paga/blob/master/planaria/planaria_paga_velocyto.ipynb); however, until this becomes really well-documented etc. this will still take a while... the model behind this will also be subject to change, I guess... Get Scanpy 1.1 for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:203,deployability,version,version,203,"Thanks for uploading the notebook! This is exactly what I was looking for! I'll try it out and let you know how it works on my data, and I'll try look into the model (and code) too. Great to see the new version coming out today. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:160,energy efficiency,model,model,160,"Thanks for uploading the notebook! This is exactly what I was looking for! I'll try it out and let you know how it works on my data, and I'll try look into the model (and code) too. Great to see the new version coming out today. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:203,integrability,version,version,203,"Thanks for uploading the notebook! This is exactly what I was looking for! I'll try it out and let you know how it works on my data, and I'll try look into the model (and code) too. Great to see the new version coming out today. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:203,modifiability,version,version,203,"Thanks for uploading the notebook! This is exactly what I was looking for! I'll try it out and let you know how it works on my data, and I'll try look into the model (and code) too. Great to see the new version coming out today. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:160,security,model,model,160,"Thanks for uploading the notebook! This is exactly what I was looking for! I'll try it out and let you know how it works on my data, and I'll try look into the model (and code) too. Great to see the new version coming out today. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:62,deployability,version,version,62,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:129,energy efficiency,model,models,129,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:62,integrability,version,version,62,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:62,modifiability,version,version,62,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:210,modifiability,extens,extensive,210,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:266,safety,review,review,266,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:129,security,model,models,129,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:10,testability,plan,planning,10,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:266,testability,review,review,266,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:161,usability,clear,clearer,161,"If you're planning to look into the code: There will be a new version of PAGA in Scanpy 1.2, which will feature two connectivity models... The code will be much clearer. We'll also see whether we can upload an extensive revision of the preprint - unfortunately, the review process at the journal took ages and coming up with the revision, too. All of this should happen in the next days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:94,deployability,version,version-,94,"This what I'm currently compiling. While [Scanpy 1.1](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018) concerned some basic updates and more general features, Scanpy 1.2 will be about PAGA. No worries, everything is backward compatible... but PAGA will have many more cool features and in addition, also feature a second, better model. I will release it this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:140,deployability,updat,updates,140,"This what I'm currently compiling. While [Scanpy 1.1](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018) concerned some basic updates and more general features, Scanpy 1.2 will be about PAGA. No worries, everything is backward compatible... but PAGA will have many more cool features and in addition, also feature a second, better model. I will release it this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:359,deployability,releas,release,359,"This what I'm currently compiling. While [Scanpy 1.1](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018) concerned some basic updates and more general features, Scanpy 1.2 will be about PAGA. No worries, everything is backward compatible... but PAGA will have many more cool features and in addition, also feature a second, better model. I will release it this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:14,energy efficiency,current,currently,14,"This what I'm currently compiling. While [Scanpy 1.1](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018) concerned some basic updates and more general features, Scanpy 1.2 will be about PAGA. No worries, everything is backward compatible... but PAGA will have many more cool features and in addition, also feature a second, better model. I will release it this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
https://github.com/scverse/scanpy/issues/96:284,energy efficiency,cool,cool,284,"This what I'm currently compiling. While [Scanpy 1.1](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018) concerned some basic updates and more general features, Scanpy 1.2 will be about PAGA. No worries, everything is backward compatible... but PAGA will have many more cool features and in addition, also feature a second, better model. I will release it this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96
